\chapter{Modelling Performance Strategies}\label{chap:mp_network}

\section{Introduction}

Jazz ensemble performances involve intricate processes of coordination among the musicians involved. Through collective improvisation, performers exchange musical ideas, negotiate their roles in the ensemble, and strive to understand each other’s intentions in the performance. In particular, jazz musicians display unique (and genre-specific) approaches to embodied musical timing, variously referred to as their “feel,” “swing,” “pocket,” “time” \citep{Berliner1994}, and they must align their timing with their partners’ in order to maintain a coherent performance \citep{Doffman2014}. Group jazz improvisation thereby exemplifies a particular kind of joint action in which coordination is achieved through multi-level interactive alignment, the process by which the participants in a joint activity come to understand aspects of their shared world in the same way as each other \citep{Garrod2004}. In this respect, jazz improvisation has often been compared to spontaneous spoken conversation \citep{Kello2017, Monson1996}, where alignment towards shared conceptualizations of space and time can also occur between participants.

With the rapid advancements in high-quality audio streaming technology, interactive musical performances of genres including jazz can now take place over vast distances via the internet. Networked performance brings with it certain advantages; for example, improving access to live performances for those with disabilities and reducing travel-related costs, time, and environmental emissions. More recently, it became necessary for many musicians because of restrictions on face-to-face performances during the COVID-19 pandemic. However, using a network to mediate a musical performance has its limitations. 

Whenever a sound is transferred over a network, a temporal delay—known as latency—is introduced between when it was first produced and when it is received, resulting from the time required to convert sound waves to digital packets and transmit them over a network. While some form of delay is present even when music is performed face-to-face, owing to the time taken for sound to transmit in air, the latency present in networked performances is often several orders of magnitude greater \citep{Chafe2010}. In addition, transmission errors and network congestion can cause fluctuation in packet arrival time, and this variability—known as jitter—can cause further instability in (or even the momentary loss of) the output signal during networked performances.

This variable delay poses significant challenges for successfully coordinating joint action in various forms of time-dependent communication such as spoken conversation \citep{Aagaard2022, Boland2022} and interactive music-making \citep{Chafe2010, Chew2005, Rottondi2015}. Network latency impedes the alignment of temporal models and precludes the extreme rhythmic synchrony that is typical of ensemble playing; networked performances have correspondingly been associated with decreased ratings of performance quality and reduced connectedness with co-performers compared to face-to-face music-making \citep{Bartlette2006, Monache2019, Olmos2009}. Moreover, unlike speech interaction, in musical performance action and interaction are generally organized around a continuous temporally periodic pulse \citep{London2012}, which is highly susceptible to disruption by latency and jitter. Network latency starts to cause problems for interactive musical performances at 28 milliseconds of one-way delay \citep{Chafe2010}, while the threshold for negotiating spoken conversations online without difficulty seems to be much higher, at 500 ms \citep{Holub2007}.

Prior research has focused on optimizing networking infrastructure to improve the fluidity and coherence of remote musical performance. This has included the development of low-latency, low-jitter platforms such as JackTrip \citep{Caceres2010} and LOLA \citep{Drioli2013} that intend to offer the networked ensemble an experience as close as possible to that of playing in the same room as each other. Strategies used by these systems include data buffering, where incoming data packets are stored by the application before being released at regular intervals to ensure consistency in the output signal. But while these technological advances can minimize the presence of a time-lag to performers, latency can never be eliminated completely. A networked ensemble must, therefore, find some way of coordinating their joint action that accommodates this delay in the process.

In this study, we aim to determine the relative optimality of strategies for coordinating group musical improvisation over a network, with all the reliance on periodicity and the tight temporal coordination of action that this process entails. In previous work, coordination in face-to-face performances has typically been modeled as a function of one performer’s adaptation to any deviations from expected isochrony in another’s playing (phase correction or “coupling”: see \citealp{Jacoby2021}, \citealp{Timmers2014}, \citealp{Wing2014}; see also \citealp{Demos2023}, for a recent review). In networked performances, one hypothesis is that all players in an ensemble should try hard to listen to each other and couple together, which could result in mutual and symmetrical adaptation to timing variability \citep{Nowicki2013}. An alternative hypothesis is that successful networked interaction requires a degree of asymmetry in the distribution of roles within a musical ensemble: one performer ignores the delayed feedback, while their partner(s) attempt to match and adapt to them \citep{Carot2009}. Participants in prior studies have mentioned adopting either these or similar strategies to accommodate latency during networked performances (e.g., \citealp{Bartlette2006}), but the question of which might be optimal has not been systematically explored. 

To address this issue, we conducted a series of experiments where five duos of professional jazz drummers and pianists improvised together over a simulated network. This network introduced delay and jitter of a magnitude up to and including that present on Zoom, a telecommunications platform commonly used in remote interaction and teleconferencing. To evaluate the relative optimality of their coordination strategies, we use a battery of objective and subjective metrics as indicators of the overall success of these performances. Data are gathered from MIDI recordings and evaluations are provided by both the musicians and a secondary sample of naive listeners recruited via an online perceptual study. We begin our analysis by outlining the results obtained from co-present (i.e., non-delayed) conditions, before then considering how the presence of latency and jitter affects these baselines. Next, we use a combination of linear causal modeling and participant self-reports to characterize the individual coordination strategies of each duo. Finally, we evaluate the relative optimality of these strategies by conducting computer simulations.

\section{Methods}\label{sec:mp_methods}

\subsection{Participants}	

Ten adult men with a median age of 24 ($SD = 5$, $\text{range} = [21, 36]$) participated in the study. All participants had at least three years of professional experience on either piano or drum kit and held an undergraduate (or higher) degree in music performance and were required to be fluent English language speakers. This combination of instruments was selected as they constitute part of the “rhythm section” in jazz: these musicians play continuously throughout a performance, and their interaction is considered vital to its overall success. Participants were recruited from within the author’s network of performance contacts and were all professional or semi-professional musicians based in London, UK. All individuals who were approached for inclusion participated in and completed the study, with the experiments being conducted during April–July 2022.

Participants were grouped into five duos, each consisting of one pianist and one drummer, with no participant performing in more than one duo. The two musicians in duo 3 had never played together before, while the remaining pairs reported performing with each other during the past year. However, none of the participants had any prior experience of networked performance with their duo partner before the present experiment. 

This sample size was deemed appropriate because we treated each participant (and participant-duo) as an independent entity, extensively characterizing their individual coordination strategy over a large number of performances rather than focusing on group averages across the entire sample. This approach is typical for psychological studies of advanced musical performance where ensemble roles and interpretative strategies are both highly specialized and individualized, and may depend on pre-existing relationships within a particular participant-group (e.g., \citealp{Jacoby2021}, \citealp{Pras2017}, \citealp{Timmers2014}, \citealp{Wing2014}).

The experiment was approved by the Ethics Review Subcommittee at the Faculty of Music, University of Cambridge, UK, and all participants provided written informed consent. Participants were paid for their time and travel expenses.

\subsection{Testbed Configuration}

\begin{figure}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/mp_network/figure_1.png}
  \caption{Testbed configuration. The top row of panels shows (a) the procedure used to measure network latency over Zoom Meetings and (b) the resulting 90-second latency and jitter time-series profile. The bottom row shows (c) a diagram of the testbed layout and (d) how this looked within the experiment room, for pianist and drummer.}
\label{fig:mp_testbed_configuration}
\end{figure}

We designed a novel testbed for the experiment, shown in Figure \ref{fig:mp_testbed_configuration}. First, we generated a representative measurement of network latency and jitter by connecting two computers on the same network to a virtual call on a popular telecommunications platform (Zoom). Then, we positioned a metronome (playing at 80 quarter note beats per minute) next to one computer, so that an echo could be heard from the speakers of the other computer as each pulse was transmitted (Figure \ref{fig:mp_testbed_configuration}a). We recorded audio of this process for 90 seconds and derived the variable roundtrip latency between pulse and echo by applying the onset detection algorithm (using the "spectral flux" method: see section \ref{sec:jtd_alternate_methods}) contained in the \texttt{librosa} (version \texttt{0.8.1}) Python library \citep{McFee2015}, to the recording. Network latency was generally stable around a median peak-to-peak delay of 192 ms ($SD = 17.7$, $\text{range} = [181, 293]$ ms), with occasional spikes caused by jitter (Figure \ref{fig:mp_testbed_configuration}b). 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s1}
  \caption{Additional network latency tests. Each column of plots shows the variable latency time experienced during a 90-second teleconferencing call on Zoom Meetings, created following the procedures used in Figure \ref{fig:mp_testbed_configuration}a. The left-most column shows the network latency measurements used in the present study, given also in Figure \ref{fig:mp_testbed_configuration}b. The remaining columns show results from identical tests in three different locations. In each column of plots, the $y$-axis shows the latency time between initial metronome beat and echo, normalized such that the minimum delay time is 0 ms; the $x$-axis shows either the duration of the call (line plot), or the density function (histogram).}
\label{fig:mp_additional_network_tests}
\end{figure}

We conducted identical tests in three different locations, using different network configurations. These were: (1) a recording studio, with both devices connected wirelessly to an institutional network; (2) the same studio, with one device connected to the institutional network and the other wirelessly to a mobile cellular network; (3) a home office, with one device connected via Ethernet to a commercial router and the other to a mobile cellular network. These produced broadly similar results (Figure \ref{fig:mp_additional_network_tests}), which suggested that our measurements resembled the typical experience of using this platform for telecommunication.

The testbed was designed to apply these measurements to a performance in a controlled fashion --- simulating a network, not directly implementing one (as in e.g., \citealp{Rottondi2015}). In the experiment room, an acoustically isolated recording studio, both participants sat apart from each other, with barriers placed so as to prevent direct visual contact (\ref{fig:mp_testbed_configuration}c). Separate video and MIDI streams were captured of their performances, using an electronic keyboard (\texttt{Nord Electro 6D-73}), drum kit (\texttt{Roland TD-27KV}), and computer webcams (\texttt{Logitech Brio 4K Pro}). Video was captured at a resolution of $1920 \ \times \ 1080$ px and a rate of 30 frames per second. These signals were then transmitted to a computer server via USB connection and a 32-channel MIDI interface (\texttt{M-Audio MIDISPORT $2 \ \times \ 2$}). 

We implemented the software components of our testbed in the Python programming language. Variable latency was applied to each musical track using the digital audio workstation \texttt{REAPER} (version \texttt{6.46}).\footnote{\href{https://www.reaper.fm/}{\texttt{https://www.reaper.fm/}}} Communication with the Python backend was handled using the \texttt{ReaPy} bindings. (version \texttt{0.10.0})\footnote{\href{https://github.com/RomeoDespres/reapy}{\texttt{https://github.com/RomeoDespres/reapy}}} Each time a note was played, the corresponding latency was determined by looking up the current value in the latency time series (Figure \ref{fig:mp_testbed_configuration}), and the playback of that note was then delayed by that amount. Delay times were resampled from the latency time series at periodic intervals of 750 ms to replicate the metronome speed of the original test. Latency was applied to each video track in an identical manner using the \texttt{OpenCV} \citep{Bradski2000} computer vision library in Python (version \texttt{4.5.5.64}).

The server then stored both the incoming (live) and outgoing (delayed) signals for later analysis before presenting them to participants. MIDI signals were first transcoded to audio using a high-quality virtual instrument library and then routed over closed-back headphones at a rate of 44.1 kHz through a 16-bit digital-to-analog converter. Video was shown on individual 27-inch computer monitors in front of each participant. Participants heard and saw delayed audio and video from their partner’s performance, alongside unmanipulated audio of their own playing. They did not see video of themselves, due to the additional computational demand this would introduce and the likelihood that this would obstruct the view of their partner and their instrument (Figure \ref{fig:mp_testbed_configuration}d). 

During testing, we found that the inherent delay added by our testbed signal path to the incoming MIDI signal was 4 ms for the keyboard and 3 ms for the drums. This is significantly lower than the inherent audio latency reported in previous studies (e.g., \citealp{Olmos2009}, \citealp{Rottondi2015}) and likely stems from our use of MIDI data, rather than audio. This value is not included in the reported results as it is likely perceptually sub-threshold \citep{Grant2004}.

The inherent delay for the incoming video signals was substantially greater at 33 ms (i.e., one frame), which was not unexpected due to the greater computational demands involved in the real-time processing of video compared to audio. Rather than applying additional latency to the MIDI to compensate for this, we instead allowed both audio and video to be unsynchronized, which is common during networked performance and teleconferencing \citep{Rottondi2016}.

\subsection{Experimental Design}

We selected a “twelve-bar blues” structure in the key of $\text{B}\flat$ as the musical stimulus for the experiment. This simple, repetitive form is pervasive in jazz and popular music and was immediately familiar to all participants, all of whom chose to perform it from memory and without the aid of a musical score that was offered to them. Performances lasted 90 seconds, the same duration as our measured latency time series, meaning that the total number of repeats of the blues form was dictated by the tempo established by the musicians. Before the experiment began, participants completed three warm-up performances without any latency and at a variety of tempi, allowing them to practice together in the testbed environment. The remaining performances comprised the experimental session and were characterized by differing amounts of latency and jitter.

We operationalized latency by transposing the original latency time series $d$ (Figure \ref{fig:mp_testbed_configuration}b) so that $\text{min}(d) \in \{23, 45, 90, 180\}$ ms, not including the inherent delay introduced by the testbed. This latter value (180 ms) was within the upper limit of latency times tested in prior research and was essentially equivalent to the minimum delay we had originally measured on Zoom (181 ms); the other values tested were the integer quotients resulting from the successive division of 180. We manipulated jitter by keeping the minimum latency value as set above but scaling the deviations from this minimum value by either 1.0x (no change from original variation measured on Zoom), 0.5x, or 0.0x (no jitter, consistent/“flat” delay). The procedure used to transform the original latency time series $d$ to the latency time series $d'$, with minimum latency time $L$ and jitter scaling $J$, can be written as:

\begin{align}\label{eq:mp_latency}
d'^N_1=\biggl(J\biggl(d_i-\text{min}(d^N_1)\biggr)+L\biggr)^N_1
\end{align}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_2}
  \caption{Experimental conditions. The thirteen conditions tested in the experiment were derived from the transformation of the measurements in Figure \ref{fig:mp_testbed_configuration}b. The rows indicate minimum latency values between 0 and 180 ms, with jitter scalings shown by the color of each line. The left column shows the raw latency timings over the 90-second duration of each performance. The right column displays the standard deviation of latency values obtained over a sliding window of four seconds, which we later use in the partial correlation analysis of timing variance shown in Figure \ref{fig:mp_partial_correlations}}
\label{fig:mp_experimental_conditions}
\end{figure}

A final control condition was also tested, in which no latency or jitter was applied to the signal beyond that introduced by the testbed (i.e., $L = 0$, $J = 0$). These thirteen conditions were presented to duos in a randomized order across two successive sessions with a break of one hour in between, with each condition appearing once in every session. All experimental manipulations were delivered by the author. Figure \ref{fig:mp_experimental_conditions} shows the transformations of the latency time series that were used in each condition.

\subsection{Experimental Procedure}\label{sec:mp_experimental_procedure}

Before each performance began, participants heard sixteen quarter-note pulses from a synthesized metronome over their headphones at a moderate tempo of 120 quarter-note beats per minute, which is a typical speed for a medium tempo jazz blues. The first of each group of four pulses was played at a higher pitch and greater dynamic level than the others to clarify the meter as four quarter-note beats per measure. The total duration of this count-in was eight seconds.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s2c}
  \caption{MIDI note distribution. Both "instruments" show the frequency of MIDI note placement across all performances in the dataset; the darker the color, the more often that particular drum or piano note was played. Values are scaled so that the most frequently played note has a normalized value of 1. Note that the rims of the snare, rack, and floor toms were tracked independently of the center of these drums, and are coloured accordingly. Additionally, the ride cymbal is separated into bell (center) and bow (edge), and the hi-hat into cymbal (struck with the stick) and pedal (operated with the foot). Only the four octaves of the piano keyboard that were used most frequently are shown here.}
\label{fig:mp_instrument_heatmaps}
\end{figure}

Participants were then instructed to improvise together over the blues form while maintaining both the tempo and meter established by the metronome pulses. To do so, they were asked to play continuous quarter notes, either in their left hand as part of a “walking bass” or “stride” accompaniment (pianist), or by “playing time” on their hi-hat and ride cymbals and bass kick drum in a swing style (drummer). In Figure \ref{fig:mp_instrument_heatmaps} we analyze the frequency of MIDI note distribution across the total range of each instrument to demonstrate that their performances broadly conformed to the given brief. 

Participants were not made explicitly aware of the presence of latency and jitter. Instead, they were told that the feedback they would receive from their partner would change during the experiment, and that they should interact with them as they otherwise would during a “real” performance. To that end, we encouraged participants to improvise light musical embellishments while following their assigned brief, provided that this did not disrupt their ability to maintain the underlying quarter-note pulse. All instructions given to participants were in English.

Each performance lasted for 90 seconds before participants were instructed to stop. Recording was then maintained for several seconds to prevent notes from being cut-off if they occurred shortly before the 90-second point; the following analyses only consider the first 90 seconds of a performance, however.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s3}
  \caption{Test-retest reliability, performance questionnaire. Each bar shows the inter-rater (i.e. between both the pianist and drummer in a duo) and test-retest (i.e. between matched scores for each condition across both sessions of the experiment) reliability of the scalar questions presented to performers in the experiment. The $x$-axis shows each question, with values of Pearson’s $r$ on the $y$-axis. Bar coloring corresponds to duo numbers. Asterisks above a bar indicate the significance of the correlation coefficient, $^* \ p < .05, \ ^{**} \ p < .01, \ ^{***} \ p < .001$.}
\label{fig:mp_performer_questionnaire_test_retest}
\end{figure}

After each performance, participants responded to questionnaires indicating their subjective experience of that performance in terms of: (1) the quality of the interaction with their duo partner; (2) the ease of coordination with their partner and; (3) the overall success of the performance. These questions were administered using the \texttt{Qualtrics} online survey platform and are similar to those used in an earlier study of improvised duo interaction by \citet{Setzler2020}. Participants provided responses to each question using integers from 1 to 9 inclusive, with lower scores corresponding to negative and higher scores to positive evaluations. We show measurements of test-retest reliability in Figure \ref{fig:mp_performer_questionnaire_test_retest}. Participants were also able to comment in free text on a performance, with anonymized transcripts of these responses provided in Appendix \ref{chap:mp_appendix}.

\subsection{Listener Evaluations}

As we could not assume that our participants would provide an unbiased assessment of the quality of their own performance \citep{Pras2017, Schober2014}, we also obtained equivalent evaluations from listeners recruited online via the \texttt{Prolific} platform. This experiment was implemented in the \texttt{PsyNet} (version \texttt{10.2.0}) software package \citep{Harrison2020} that enables large-scale perceptual studies to be conducted online through a browser-based interface. Participants were required to: (1) be at least 18 years old, (2) use headphones, (3) be in a quiet environment where they can clearly see their computer screen, and (4) use an up-to-date Google Chrome browser. 

A pre-screening listening task that asked participants to discern differences in the volume of three synthesized sounds \citep{Woods2017} was presented at the start of the experiment to exclude participants who were not listening attentively over headphones. Successful participants were then shown recordings (audio and video, with latency and jitter applied to both participants as in the original performance) of the first 45 seconds of 15 performances randomly sampled from the dataset, and were asked to rate the overall success of the performance. To ensure consistency between multiple evaluations of one performance, listener ratings were made using the same 9-point scale that was initially given to the musicians in the experiment. Of the three initially answered by our performers, only the performance success question was used in this experiment as it was most likely to be comprehensible to listeners, who were not required to have any prior experience of listening to jazz. Participants were told only that the performances were taking place over the internet, and were not informed about latency or jitter. 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s4b}
  \caption{Listener demographic information. Each bar plot shows the proportion of responses to every demographic question presented to each participant in the listening evaluation test.}
\label{fig:mp_listener_demographics}
\end{figure}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s4c}
  \caption{Distribution of results in subjective listening evaluation. Each plot shows 95\% confidence intervals obtained from bootstrapping (with $N = 10,000$ replicates) over the listener-reported success scores ($x$-axis) obtained from the perceptual study for each condition ($y$-axis).}
\label{fig:mp_listener_results_distribution}
\end{figure}

Eighty-eight adults (44 women, 42 men, 2 nonbinary) with a median age of 38 ($SD = 14$, $\text{range} = [18, 75]$) participated in the study, excluding those who failed pre-screening tasks. For full demographic details, including information on participants’ musical background, see Figure \ref{fig:mp_listener_demographics}. An appropriate sample size was determined by calculating the number of participants required to obtain 10 ratings of each of the 130 performances in the dataset, assuming 15 performances rated per participant (equivalent to a study duration of 11.25 minutes, excluding pre-screening). In reality, not all performances received the full number of ratings, due to attrition caused by network time-outs or participants otherwise ending the study early: 31 (23.8\%) performances were rated by 9 participants and 6 performances (4.6\%) were rated by 8. Responses were generally consistent across participants when rating the same performance (Figure \ref{fig:mp_listener_results_distribution}.

The experiment was approved by the Ethics Review Subcommittee at the Faculty of Music, University of Cambridge, UK, and all participants provided written informed consent. Participants were compensated at a GBP £10/hour rate, according to the amount of the experiment they completed; thus, if a participant failed a pre-screening task or left the study early, they were still paid for the proportion of the task that they had completed.

\subsection{Beat Extraction}

For each of the 130 performances in the dataset, we extracted the position of the MIDI onsets corresponding to each quarter-note beat by manually removing any improvised embellishments from the unmanipulated (live) recordings. The precision of detected beats was 0.5 ms, corresponding to an internal MIDI resolution of 960 pulses-per-quarter-note at the reference tempo of 120 quarter-note beats per minute.

\begin{figure}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/mp_network/figure_3.png}
  \caption{Beat extraction procedure. (a) shows notation from a hypothetical performance where linear interpolation would have been applied. The note annotated with an exclamation point in the upper stave has been ‘pushed’ before its expected position as the first beat of the next bar. The lower stave shows the performance after interpolation, with this note aligned midway between the quarter notes immediately before and after it (the interbeat interval between which is given by $y$). (b) shows the total number of beats contributed by each participant to the final dataset, after filtering and nearest-neighbor matching. The hatched segment of each bar shows the proportion of beats by that performer that required interpolation, with the exact number of beats given above the bar.}
\label{fig:mp_beat_extraction_procedure}
\end{figure}

In a small number of performances, the regular quarter-note pulse was occasionally disrupted, either due to mistakes made by participants or due to syncopated anticipation (“pushing”) of the quarter-note beat ahead of its expected metrical position \citep{Berliner1994}. Missing (or anticipated) quarter notes were detected through inspection of the MIDI data, using the video recordings of a performance for reference. We then realigned these notes into their expected position through linear interpolation between those beats occurring immediately before and after (Figure \ref{fig:mp_beat_extraction_procedure}a).

Repeat notes (where one musical event was incorrectly registered as two or more MIDI notes) were filtered from performances in the dataset by discarding any quarter-note beats where a preceding beat had occurred less than 250 ms before. Repeat notes may inadvertently occur when a performer presses a piano key or hits a drum pad several times in rapid succession. We chose this threshold as it was half the duration of quarter-note interbeat intervals at the reference tempo provided to participants (500 ms), and we deemed it unlikely that participants would have accelerated to more than twice this initial tempo.

A nearest-neighbor algorithm was then used to match each quarter-note beat from one performer with the closest equivalent beat played by their partner, with the addition of the latency applied by the testbed at that moment in the performance. In cases where two consecutive beats by one participant could conceivably be matched with the same beat by their partner, the pair with the maximum temporal distance between matched beats was excluded. This process accounted for instances where a performer may have inserted an additional quarter note into their performance to realign with their partner \citep{Berliner1994}; several of their comments attested to the use of this procedure, e.g., “popped an extra beat in a middle fill” (drummer, duo 1), “I added an extra beat towards the end of the recording to get back on [beats] 2 and 4” (pianist, duo 3).

The raw dataset consisted of 46,640 quarter-note beats, 2.7\% of which required linear interpolation. Filtering repeated MIDI notes from the performances amounted to a loss of 0.4\% of the raw data, with the process of nearest-neighbor matching incurring a further loss of 4.0\%. The final dataset comprised 44,605 matched quarter-note beats, extracted from four hours of performances (Figure \ref{fig:mp_beat_extraction_procedure}b). 

\subsection{Analysis}

We extracted three objective measures of coordination success from the matched quarter-note beats dataset: (1) tempo slope, capturing systematic digression from the reference tempo; (2) asynchrony, the extent to which both performers remained “in time” with each other; and (3) timing irregularity, the local variability of quarter-note interbeat intervals. Tempo slope and asynchrony were calculated within groups, with a single performance yielding one value for both musicians. Timing irregularity was calculated individually for both participants, with a single performance yielding a separate value for each musician. Alongside these objective measurements, we also considered two subjective indices of performance success as provided by (1) the musicians themselves (two values per performance, one per musician), and (2) the participants in our online perceptual study (one value per performance, averaged across all raters). 

We define tempo slope as the signed overall tempo change per second within a performance, equivalent to the slope of a linear regression of instantaneous tempo against beat onset time such that a negative slope implies deceleration over time and a positive slope acceleration \citep{Rottondi2016}. Individual coefficients obtained for both musicians in a duo were averaged to reflect the fact that one performer’s tempo would not feasibly be independent of their partner’s when attempting to play together.

We define asynchrony as the root mean square of the temporal distance between all matched beat pairs articulating the same metrical position played by both musicians \citep{Clayton2020}, including the latency applied by the testbed to both beats. The single asynchrony value obtained from each performance represents the perspective of a hypothetical listener joined to the same virtual “call” as our duo, who would have experienced latency and jitter applied to both musicians’ performance equally. This was the perspective adopted by the participants in our online rating study.

We define timing irregularity as the relative temporal instability of a performance, as characterized by the moment-to-moment variability in quarter-note beat durations. This metric was computed by sliding an overlapping window of four seconds duration (equivalent to two measures at the reference tempo and meter) over both performers’ quarter-note interbeat intervals (such that the first window spanned the opening four seconds of a performance, and the second window seconds one to five), taking the standard deviation of interbeat intervals within each window, and then finally obtaining the median of all standard deviation values. We opted to use windowed statistics due to their increased robustness to trends and patterns in time series analysis, as the mean interbeat interval duration of a performance would be expected to change over time if the tempo slowed down or sped up. 

We obtained separate values for the regularity of each performer’s timing in a duo. This is because we were interested in modeling the variability inherent within their individual performance, which we assumed would be the result of both between-participant variance (i.e., differences in note/phrase choices during improvisation across all pianists and drummers), alongside the inherent differences between the roles occupied by the pianist and drummer in a jazz rhythm section \citep{Kilchenmann2015}. 

We define performer-reported success as the response given by participants to the question “how successful was the performance?” with a rating of 1 indicating an “extremely unsuccessful” performance and 9 an “extremely successful” one. This question was selected for analysis as it demonstrated the best test-retest and inter-rater reliability of the three that we initially asked performers (Figure \ref{fig:mp_performer_questionnaire_test_retest}). However, we note here that levels of inter-performer agreement were still not especially high, as indicated by values of Pearson’s $r$ obtained from the correlation of all pianist-drummer scores in one duo: $mean(r) = .40$ ($SD = .24$, $\text{range} = [.17, .73]$), suggesting only moderate agreement on average. Disagreements of this kind are common in group musical improvisation, however, where performers rarely share the same understanding of what unfolded \citep{Pras2017, Schober2014}, and this was not taken to indicate any inherent lack of reliability in how this question had been presented.

We define listener-reported success as the ratings of overall performance success given by listeners in our online perceptual experiment, in response to the same question initially presented to our performers. Individual ratings of the same condition were generally consistent across participants ($mean(SD) = 1.64$; see also Figure \ref{fig:mp_listener_results_distribution}), which led us to average ratings obtained for each performance. Average levels of listener-pianist and listener-drummer agreement were broadly equivalent with the levels of pianist-drummer agreement given above: when values of the correlation coefficient $r$ were averaged across all duos, listener-pianist $mean(r) = .33$ ($SD = .39$, $\text{range} = [-.32, .72]$), listener-drummer $mean(r) = .40$ ($SD = .15$, $\text{range} = [.19, .56]$). Our musicians did not hold a privileged understanding of the success of their own performances \citep{Schober2014}: they agreed with listeners to an equivalent degree that they agreed with each other.

\section{Results}

\subsection{Baseline Measurements for Non-Delayed Performances}

\begin{figure}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/mp_network/figure_4.png}
  \caption{Baseline results. Number lines showing baseline values obtained for tempo slope, asynchrony, timing irregularity, performer- and listener-reported success, averaged for both repeats of the control condition by a duo. Note that performer-reported success values are randomly displaced horizontally for increased visual clarity and to prevent over-plotting.}
\label{fig:mp_baseline_results}
\end{figure}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s5}
  \caption{Performance tempo maps. Time is shown on the $x$-axis and tempo (in quarter-note beats per minute) on the $y$-axis for all 130 performances in the dataset, separated by ensemble (rows) and testbed configuration (columns). The gray dotted line in each plot shows the reference tempo (120 quarter notes per minute, four quarter notes per measure) provided to participants over headphones before each performance. The blue lines correspond with performances from the first session of the experiment, and the orange lines show performances from the second session. For visual clarity, each line shows a moving average of the performance tempo, obtained across a window of 8 seconds duration (four measures at the reference tempo).}
\label{fig:mp_performance_tempo_maps}
\end{figure}

In the following discussion, we outline the baseline results obtained from the control condition, when no latency or jitter was applied to the performance (Figure \ref{fig:mp_baseline_results}). The baseline mean tempo slope for all our duos during the control condition was 0.04 beats-per-minute-per-second (BPM/s) ($SD = 0.03$, $\text{range} = [-0.02, 0.10]$ BPM/s), indicating that the tempo of performances remained stable when no latency was present, though with a slight tendency towards acceleration. In Figure \ref{fig:mp_baseline_results} we compare these results with tempo slope coefficients obtained from previous networked performance studies, noting that the behavior of our duos did not differ from expected standards. In Figure \ref{fig:mp_performance_tempo_maps} we show individual “tempo map” plots for each performance.

The baseline mean asynchrony for our duos in the absence of latency and jitter was 33.1 ms ($SD = 7.2$, $\text{range} = [22.5, 48.8]$ ms), which we compare in Figure \ref{fig:mp_baseline_results} to prior studies of real-time ensemble performance across various musical genres. We note that this value is greater than the asynchrony observed in a prior study of jazz bass and drums synchronization \citep{Kilchenmann2015}, closer instead to the synchronization of Cuban salsa or North Indian raga musicians \citep{Clayton2020}. This may be because of the random placement of the control within each experimental session and participants’ overall lack of awareness of our manipulations, such that they could have been primed to adopt particular strategies in non-delayed performances as a result of earlier conditions where latency had been present. We refer to the comment of one pianist here, that it “felt slightly more difficult to coordinate, and to be creative” (pianist, duo 4) during the control in comparison to the previous condition they encountered. Another explanation is that the digital environment created by the testbed simply made it harder to play music together effectively versus the face-to-face, copresent conditions used in these reference studies, even without latency and jitter \citep{Doherty-sneddon1997}.

The baseline timing irregularity was 16.1 ms ($SD = 5.8$, $\text{range} = [7.9, 22.1]$ ms) for drummers and 26.4 ms ($SD = 4.5$, $\text{range} = [21.9, 36.7]$ ms) for pianists, which suggests significantly lower variability in the timing of drummers compared to pianists. Note that no participant demonstrated precise temporal isochrony: indeed, anisochronous timing has been theorized as aesthetically preferable over quantized isochrony in “groove-based” music such as jazz, due to the increased rhythmic interest it imparts (“participatory discrepancies”; see \citealp{Keil1987}).

The baseline mean performer-reported success score was 7.9 ($SD = 0.7$, $\text{range} = [7, 9]$) for drummers and 6.9 ($SD = 1.9$, $\text{range} = [2, 8]$) for pianists, suggesting that real-time performances were regarded as more successful than unsuccessful. Inter-participant agreement was typically higher in their evaluation of the control condition than in the remainder of the experiment, with an absolute difference between pianist and drummer scores of no more than 1 obtained for all control performances bar one.

The baseline mean listener-reported success score was 7.1 ($SD = 0.6$, $\text{range} = [6, 8]$) for the control condition; in Figure \ref{fig:mp_listener_results_distribution}, we demonstrate that there were no significant differences in mean listener score for performances in the control condition across any duo. These results again indicate that the non-delayed, real-time performances of all duos were consistently regarded as successful.

\subsubsection{Linear Associations Between Variables}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_5}
  \caption{Univariate and bivariate distributions. The histograms on each diagonal show the distribution of the variable plotted in that column/row. The scatter plots below the diagonal show the pair of variables obtained at the intersection of every column and row, with markers representing the score obtained by each duo for all thirteen conditions, averaged across instruments and sessions of the experiment. The straight red lines show a linear regression model fit between both variables, with error bars denoting 95\% confidence intervals generated via bootstrapping ($N = 10,000$ replicates). Likewise, values above the diagonal denote the coefficient of Pearson’s $r$ calculated between the corresponding variable pair, with the font size also indicating the strength of the correlation. Asterisks indicate the significance of the correlation coefficient, $^* \ p < .05, \ ^{**} \ p < .01, \ ^{***} \ p < .001$. Values for the tempo slope variable are given in their absolute (unsigned) form.}
\label{fig:mp_univariate_bivariate_distributions}
\end{figure}

In Figure \ref{fig:mp_univariate_bivariate_distributions}, we show the pairwise associations between the five performance success variables discussed above; to minimize overplotting, each datapoint on this graph corresponds with the response of one duo to a single condition, averaged across both sessions of the experiment. Note that this also means that the timing irregularity and performer-reported success variables are averaged over both members of a duo to ensure the number of values plotted remains consistent. Tempo slope is given in its absolute (unsigned) form to show the relationship between individual metrics and deviations from the reference tempo, regardless of whether this change had occurred via acceleration or deceleration.

We observe here that the three objective metrics derived from the extracted quarter-note beats (absolute tempo slope, asynchrony, and timing irregularity) were all negatively correlated with both reported success variables, such that performances that diverged from the reference tempo and displayed lower synchronicity and isochronicity were evaluated less favorably by participants and listeners. Additionally, tempo slope coefficient and timing irregularity were also positively correlated with each other, with a larger magnitude of tempo change associated with more unstable performances.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_6}
  \caption{Objective features affecting success evaluations. The panels show standardized regression coefficients ($\beta$) for a mixed-effects model predicting success ratings from musicians and naive listeners respectively. Error bars represent 95\% confidence intervals computed by bootstrapping with ($N = 10,000$ replicates). Where an error bar does not cross 0, the effect of that predictor is statistically significant. }
\label{fig:mp_objective_features_affecting_success}
\end{figure}

To further establish the relative importance of the different factors considered when evaluating a networked performance, we fitted a mixed-effects model to the dataset, predicting performer- and listener-rated success using a combination of absolute tempo slope, timing irregularity, and ensemble asynchrony (Figure \ref{fig:mp_objective_features_affecting_success}). A random effect (intercepts and slopes) of duo number was included in both models, as we wished to model group-specific variations in both the baseline rating and in the effects of the predictor variables. The statistical significance of the fixed effects was assessed by bootstrapping over duos ($N = 10,000$ replicates) to produce 95\% confidence intervals. For performers, an increase in timing irregularity was the strongest predictor of a decrease in subjective rating, although all three predictors were significant; for listeners, timing irregularity and asynchrony were both significant predictors of rating decreases (with asynchrony having the stronger effect), while tempo slope was not significant.

The amount of variance explained by both the fixed and random effects (conditional $R^2$) was .762 for the performer reports and .856 for the listener reports. The amount of variance explained by only the fixed effects (marginal $R^2$) was .483 for the performer reports and .735 for the listener reports. The standard deviation in scores estimated for the random effect of duo was .970 for the performer reports and .520 for the listener reports. These statistics indicated that the objective metrics effectively summarized the proximal causes of subjectively evaluated performance success; listeners cared most about whether performers remained stable and synchronized, but not whether they changed tempo, while musicians considered all three factors to be important.

\subsection{Network Latency Impairs Musical Performance}

To evaluate the effect of testbed configuration on the performance of each group, we fitted a separate linear model to the data obtained for each of our five duos, using each of our performance success variables as a response measure ($N = 25$ models total). Latency and jitter were included as predictors in every model and were treated categorically (with the control condition as the reference category), due to the possibility of non-monotonic effects. For models predicting timing irregularity and performer-reported success, where separate values had been obtained individually for both musicians in a duo, instrumental role was additionally included as a predictor (with the drummer’s performance used as the reference category). 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s6a}
  \caption{Reliability of performance success metrics. Each plot shows the test-retest reliability for every performance success metric by comparing values obtained from the first session of the experiment with those from the second. The straight black line corresponds with a simple linear regression, with confidence intervals obtained via bootstrapping ($N = 10,000$ replicates). Integer values corresponding to performer-rated success scores are jittered horizontally and vertically to reduce overplotting.}
\label{fig:mp_performance_success_reliability}
\end{figure}

We accounted for our repeated-measures design by averaging the results obtained from a duo for a particular condition across both sessions of the experiment. Values of Pearson’s $r$ obtained from the correlation of scores from both sessions of the experiment indicated good to excellent test-retest reliability for each metric (Figure \ref{fig:mp_performance_success_reliability}): for tempo slope, $r(63) = .66, \ p < .001$, for timing irregularity, $r(63) = .86, \ p < .001$, for asynchrony, $r(63) = .98, \ p < .001$, for performer-reported success, $r(63) = .67, \ p < .001$, and for listener-reported success, $r(63) = .78, \ p < .001$. 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s6b}
  \caption{Bias of performance success metrics. Each plot compares the difference in means for every performance success metric across experimental sessions. The $x$-axis shows the difference in means between sessions, such that a positive value corresponds to larger scores obtained in the second set of the conditions than the first. Error bars show 95\% confidence intervals obtained via bootstrapping ($N = 10,000$ replicates); where a bar does not cross the dotted line, the difference in means between sessions for that combination of performers and metric is significant at the $p < .05$ level.}
\label{fig:mp_performance_success_bias}
\end{figure}

In Figure \ref{fig:mp_performance_success_bias} we show bootstrapped confidence intervals for the difference in mean scores ($N = 10,000$ replicates) for each metric across both sessions. Barring duo 2 demonstrating a significantly greater mean tempo slope coefficient in the second session compared to the first (mean difference = 0.03, 95\% CI: $[0.02, 0.04]$), there were otherwise no significant differences in means. These analyses suggest that the behavior of each duo was consistent across both sessions of the experiment, validating our decision to average their scores.

The average $R_{adj}^2$ value for our models was .529 when predicting tempo slope ($SD = .529$, $\text{range} = [-.390, .884]$), .985 when predicting asynchrony ($SD = .009$, $\text{range} = [.973, .993]$), .908 when predicting timing irregularity ($SD = .051$, $\text{range} = [.842, .961]$), .717 when predicting performer-reported success ($SD = .175$, $\text{range} = [.407, .820]$), and .885 when predicting listener-reported success ($SD = .062$, $\text{range} = [.821, .971]$). We took this as an indication that testbed configuration and instrumental role alone were generally strong enough predictors to explain a large degree of the variance in each performance success metric, albeit with greater spread of $R_{adj}^2$ values obtained for some variables than others.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_7}
  \caption{Effects of testbed configuration on performance success variables. The bars show regression coefficients from models predicting one of the five performance success variables, with results split by duo. The reference category for each model corresponds to the performance during the control condition (i.e., with no latency or jitter); if values were obtained separately for each instrument for a given variable, the reference category also corresponds to the drummer’s performance. Crosses indicate where a particular predictor variable was omitted from that model. Error bars represent 95\% confidence intervals computed by the model; where an error bar does not cross 0, the effect of that category is statistically significant at the $p < .05$ level.}
\label{fig:mp_testbed_configuration_on_success}
\end{figure}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s7}
  \caption{Inferential statistics computed across all duos. The points show the mean value obtained for a given performance success metric averaged over all performances made using a particular latency or jitter condition. Error bars show 95\% confidence intervals, obtained via bootstrapping over duos ($N = 10,000$ replicates). Where two error bars do not cross, the difference between two latency or jitter values is statistically significant at the $p < .05$ level.}
\label{fig:mp_inferential_statistics_across_duos}
\end{figure}

Figure \ref{fig:mp_testbed_configuration_on_success} plots the coefficients and confidence intervals obtained for every predictor and categorical level in our models. The following discussion is organized to address in turn the effect of testbed configuration (latency and jitter) on indicators of overall performance success for each duo. Inferential statistics for each success metric across every latency and jitter value (averaged over all duos) are shown in Figure \ref{fig:mp_inferential_statistics_across_duos}.

\subsubsection{Effects of Latency} 

Increases in latency were strongly correlated with increases in ensemble asynchrony, $r(63) = .97, \ p < .001$, as would be expected. The effect of latency on the remaining metrics was more complex. The lowest amount of latency we tested, 23 ms, predicted significantly reduced ratings of performer-reported success for three duos, but no equivalent changes in any other metric. Above this value, latency had a detrimental effect on many performance features. Both 45 and 90 ms of latency produced significant decreases in tempo slope and increases in timing irregularity for two duos, alongside reductions in performer-reported success for all duos. For listener-reported success values, 45 ms of latency predicted significant decreases in ratings for two duos and 90 ms for all duos. These differences between performer- and listener-reported success at 45 ms latency could suggest a lower tolerance for latency exists when performing versus listening to music. In total, our results replicate many of the “classic” findings of prior networked performance studies, where latency typically contributes to a recursive slowing in the tempo of a performance and reductions in timing regularity and ensemble synchrony, alongside reductions in subjective assessments of performance quality \citep{Bartlette2006, Chafe2010, Monache2019, Rottondi2015}. 

Surprisingly, the maximum amount of latency we tested, 180 ms, was not associated with significant decreases in tempo slope coefficient for any duo, which contradicts the argument in \citet{Chafe2010} of a linear relationship between increases in delay time and decreases in tempo. Instead, this amount of latency was associated with positive (albeit nonsignificant) tempo slope coefficients for four out of five duos, suggesting that their tempo had either accelerated or remained stable. 

One possible cause of this phenomenon is that, at higher latency values, networked musicians operate more on ‘auto-pilot’, ignoring their partner and focusing solely on the stability of their own performance. We note in support of this suggestion that one drummer described the sensation of performing with 180 ms of latency as "being on parallel tracks" with their partner, "rather than being locked in together" (duo 2). If one musician in an ensemble exhibits an inherent tendency towards acceleration that may be constrained when they entrain with the other members of a group, this strategy could potentially lead to recursive increases in the tempo of their performance when this does not occur.

An alternate explanation is that, at extreme amounts of latency, a performer’s perspective of the relative phase of their partner’s meter with respect to their own could invert. At a tempo of 120 quarter notes per minute (or 500 ms per quarter-note interbeat interval), 180 ms of latency is relatively close to the duration of an eighth note, half of one quarter note (250 ms), and closer still to a triplet eighth note, one third of a quarter note (167 ms). Consequently, this amount of latency affords the potential for performers to instead perceive their partner as playing \emph{ahead} of the position of their next, upcoming beat, rather than hearing their partner as playing after their previous beat. This could lead to the recursive tempo acceleration we observed to occur in this condition, as both performers continually rush to catch up with their partner --- rather than deceleration, as they slow down to meet each other. 

The free-text responses given by participants after each performance attested to these effects of latency. Comments ranged both from acknowledging the changes in performance tempo (“to me it felt like a constant rallentando that kept failing to land”: drummer, duo 1, “there was a tendency to rush”: drummer, duo 3) and timing regularity (“when the time isn't settled I have a tendency to tense up”: drummer, duo 2) caused by latency, to annoyance at their inability to interact with their partner successfully (“frustrating to not be able to use body language effectively”: drummer, duo 1), and finally to a dislike of their performance in the testbed environment (“absolute carnage and I think it sounded utterly awful”: pianist, duo 1). Additionally worth noting here is the typically more positive tone used to describe performances made at 180 ms latency (“everything seemed to align this time”: pianist, duo 1, “we were on the same page with this one”: pianist, duo 3, “lots of creative energy”: pianist, duo 4) than lower values.

\subsubsection{Effects of Jitter}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s8}
  \caption{Model comparisons. This plot shows averages from five linear regression models predicting one of five performance success metrics, using the data from each duo individually. The $x$-axis shows the combination of predictor variables contained within each model. The $y$-axis corresponds with the amount of variance explained by the model predictors, using the average $R_{adj}^2$. Error bars in both plots show 95\% confidence intervals obtained via bootstrapping over all $R_{adj}^2$ values ($N = 10,000$ replicates).}
\label{fig:mp_model_comparisons}
\end{figure}

While a spike in network latency time caused by jitter inevitably causes large asynchronies in performances at a local scale, at a global scale the jitter conditions we tested had a much smaller impact on our performance success metrics than latency time alone. The presence of 1.0x jitter predicted significant increases in asynchrony for two duos, increases in timing irregularity for one duo, decreases in performer-reported success for one duo, and decreases in listener-reported success for two duos. The magnitude of these effects, however, was typically small in comparison to the other predictors included in each model. Removing jitter as a predictor resulted in little change to how well each model fit the data obtained for any variable or duo ($mean(\Delta R_{adj}^2) = 0.01$), in comparison to removing either latency ($mean(\Delta R_{adj}^2) = 0.69$) or instrumental role ($mean(\Delta R_{adj}^2) = 0.61$) (Figure \ref{fig:mp_model_comparisons}).

A complementary way to quantify the effect of jitter is to analyze whether moment-to-moment fluctuations in latency were followed by increased variability in performance timing. To do so, we measured the standard deviation of the quarter-note interbeat intervals played by a performer and the latency time applied by the testbed across a sliding window of four seconds duration. We then computed partial correlations between these two time series, with latency variability lagged at increasing one-second intervals between 0 and 8 seconds (or two bars at the reference tempo and meter). Any prior variation in a performers’ timing up to this lag was controlled for in the correlation, to account for the probability that subsequent quarter-note beat durations in jazz performance may display autocorrelation with previous values \citep{Cheston2022}. Put differently, when computing the partial correlation between timing variability $t$ and latency variability $d$ at lag $k$ seconds, we controlled for prior timing variability at all lags up to and including lag $k$, except for when $k = 0$ (in which case the correlation coefficient used was Pearson’s $r$, with no controls). 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s9}
  \caption{Partial correlation plots. Each column of plots corresponds to one of the three jitter scalings tested in the experiment. The $x$-axis shows the degree of lag in seconds that was applied to rolling measurements of the standard deviation of the latency time series used in the performance (see Figure \ref{fig:mp_experimental_conditions}, right column) and to prior inter-beat interval variance. The $y$-axis shows values of the coefficient $r$ averaged across all performances in the dataset, irrespective of duo or instrument. Error bars show 95\% confidence intervals of $r$ obtained by bootstrapping ($N = 10,000$ replicates).}
\label{fig:mp_partial_correlations}
\end{figure}

We calculated these partial correlations separately for all performances made using the three jitter values tested in the experiment, regardless of minimum latency time (Figure \ref{fig:mp_partial_correlations}): note that minimum delay and delay variability were independent of each other (see Figure \ref{fig:mp_experimental_conditions}, right column). We observed that, when the 1.0x jitter scaling was used, previous variation in network latency was positively correlated with future variation in performance timing. The strongest association between prior increases (or spikes) in latency and future increases in timing variability occurred at a lag of two seconds: averaged across performances by all musicians made with 1.0x jitter, $mean(r) = .11$ (95\% CI: $[.08, .14]$, obtained via bootstrapping across all obtained values of $r$ with $N = 10,000$ replicates).

However, the small magnitude of this correlation suggests that jitter only had a slight impact on performance stability, and the musicians’ own comments validate this claim. While they were evidently aware of its presence (“moments of ride cymbal jolting”: pianist, duo 4, “I noticed the [video] fluctuating”: pianist, duo 5), participants were able to develop strategies to accommodate jitter. These included inserting or removing beats from the underlying meter (“there were several points where we were suddenly playing on different beats to each other but it was easy to add/drop a beat to come back in time”: drummer, duo 3), cultivating a deeper sense of rhythmic intensity in the performance (“subtle disruptions in the feed were subsumed within the strength of our interaction/groove”: pianist, duo 4), and looking at the video feed (“eye contact and watching the fingers on the [piano] keys helped”: drummer, duo 3). Indeed, one participant even claimed that the disruption caused by jitter had had a positive effect (“disruptions through the feed, but these helped with the flow of the music,” “... we were able to use [the disruptions] to interact consistently and vibrantly”: pianist, duo 4).

\subsubsection{Effects of Instrumental Role}

Instrumental role significantly predicted differences in timing irregularity for four of five duos, with pianists showing increased variability in beat duration compared to drummers, and changes in performer-reported success for all duos, with pianists associated with higher ratings in three duos and lower ratings in the remaining two. In the case of timing irregularity, pianists may have been less comfortable with the networked conditions (or the procedures of the experiment) than drummers, or alternatively had adopted a role in their ensemble that enabled them to perform with increasingly flexible timing. In the case of performer-reported success, it is not uncommon for musicians to develop very different understandings of the same performance \citep{Schober2014}; alternatively, these differences could also imply differences in the roles adopted by pianist and drummer.

Removing instrumental role as a predictor of both timing irregularity and performer-reported success resulted in a substantial effect on $R_{adj}^2$ when compared to the full model, while removing the testbed condition (both latency and jitter) had altogether less of an impact on the amount of variance explained when predicting these variables (Figure \ref{fig:mp_model_comparisons}). This implied that between-participant variability contributed more to these measures than testbed configuration.

\subsection{Musical Ensembles Adopt Diverse Coordination Strategies During Networked Performance}

The members of any musical ensemble coordinate via complex, distributed processes of mutual attending and adaptation \citep{Clayton2020, Jacoby2021, Timmers2014, Wing2014}, which may be referred to by jazz musicians as “hooking up,” “grooving,” and “swinging” \citep{Berliner1994, Monache2019}. For a group of musicians to remain synchronized, they must adapt to any small deviations from isochrony in each other’s performances. When one musician adapts to match variation in another’s performance, we can say that they are influenced by—or “coupled with”—that musician; vice-versa, the absence of coupling implies that one musician does not correct for variability in another’s performance, and is thus not influenced by them \citep{Jacoby2021, Konvalinka2010}. 

In the context of networked music-making, the perception of timing variability in a performance will be affected by any network instability or jitter present in the output signal: a musician does not, therefore, couple with the real-time performance of their partner, but with the delayed feedback they receive from the network. We begin this section by describing the linear phase correction model we employed to model this process, alongside a series of control analyses we conducted to validate it. We then describe the results from applying these models to the performances in our dataset, including evidence suggesting the presence of two distinct coordination strategies employed by the duos who participated in our experiment.

\subsubsection{Phase Correction Modeling}

We model the coordination in a networked ensemble using a process of linear phase correction \citep{Vorberg1996}, where a performer’s upcoming quarter-note interbeat interval is predicted from both the duration of their prior interbeat interval and the asynchrony with their partner at the previous quarter note beat \citep{Jacoby2021}. We consider the particular coordination strategy adopted by a networked ensemble to be equivalent to the complete system of coupling responses established between every pairwise combination of musicians in an ensemble, and hence we create a separate model for each performer in a duo.

\begin{figure}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/mp_network/figure_8.png}
  \caption{Measured coupling between the musicians in each duo. (a) is a schematic diagram of the linear phase correction model. Quarter-note beats are given by colored circles: the circles with dashed borders show the position of beats after latency has been applied, representing when they would have actually been heard by a performer. The vertical gray rectangles indicate the metric grid of quarter notes, while horizontal and diagonal black lines show the interbeat interval between quarter notes, either from one performer or between performers. The braces indicate the difference between successive interbeat intervals played by the same musician. (b) depicts the mean coupling coefficient obtained for each participant. (c) shows the mean coupling strength and asymmetry across each duo. Error bars in both (b) and (c) show 95\% confidence intervals of the mean obtained via bootstrapping ($N = 10,000$ replicates). (d) groups the duos by their respective coordination strategy, with the direction and degree of the coupling in each duo given by the color and thickness of the arrows respectively. Values above each arrow show the mean coupling coefficient, with parentheses indicating standard deviations. Duos are ordered, left-to-right, by average coupling asymmetry across all conditions.}
\label{fig:mp_coupling_model}
\end{figure}

We refer to a single performance by a duo in our dataset as $K$, which can be described as two separate time series comprising sequences of quarter note beat positions $t$ contributed by two musicians, $i$ and $j$. Beat onset positions are measured in seconds from the start of performance, meaning that the performance of performer $i$ in dataset $K$ is given by the sequence 
\begin{align}
K_i = \biggl(t_k^i\biggr)_{k=1}^N,
\end{align}
where $N$ is the index of the final beat in $K$ and $t_1^i > 0$.

For each performer, we then obtain the sequence of interbeat intervals $T$, equivalent to the duration of each quarter note beat that they played. The sequence of interbeat intervals by performer $i$ is thus written as 
\begin{align}\label{eq:mp_model_timeseries}
\biggl(T^{i,i}_k\biggr)^N_{k=2} &= \biggl(t^i_k - t^i_{k-1}\biggr)^N_{k=2}. 
\end{align}

Note that if the tempo of a performance changes over time, then the mean and variance of $\biggl(T^{i,i}_k\biggr)^N_{k=2}$ will change too, with individual quarter note interbeat intervals $T^{i,i}$ trending towards smaller or larger values as {k} increases. To remove any such pattern or trend, we transform the time series in equation \ref{eq:mp_model_timeseries} by taking the signed first difference of interbeat intervals $T'$, equivalent to the difference in duration of successive quarter notes $T$. This creates the detrended time series 
\begin{align}
\biggl(T'^{i,i}_k\biggr)^N_{k=3} &= \biggl(T^{i,i}_k - T^{i,i}_{k-1}\biggr)^N_{k=3},
\end{align}
which is equivalent to
\begin{align}
\biggl(T'^{i,i}_k\biggr)^N_{k=3} &= \biggl((t^i_k - t^i_{k-1}) - (t^i_{k-1} - t^i_{k-2})\biggr)^N_{k=3}.
\end{align}

We then use a nearest neighbor algorithm to match every quarter note beat $t_k$ played by performer $i$ with the temporally closest beat played by their partner $j$. From these matched beats we compute the ‘actual’ beat asynchronies of performer $j$ from the perspective of performer $i$ as 
\begin{align}
\biggl(T_k^{i,j}\biggr)_{k=1}^N &= \biggl(t_k^i - t_k^j\biggl)_{k=1}^N. 
\end{align}

We then compute the ‘perceived’ beat asynchronies of performer $j$ from the perspective of performer $i$ as 
\begin{align}
\biggl(T'^{i,j}_k\biggr)_{k=1}^N &= \biggl(t_k^i - t_k^j + d^j_k\biggl)_{k=1}^N,
\end{align}
where $d'^j_k$ is the amount of delay applied by the testbed at the point when musician $j$ played beat $k$, and $d'^j_k>0$ for all possible values of k and in all experimental conditions, apart from the control.

We can now write the complete linear phase correction model as 
\begin{align}\label{eq:mp_phase_correction_model}
T'^{i,i}_{k+1} &= \alpha_{i,i} T'^{i,i}_k + \alpha_{i,j} (T^{i,j}_k+d'^j_k) + \alpha_{i,0} + \varepsilon^i_k. 
\end{align}
As stated above, $T'^{i,i}_{k+1}$ is the difference between the durations of the quarter notes by musician $i$ at beats $k+1$ and $k$, $T'^{i,i}_k$ is the difference between the durations of the two quarter note inter-beat intervals directly preceding $T'^{i,i}_{k+1}$ by musician $i$ (i.e. at beats $k$ and $k-1$), $T^{i,j}_k$ is the asynchrony between musicians $i$ and $j$ at beat $k$, $d'^j_k$ is the variable delay applied to musician $j$’s performance by the testbed at beat $k$, $\alpha_{i,i}$ is the influence of the previous inter-beat interval difference by musician $i$ on the duration of $i$’s future quarter notes, $\alpha_{i,j}$ is the coupling coefficient reflecting the influence of musician $j$ on future quarter note durations by their partner $i$, $\alpha_{i,0}$ is an intercept term specific to musician $i$, and $\varepsilon^i_k$ is residual noise.

Note that the perspectives of $i$ and $j$ in $K$ are modeled separately; so, rewriting equation \ref{eq:mp_phase_correction_model} to predict the performance of $j$,
\begin{align}\label{eq:mp_phase_correction_model_alt}
T'^{j,j}_{k+1} &= \alpha_{j,j} T'^{j,j}_k + \alpha_{j,i} (T^{j,i}_k+d'^i_k) + \alpha_{j,0} + \varepsilon^j_k. 
\end{align}

\subsubsection{Control Analyses}

The average $R_{adj}^2$ for our model was .487 ($SD = .128$, $\text{range} = [.094, .742]$), meaning that it typically captured about half of the total variability in differenced inter-beat interval durations during a performance. We further verified the robustness of our model by conducting a series of four control analyses that evaluated both the consistency and reliability of coupling as a measure of synchronization behavior and phase correction itself as a model of coupling.

Our first control analysis investigated the reliability of coupling across the experiment by computing Pearson’s $r$ between coupling coefficients obtained from the first and second session of the experiment. We found a strong positive correlation between coupling observed in both sessions, $r(63) = .81, \ p < .001$, suggesting that the synchronization behaviors deployed by our participants were consistent and reliable across the experiment.

Our second control analysis ran complementary to our first and investigated the internal consistency of coupling within a single performance by computing Pearson’s $r$ across coefficients obtained from the first and second 45-second halves of each performance. Although not as strong as the correlation between coupling in both experimental sessions, we again found a positive correlation between coupling in the first and second half of a performance, $r(128) = .67, \ p < .001$. Nonetheless, given the relatively small magnitude of this difference, we still consider coupling to be internally consistent within a typical performance by our duos.

Our third control analysis evaluated the performance of our initial phase-correction models in comparison to higher-order linear models that consider a longer past history of beats. With respect to the phase-correction model defined in equation \ref{eq:mp_phase_correction_model}, we define a further higher-order phase correction model that includes information from the previous $M + 1$ differenced interbeat intervals and asynchronies as
\begin{align}\label{eq:mp_higher_order_phase_correction_model}
T'^{i,i}_{k+1} &= \sum^M_{m=0}\biggl(\alpha_{i,i} T'^{i,i}_{k-m} + \alpha_{i,j} (T^{i,j}_{k-m}+d'^j_{k-m})\biggr) + \alpha_{i,0} + \varepsilon^i_k,
\end{align}
where $\alpha_{i,i} T'^{i,i}_{k-m}$ is the influence of previous differenced interbeat interval durations at beat position $k - m$ on future durations for the same musician $i$ and $\alpha_{i,j} (T^{i,j}_{k-m}+d'^j_{k-m})$ is the coupling coefficient between musicians $i$ and $j$ at beat $k - m$ with delay $d'$ applied to $j$.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s10c}
  \caption{Higher-order model results. Each panel shows evaluation metrics obtained for models with different orders, with $M = 0$ equivalent to the model used in the analysis here. Error bars show 95\% confidence intervals obtained by bootstrapping across duos ($N = 10,000$ replicates)}
\label{fig:mp_higher_order_evaluation}
\end{figure}

In Figure \ref{fig:mp_higher_order_evaluation}, we compare our initial phase-correction model (i.e. where $M = 0$) with three higher-order models where $M\in\{1, 2, 3\}$, such that future interbeat interval durations are now predicted from values obtained up to one measure before. These models were applied to every individual performance in the dataset, with values of $R_{adj}^2$, Akaike information criteria (\GLS{AIC}), and Bayesian information criteria (\GLS{BIC}) used to evaluate their performance.

While increased values of $M$ do result in improvements to $R_{adj}^2$ over our initial model, these improvements are minimal, with only 10\% more variation in the target variable $T'^{i,i}_{k+1}$ explained when $M = 3$ compared to $M = 0$. Furthermore, no significant improvements in \GLS{AIC} or \GLS{BIC} were observed in the higher-order models when compared to our initial model. We took this as an indication that the higher-order models did not perform substantially better than our initial model, and thus that values of $M = 0$ were acceptable when predicting future interbeat interval variation in our dataset.

Our fourth and final control analysis involved the generation of simulated musical performances. We fitted the models in equations \ref{eq:mp_phase_correction_model} and \ref{eq:mp_phase_correction_model_alt} separately to each individual recording in the dataset and averaged the coupling coefficients obtained from each of our thirteen conditions across performers and the two sessions of the experiment. We then ran 500 simulations per condition and duo combination, where artificial interbeat intervals for two performers were created by recursively applying the model. The noise term $\varepsilon^{sim(i)}$ was randomized for each successive interbeat interval duration at position $k$ from a Gaussian distribution, such that $\varepsilon^{sim(i)}_k\sim \mathcal{N}(0,\, \varepsilon^i_k)$. This independent noise was added to simulate motor variance and ensure that every simulation was a stochastic process.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s10d}
  \caption{Control simulation results. Both panels compare (respectively) tempo slope coefficients and ensemble asynchrony values obtained from the performances in our dataset ($y$-axis) with simulations based on the ensemble coupling present within them ($x$-axis).}
\label{fig:mp_control_simulation_results}
\end{figure}

We then extracted the median simulated tempo slope coefficient and ensemble asynchrony value for each condition and duo pair. Timing irregularity was not used in this comparison as it would be collinear with the amount of noise applied to each interbeat interval. Both simulated and observed tempo slope coefficients were strongly correlated, $r(63) = .89, \ p < .001$, as were simulated and observed asynchrony values $r(63) = .96, \ p < .001$ (Figure \ref{fig:mp_control_simulation_results}). This suggests that our model adequately predicted the effects that ensemble interaction strategies had on our networked performances.

In summary, our control analyses indicated that our model had adequately captured both the rhythmic adaptation present within each duo and the effect that this had had on their networked performance and, indeed, that coupling was a robust and internally consistent measurement of ensemble coordination.

\subsubsection{Coupling Responses}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s11a}
  \caption{Distribution of observed coupling responses. Each panel shows the distribution of the different coefficients obtained for every term in the model, with color indicating instrument.}
\label{fig:mp_coupling_responses_distribution}
\end{figure}

Figure \ref{fig:mp_coupling_responses_distribution} plots distributions and kernel density estimates of the self-coupling coefficients $\alpha_{i,i}$, partner-coupling coefficients $\alpha_{i,j}$, and intercept terms $\alpha_{i,0}$ obtained from all performances in the dataset. Consistent with previous studies employing similar models \citep{Jacoby2021}, all observed values of the coupling coefficient $\alpha_{i,j}$ were positive ($mean(\alpha_{i,j}) = 0.474, \ SD = 0.299, \ \text{range} = [0.015, 1.215]$), suggesting that participants had coupled to their partner to some degree in every performance. Figure \ref{fig:mp_coupling_model}b shows the average coupling of each participant to their partner.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s11c}
  \caption{Difference in mean performer coupling coefficients. Each panel shows mean differences in self- and partner-coupling between both musicians within the same duo. Error bars show 95\% confidence intervals obtained via bootstrapping ($N = 10,000$ replicates). Where a bar does not cross the dotted line, the difference in means between those performers is significant at the $p < .05$ level.}
\label{fig:mp_coupling_mean_differences}
\end{figure}

To compare the relative influence of both musicians, we obtained bootstrapped confidence intervals ($N = 10,000$ replicates) for the mean difference between pianist-drummer and drummer-pianist coupling coefficients in each of our duos (Figure \ref{fig:mp_coupling_mean_differences}). For 4 out of the 5 duos, the drummer had exerted significantly more influence on the pianist than the pianist had exerted on the drummer, with duo 1 being the only group where neither musician had emerged as significantly more influential than their partner (mean difference in coupling, duo 1 $= -0.01$, 95\% CI: $[-0.08, 0.05]$). 

With regards to these differences in coupling between instruments, we refer to the comment in \citet[p. 990]{Chafe2010} that, during a networked performance, “the weaker side (in terms of rhythmic function) naturally follows the strong one”; Chafe’s example of a guitarist following a drummer in a networked performance bears resemblance to the pianists in our duos, who typically followed their drummer partners.

\subsubsection{Coordination Strategies}

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s11d}
  \caption{Pairwise differences in coupling between duos. Each line shows mean differences in coupling strength and asymmetry between different pairs of duos. Error bars show 95\% confidence intervals obtained via bootstrapping ($N = 10,000$ replicates). Where a bar does not cross the dotted line, the difference in means between those duos is significant at the $p < .05$ level.}
\label{fig:mp_duo_coupling_mean_differences}
\end{figure}

We evaluated the coordination strategy employed by each ensemble by considering the strength (or “gain”) and asymmetry of their coupling, equivalent to 
\begin{equation}
    \begin{split}
    \text{Coupling Strength} = \alpha_{i,j} + \alpha_{j,i} \\
    \text{Coupling Asymmetry} = \left|\alpha_{i,j} - \alpha_{j,i} \right|
    \end{split}
\end{equation}
when considering values of $\alpha_{i,j}$ and $\alpha_{j,i}$ extracted from a single performance. 

We show the average coupling strength and asymmetry for each duo in Figure \ref{fig:mp_coupling_model}c, and in Figure \ref{fig:mp_duo_coupling_mean_differences} we present confidence intervals for the differences in mean coupling strength and asymmetry calculated across all independent pairwise combinations of duos (10 combinations total). No correlation was found between coupling strength and asymmetry, $r(128) = .13, \ p = .14$.

The members of duo 3 exhibited the strongest ensemble coupling out of all the groups studied, with a mean coupling strength of $1.10$ ($SD = 0.24$, $\text{range} = [0.56, 1.47]$). Significant differences in mean coupling strength were found between this duo and all other groups apart from duo 4 (difference in mean coupling strength, duo 3/4 $= -0.05$, 95\% CI: $[-0.14, 0.05]$). Duo 1 displayed the weakest coupling overall, with a mean coupling strength of $0.84$ ($SD = 0.28$, $\text{range} = [0.27, 1.35]$). All in all, however, coupling strength did not differ to a particularly large extent between the duos, with the average sum of coupling coefficients falling within the range suggested by \citet{Vorberg2005} to be required for a stable performance by two musicians.

Coupling asymmetry varied more across the duos and indicated the presence of two distinct coordination strategies. The coupling within duo 1 was the most symmetrical of all groups studied, with a mean coupling asymmetry of $0.14$ ($SD = 0.09$, $\text{range} = [0.00, 0.30]$), indicating that the distribution of error correction was almost entirely equal between pianist and drummer. No significant differences were observed between the mean coupling asymmetry of this group and duo 3 ($0.06$, 95\% CI: $[-0.01, 0.12]$; see also Figure \ref{fig:mp_coupling_model}c). Thus, and despite the drummer of this latter duo emerging as more influential than the pianist, we consider both duos 1 and 3 to best embody the same coordination strategy—that of egalitarianism or “democracy” \citep{Wing2014}, where both musicians had adapted to each other at equivalent (or near-equivalent) levels, such that neither could be said to clearly and definitively occupy a leadership role in the ensemble.

The self-reports from participants in these two groups reinforced our labeling of their interaction as democratic, involving attempts to maintain the reciprocal co-adaptation in timing typical of interpersonal action coordination \citep{Nowicki2013}. References were continually made by these participants to an inability to choose whether or not to lead the performance or follow their partner (“difficult to decide whether to plow on at correct speed when things go awry or to try and match [the pianist]”: drummer, duo 1) and, even when such a decision was made, they were not necessarily able to manifest this in their performance (“this time I tried to resist and keep the initial tempo but it didn’t work,” “... tried to lead tempo again but gave up”: pianist, duo 3). This occasionally contributed to situations where both participants directly disagreed as to who was attempting to lead the other, as seen in two remarks made about the same performance by duo 3: “felt like [the drummer] was following my tempo this time” (pianist), “I had to play a beat ahead of [the pianist]” (drummer). The overall sense amongst these groups was one of confusion about how best they should coordinate with their partner, leading to performances that felt more “like a battle of wills” (drummer, duo 1) than truly interactive.

Coupling in the remaining three duos was less balanced, with duos 2, 4, and 5 all displaying significantly greater coupling asynchrony than both duos 1 and 3 (see Figures \ref{fig:mp_coupling_model}, \ref{fig:mp_duo_coupling_mean_differences}). We therefore considered these three duos to instead embody a “leadership” coordination strategy, where one musician had adapted significantly less to their partner than their partner had adapted to them \citep{Goebl2009, Konvalinka2010}. As noted previously, it was the drummer in all three duos who emerged clearly as the leader here, with the pianist thereby acting as the follower. Duo 2 exhibited the most unbalanced coupling overall, with a mean coupling asymmetry of $0.73$ ($SD = 0.21$, $\text{range} = [0.28, 1.19]$): these performers thus established the strongest leadership dynamic of all the groups we studied. There were no significant differences in mean coupling asymmetry between the remaining two leadership groups, duos 4 and 5 ($0.06$, 95\% CI: $[-0.01, 0.14]$).

Although fewer self-reports were provided by the participants in these three duos than those in the democracy groups, they were nonetheless revealing in demonstrating an awareness of the leader-follower relationship that they had established. One drummer made direct reference to this strategy, describing how they had ignored their partner while their partner had followed and adapted to them: “I worked out where I had to play in relation to [the pianist]. It seemed that it appeared to [the pianist that] we were playing in sync, however I displaced my beat by one triplet quaver against the pulse I got from [them]” (drummer, duo 4). We also note here that the performers in the three leadership duos demonstrated substantially greater disagreement in their reported success scores than the musicians in the two democracy duos, as demonstrated by lower values of Pearson’s $r$ (Figure \ref{fig:mp_performer_questionnaire_test_retest}). This again supports our claim that a divergence in ensemble role took place for the musicians in these groups that did not occur in the two democracy duos.

In Figure \ref{fig:mp_coupling_model}d, we visually depict the coupling networks established by all five duos and group them under either “democracy” or “leadership” headings.

\subsection{Simulations Demonstrate Trade-Offs in Coordination Strategies Used in Networked Performances}

Evidence for democratic and leadership coupling between performers can be found throughout the literature on musical performance \citep{Goebl2009, Jacoby2021, Timmers2014, Wing2014}. The coordination strategy adopted in any ensemble likely depends on the appropriateness of this strategy for their performance situation and the style of music they play. For instance, mutual co-adaptation (“democracy”) was found to be more effective in coordinating temporal alignment during real-time, face-to-face jazz improvisation by duos than in non-contingent, asynchronous “overdubbed” performances \citep{Setzler2020}. Beyond jazz, “leadership” coordination has been observed in Classical string quartets, where artistic leadership has typically been attributed to the first violin, with the remaining instruments taking up other roles \citep{Timmers2014}. Finally, studies of West African drum ensembles have found that rhythmic adaptation was distributed asymmetrically across performers and reflected their social organization \citep{Jacoby2021}.

We were interested in establishing whether our duos had chosen to employ a particular coordination strategy because it offered them an advantage in achieving a particular aesthetic or musical outcome in their performance: for example, enabling tighter synchronization with their partner or reducing the overall magnitude of any tempo change. We accomplished this by modeling a series of simulated networked performances in which the coupling patterns between musicians were systematically manipulated yet were otherwise derived from actual performance data obtained from each of our thirteen experimental conditions. Conducting simulations allowed us to have complete control over the coupling between musicians in a way that would not be possible when working with results from the dataset directly. This assisted in interrogating the specific effects of coupling on the objective factors shown to predict subjective evaluations of performance success in Figure \ref{fig:mp_objective_features_affecting_success}. In addition, simulations also enabled us to explore alternative coordination strategies that were not displayed by any of the duos in the experiment.

We compared the following simulations across each of the thirteen conditions tested in the experiment: (1) a “democracy” coordination strategy, in which the coupling coefficients for both simulated performers were set equal to the average of all coupling responses obtained for one condition; (2) a “leadership” coordination strategy, in which the simulated pianist was coupled to the drummer to a degree equivalent with the mean pianist-drummer coupling observed for one condition, while drummer-pianist coupling was set to zero; and (3) a baseline “anarchy” coordination strategy --- not followed by any duo in the experiment --- in which each simulated musician acted independently of the other with all coupling coefficients set to zero. 

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_9}
  \caption{Simulation results. The bar plots compare tempo slope, timing irregularity, and asynchrony across simulated coordination strategies: each point shows the median value obtained from 500 individual simulations for one condition in the experiment, with the height of each bar representing the overall mean for that strategy across all conditions. Condition type is given by marker size, shape, and color, with red square markers showing results from control simulations, with no latency applied.}
\label{fig:mp_simulation_results_barplot}
\end{figure}

To ensure consistency across simulations, self-coupling coefficients $\alpha_{i,i}$ were all set to the mean observed for that experimental condition, intercept terms $\alpha_{i,0}$ were set to 0, and the error term $\varepsilon^i_k$ was set to 5 ms, found to add sufficient noise to artificial interbeat intervals without adversely affecting the stability of the simulation. Five hundred individual simulations were conducted for every experimental condition across each of the parameters given above (1,500 simulations per condition, 19,500 simulations total), with tempo slope, ensemble asynchrony, and timing irregularity selected as the criteria for comparing between simulations: earlier in Figure \ref{fig:mp_objective_features_affecting_success}, we described how increases in these factors were predictive of comparable decreases in subjective ratings provided by both musicians and listeners. In Figure \ref{fig:mp_simulation_results_barplot}, we plot the median values obtained for these criteria across simulations conducted for each condition.

The coordination strategies we tested reveal the trade-off between minimizing both tempo drift and ensemble asynchrony when optimizing coordination in networked performance. Democracy was the best strategy for maximizing ensemble synchronization; however, simulations made using this strategy quickly slowed down and became increasingly unstable, as both simulated musicians matched their performance to each other’s delays. Leadership, on the other hand, was the best strategy for minimizing tempo drift; however, simulations made using this strategy displayed substantially lower synchrony than democracy. Finally, while anarchy did lead to regular timing and no global drift in tempo, this came at the expense of unacceptable asynchrony between musicians, who became several seconds out-of-time by the end of the simulation as a result of no adaptation between them.

The simulated performances made under the control conditions were the exceptions to the above analysis as, when no latency was applied, both democracy and leadership achieved similar results across all comparison criteria. This indicates that the use of either strategy can be considered optimal within real-time, non-delayed jazz performance, where the capacity of a musician to perceive their partner’s performance would not normally be impeded. This may also explain why no duo displayed coordination equivalent to our anarchy coordination strategy in the actual experiment, as following this strategy in a “normal” performance still led to massive asynchronies. 

Ultimately, in a networked performance environment, our simulations indicate that it is not possible for an ensemble to find a coordination strategy that achieves both maximum synchronization between the performers and a minimum of global tempo drift. These two parameters exist on opposite sides of a trade-off; a choice must be made to optimize in favor of one feature, with performances suffering in other aspects.

\begin{figure}[]
  \centering
  \includesvg[width=1.0\textwidth]{figures/mp_network/figure_s12}
  \caption{Simulation results. Each plot depicts simulated asynchrony values and tempo slope coefficients obtained from a single condition. Rows correspond to latency and columns to jitter: duo number and coordination strategy are delineated by the style and color of the marker.}
\label{fig:mp_simulation_results}
\end{figure}

Finally, in Figure \ref{fig:mp_simulation_results} we compare the median tempo slope and asynchrony values obtained from 500 simulations conducted using the coordination strategies described above with the same number of simulations using the coupling patterns displayed by the duos studied in our experiment (discussed earlier with relation to our control analyses: see Figure \ref{fig:mp_control_simulation_results}).

The results confirm our assumption that networked performance cannot be optimized fully —-- no duo achieved minimal asynchrony without also slowing down, for instance. They also validate our description of the coordination strategy employed by each duo as either democratic or leadership-based, insofar as results from simulations using the coupling established by each duo best approximated those obtained from the strategy they were claimed to follow in Figure \ref{fig:mp_coupling_model}d.

\section{Discussion}

The purpose of this chapter was to model the possible methods that can be used to coordinate spontaneous jazz improvisation. We collected data from five duos of jazz pianists and drummers improvising music together, using variable network latency (applied via a novel testbed) as a means to probe their performance strategies. We identified two coordination strategies from the linear modeling of rhythmic adaptation in their performances. A leadership strategy, where one participant adapted to their partner but the other did not, resulted in a stable tempo but high asynchrony between the performers; a democratic strategy, where both participants adapted to each other at equivalent rates, achieved less asynchrony at the expense of tempo drift. Analysis of subjective performance evaluations indicated that high levels of tempo change and asynchrony were both associated with worse evaluations, as provided by the musicians themselves and a sample of naive listeners blind to the networked conditions.

Our findings demonstrate how remoteness presents new complexities and challenges to successful interaction. While both leadership and democratic coordination can demonstrably achieve good results in real-time performances \citep{Wing2014}, neither strategy can be considered optimal when network latency is present. Rather, ensembles must prioritize either maintaining a steady tempo or achieving low levels of asynchrony in their performance and coordinate their joint action in a manner contingent with achieving that goal. 

Our results also highlight the musical qualities that different ensembles value when they perform together, as the participants in our experiment were told only that they should interact with their partner as they would in a “real” performance. One drummer who established mutual co-adaptation (democracy) with their partner described how “plowing on at right tempo didn’t really seem like an option,” as “cohesiveness [was] prob[ably] more important than tempo accuracy”; their performances “sound[ed] better when we slow down to meet each other,” and this even enabled “quite a fun heavy groove when we got the hang of it” (drummer, duo 1). Tempo change was not inherently undesirable, for this ensemble at least, so long as it enhanced synchronization and afforded new possibilities for musical creativity.

Our results demonstrate how the strategies used to coordinate joint action in an ensemble can reflect genre-specific demands in music performance. Across all of the three remaining duos who established asymmetric (leadership) adaptation, it was the drummer who emerged as the most influential performer. This instrument typically has responsibility for maintaining musical time in any jazz ensemble \citep{Monson1996}; when latency is present it disrupts this sense of shared time, so it is perhaps unsurprising that the drummer assumed the role of leader and the pianist yielded this to them. These roles were allocated implicitly and without discussion in all three groups: so, in one sense, the asymmetric relationships they adopted were still “democratic,” insofar as the individual roles adopted by each performer were consensually (albeit tacitly) allocated in accordance with genre-specific norms and the demands of the performance context.

Similar concerns to those involved in networked musical performance are at play whenever spoken conversations are coordinated over teleconferencing platforms. Temporal periodicity acts as a pragmatic resource to enhance communication \citep{Rothermich2012} in speech and to facilitate coordination in both spontaneous musical and speech interaction \citep{Pfander2019, Robledo2021}. Musicians improvise simultaneously with each other and coordination becomes a continuous, mutual process; while temporal coordination in much of speech interaction concerns organization of turn transitions between participants in a conversation \citep{Cech2004}, it is also evident in the timing of backchannel (interjections and gestures provided by the non-floor holder) in relation to the ongoing flow of the floor-holding speaker's turn \citep{Benus2011, Noguchi2000}. 

These temporal features are less likely to be reliably accessible as communicative and pragmatic cues in remote contexts than in face-to-face contexts, often leading to large increases in turn transition time \citep{Boland2022} and decreasing the effectiveness of backchannel \citep{Fox-tree2021}. To prevent this, groups engaged in teleconferencing can adopt asymmetric roles. This may involve one individual acting as a moderator, leading the conversation by speaking confidently, intervening in discussions, and also by selectively muting and unmuting the microphones of other speakers to facilitate smoother turn transitions. This suggests that “leadership” is likely to be an effective strategy in coordinating timings in transactional or task-oriented communicative interactions.

Our results have clear practical implications for the future development of network platforms used for musical performances. It would be feasible for a platform to apply our model in real-time and use this to provide feedback to musicians about predicted changes in their tempo and synchronization levels during a remote performance. This could consist of alerts when their mode of playing together may cause them to decelerate or drift out of time with each other (depending, perhaps, on pre-defined rules), similar to the warning messages currently implemented for unstable internet connections. We suggest that this feature could potentially improve user retention, as prior research has shown that encountering the negative effects of latency can impact willingness to participate in future remote performance \citep{Chew2005, Driessen2011}.

One limitation of this study concerns sample size. Recruiting professional musicians for experimental research involves an additional financial burden over recruiting amateurs, leading to smaller sample sizes and issues with statistical power. Developing proficiency in musical improvisation, however, takes many years of dedicated training \citep{Berliner1994}, meaning that the optimal way to research improvisation will always involve the recruitment of highly skilled practitioners, whose performances can then be isolated in an experimental environment. Corpus analyses of interaction in existing recordings would, however, provide a complementary perspective on the dynamics we model here and may be a direction for future research to explore.

A second limitation concerns our choice not to include a bassist in our participant-groups, as this instrument is typically included in the jazz rhythm section alongside piano and drums. As a non-fretted stringed instrument, accurately converting the performance of a double bass to MIDI with a degree of latency that is acceptable for real-time music-making is difficult, however. An interesting direction for future research would involve designing a testbed system that uses audio signal processing techniques to simulate variable latency rather than MIDI, enabling the modeling techniques developed here to be applied to larger ensembles.

A third limitation concerns our use of generalist (e.g., Zoom) rather than specialist telecommunications platforms when measuring network latency. Recent technological advances have been able to reduce latencies during networked musical performance to below the minimum threshold tested in this research (e.g., \citealp{Drioli2013}), with exciting implications for musicians. Latency, however, will always be present to some degree during networked performance, especially for musicians situated far away from each other geographically, so we still consider it necessary to study how it can be accommodated. Future research, however, may involve using these specialist technologies when modeling latency and jitter, unlike our use of a generalist platform.

Taken together, our results provide the first demonstration that error correction, a core component of the human facility for temporal coordination, can be optimized to compensate for the lack of perceived simultaneity that arises when joint action occurs over a network. While face-to-face conversations and musical performances are increasingly becoming feasible as restrictions related to the COVID-19 pandemic ease, remote facilitation is likely to remain an essential part of modern life in the future, meaning that comprehending the ways this may impact successful human interaction has never been more crucial.

\subsubsection{Data Availability}

We make all data and research materials created during this chapter available under a permissive license on a trusted third-party repository.\footnote{\href{https://doi.org/10.5281/zenodo.7773824}{\texttt{https://doi.org/10.5281/zenodo.7773824}}} The code for the analyses reported in this chapter is also publicly accessible,\footnote{\href{https://github.com/HuwCheston/Jazz-Jitter-Analysis}{\texttt{https://github.com/HuwCheston/Jazz-Jitter-Analysis}}} as is our testbed \footnote{\href{https://github.com/HuwCheston/AV-Manip}{\texttt{https://github.com/HuwCheston/AV-Manip}}} and perceptual study\footnote{\href{https://github.com/HuwCheston/2023-duo-success-analysis}{\texttt{https://github.com/HuwCheston/2023-duo-success-analysis}}} software. All statistical analyses and models were implemented using the \texttt{SciPy} (version \texttt{1.9.0}, \citealp{Virtanen2020}) and \texttt{statsmodels} (version \texttt{0.13.5}, \citealp{Seabold2010}) Python libraries.