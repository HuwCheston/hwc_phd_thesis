\chapter{Introduction}\label{chap:introduction}

Improvisation is a fundamental part of many musical traditions. While definitions of improvisation vary, most agree that it involves the spontaneous creation of musical material, as opposed to the performance of pre-composed work. This practice has long fascinated musicians, composers, and scientists across a range of disciplines due to its balance of spontaneity and prior planning, its challenges for analysis and modelling, and its apparent deep links with cognition, psychology, and linguistics.

Jazz is among the richest musical forms reliant on improvisation to have emerged in the twentieth century. With roots in African, American, and European musical traditions, jazz has become part of the intangible heritage of many cultures where it is practised \citep{Feld2012} and is studied at universities and colleges worldwide \citep{Berliner1994}. Through improvisation, jazz musicians manipulate many different aspects of the music they play, such as the harmony, melody, and rhythm of a composition. In group settings, these choices must also be negotiated collectively between the members of an ensemble for a performance to be successful \citep{Monson1996}.

The widespread freedoms that are afforded to jazz improvisers render the formalisation of this music a challenging task for researchers in the field of Music Information Retrieval (\GLS{MIR}). Computational modelling may prove to be one way of addressing this issue effectively. Good models can explicitly address the ambiguities and assumptions that are inherent in critical discourse surrounding jazz, which often involves terms such as ``feel'', ``interaction'', and ``groove'' that may be straightforward to use colloquially but difficult to locate in concrete examples of the music. Computational models can also provide a framework for studying improvisation systematically, bridging the gap between subjective interpretation and objective analysis --- with exciting potential applications both to digital humanities research and music education.

Despite the possibilities that computational modelling unlocks for the study of jazz improvisation, the extent to which these have been fully explored remains debatable. For many years, \GLS{MIR} has been a primarily ``task-oriented'' research field. New models are typically evaluated based on the extent that they improve upon the previous state-of-the-art in some objective metric or pre-defined task. With relation to jazz specifically, common tasks explored in \GLS{MIR} research involves the automatic alignment of notation to an original audio recording \citep{Shanin2023}, the detection of structural boundaries separating different improvised solos \citep{Balke2022}, and the automatic transcription of recordings into musical notation or MIDI \citep{Riley2024-omnibook}.

This work is undoubtedly valuable in and of itself, and has also led to numerous technologies that can help to inspire future music creation --- such as by generating accompaniment to improvisations by human performers \citep{Ostermann2021, Keller2013} or rendering their playing in the styles of particularly well-known composers \citep{George2019}. But the extent to which these models have been developed or applied to better understand how this music \textit{actually works} is altogether limited. Despite the diverse possibilities that computational modelling has unlocked for the analysis of styles of Western classical and popular music \citep[see, e.g.,][]{Foscarin2022}, it still seems as if there remains much left to discover about jazz improvisation using computational methods.

One challenge involved in modelling the complexity of jazz improvisation is a lack of data. Unlike Western classical music, the primary musical ``document'' involved in jazz is typically not a notated score, but an audio recording of a performance. While interesting research can be accomplished by training models directly on representations of sound recordings (e.g., spectrograms, waveforms), many \GLS{MIR} tasks instead require symbolic data --- abstract, human-interpretable representations like lead sheets, musical scores, or MIDI ``piano rolls''. Creating this data often has required lengthy processes of annotating recordings by hand \citep{Balke2022, Pfleiderer2017, Goto2002}, limiting the scope of previous modelling research to a relatively small number of musical performances. However, recent advancements in neural audio processing offer the chance to render these processes obsolete, with the potential for dramatically scaling up this research \citep[e.g.,][]{Edwards2023, Riley2024-omnibook, Shanin2023}.

Another challenge relates to how these models can be explained in ways that are interpretable and meaningful for those engaged with this music. Computational models can learn to rely on features that are extremely powerful for the task they are trained to perform but that are otherwise uninterpretable to humans. In task-oriented \GLS{MIR} applications --- where the primary goal is achieving the best performance on unseen data --- this may be of little importance. However, for those interested in using these models to better understand the structure of the underlying data, making these models transparent and interpretable remains challenging. While numerous techniques for interpreting machine learning models have emerged \citep[see][for a recent review]{Hassija2024}, the extent to which these can be applied to generate explanations of complex forms of music such as jazz remains to be seen.

This thesis aims to address these problems within the existing literature. Not only do we intend to advance the current state-of-the-art in the computational modelling of jazz improvisation in the symbolic domain across tasks such as automatic performer identification, but we aim also to interpret these models to learn more about jazz improvisation style and the ways in which this music is produced. We train our models using large datasets comprising hundreds of hours of annotated performances --- including a new dataset created as part of this work --- achieving a scale rarely achieved in prior computational research on jazz. Our work is musically informed, insofar as our models are interpreted in light of not only their abstract statistical properties but also their connections with prior research on jazz improvisation from the humanities.

In the remainder of this introduction, we (1) review previous computational work addressing improvised jazz, (2) define the motivations and themes of the present research, and (3) outline the structure and contributions of the thesis.

\section{Prior Research}

The earliest computational research into jazz improvisation dates to the 1970s and 1980s, with the efforts of \citet{Urlich1977} and \citet{Fry1980} to develop rule-based systems capable of generating and synthesising jazz-like ``improvisations''. Subsequent work has embraced developments in natural language processing, information theory, machine learning, cognitive psychology, neuroscience, and audio signal processing (amongst other fields). Computational research involving jazz and improvised music now appears widely in conference proceedings and journals dedicated both to \GLS{MIR} and a general scientific audience.

As we cannot discuss all computational research into jazz improvisation, we can instead summarise key trends with regards to modelling different musical concepts or domains (e.g., rhythm, harmony, melody), as well as research into the modelling of musical style and ensembles. These topics are selected to provide a broad overview of the types of computational literature on jazz improvisation that are relevant to each chapter of the thesis. We further review the specific literature that is relevant to the specific modelling tasks considered in this work at the start of every chapter.

\subsection{Rhythm}\label{sec:lit_review_rhythm}

Rhythm and timing have proved fruitful subjects for computational jazz research since at least the 1990s. This is perhaps due to the nature of the data that is required. Timing can be effectively quantified using only a vector of note onset or offset times. This means that --- unlike comparable analyses of melody and harmony, for instance --- a full notated transcription of an improvised performance is not typically necessary.

\subsubsection{``Swing''}

One prominent line of research involves analysing the ``swing'' rhythm that is characteristic of jazz music, defined as the subdivision of the quarter note musical pulse into long-short groupings of eighth notes. \citet{Rose1989} was the first to quantify swing as the ratio of long to short notes within each grouping. Subsequent research has demonstrated that these swing or ``beat-upbeat ratios'' \citep{Benadon2006} vary as a function of both the tempo \citep{Ellis1991, Friberg2002, Honing2008, Dittmar2018, Foster2021} and subgenre \citep{Corcoran2021} of a performance. Performers also show a preference for particular swing ratios, with this apparently acting as a ``signature'' of their own improvisation style \citep{Lindsay2007, Corcoran2021, Dittmar2018, Benadon2006}. \citet{Cheston2022} demonstrated that this stylistic signature varies between drummers depending on whether they are playing by themselves or accompanying an ensemble. We further discuss swing within Sections~\ref{sec:jtd_swing} and~\ref{sec:rsos_swing_features} of this work.

\subsubsection{Synchronisation}

Analysing ensemble synchronisation is a related strand of research. \citet[p. 277]{Keil1987} referred to ``the little discrepancies ... between rhythm section and soloists'' as ``participatory discrepancies''. This notion has become particularly influential in subsequent research. Jazz soloists have frequently been demonstrated to delay their downbeat with respect to that implied by the accompanying musicians in an ensemble, perhaps to manifest a sensation of ``laying back'' in their playing \citep{Doffman2014, Ellis1991}. Tight synchrony between musicians in the accompanying ``rhythm section'' has been frequently observed, with delays between bass and drums of less than ten milliseconds reported in prior experimental work \citep{Kilchenmann2015, Doffman2014}.

Evidence for whether these minute discrepancies in swing and synchrony are directly perceivable by listeners remains inconclusive. \citet{Butterfield2010} found that most listeners are unable to discern a small discrepancy in timing between musicians across a variety of musical tempos. However, \citet{Nelias2022} demonstrated that slight downbeat delays between a soloist and ensemble enhanced the perceptual salience of swing, while \citet{Kilchenmann2015} found a small effect of timing discrepancies on the body movements of listeners. Both of these findings were restricted to jazz experts and professional musicians only, however.

\subsection{Harmony}

Owing to its combinatorial complexity and apparent sonic distinctiveness (e.g., ``jazz chords''), harmony has been extensively studied in the modelling literature on jazz. 

\subsubsection{Chord Progressions}

One approach involves modelling the harmony represented by jazz ``lead sheets''. These provide a basic indication of the underlying chords, melody, and form of a composition that performers elaborate on during improvisation. \citet{Rohrmeier2020} proposed a theoretical framework of jazz lead sheet harmony based on formal grammars designed to capture the hierarchical function of common compositional devices in jazz (e.g., substitution, ``out-of-key'' chords). Although his model was outlined theoretically, similar models have been implemented computationally \citep[e.g., by][]{Keller2013}. \citet{Granroth-wilding2014} proposed an abstract, context-free probabilistic model of jazz harmony that was subsequently refined with reference to the ``twelve-bar blues'' form by \citet{Katz2017}. The performance of grammar-based models of jazz harmony can also be improved with the addition of grammars based on rhythmic information \citep{Harasim2019}.

\subsubsection{Chord Realisation}

A separate task involves modelling the actual realisation of a jazz chord progression from a lead sheet. This typically necessitates both harmonising individual chords and combining multiple chords efficiently into sequences through processes of voice-leading. \citet{Harrison2020-voiceleading} investigated the latter problem by developing a linear model to quantify the desirability of a given voice-leading for a chord progression that, although trained initially on chorale harmonisations, proved equally capable of generating realistic interpretations of jazz standards. \citet{Chen2020-jazzification} considered the problem of generating both voice-leading and harmonisations end-to-end for a plain chord progressions (i.e., a sequence of triads) as part of a process they call ``chord jazzification''. Finally, the task of modelling harmonic similarity between different harmonisations of the same underlying composition (``contrafacts'') was addressed by \citet{Bunks2023}. 

\subsection{Melody}

Modelling jazz improvisation in the melodic domain is another area of considerable research interest, particularly in generative applications. 

\subsubsection{Rule-based Approaches}

One assumption is that jazz melodies follow a set of rules that can be approximated by an algorithm. Many of the earliest generative models for jazz improvisation \citep[e.g.,][]{Urlich1977, Fry1980} were based on pre-defined, hand-crafted music-theoretic rules, such as associating particular chord progressions with certain musical scales. \citet{Johnson-laird2002} developed a rule-based algorithm for generating jazz bass lines based on contour, chord progressions, chord-scale relationships, and passing tones. \citet{Norgaard2013-cognitive}, however, found that generating ``solo'' improvisations using formal schemata produced improvisations with fewer recurrent patterns than those found in actual corpora, suggesting that such rules alone are insufficient to model the complexity of melodic improvisation in jazz. Generative models based solely on rules can also produce improvisations that may fulfil the basic harmonic and syntactical qualities of jazz but which ultimately lack musical interest \citep{Pachet2012}.

\subsubsection{Pattern-based Approaches}

In contrast to learning rules for improvisation, a pattern-based approach assumes that jazz improvisation draws from a repertoire of stock melodic sequences that can be approximated as a formal grammar using probabilistic modelling \citep{Pressing1987}. \citet{Gillick2010} used Markov modelling and unsupervised clustering of short melodic contours and pitch-class interval patterns to learn grammatical representations of melodic, monophonic jazz improvisation. \citet{Cross2023-intervals} have since explored the relationship between melodic patterns and metrical positioning in jazz. Expanding beyond soloists, \citet{Riley2023} used automatic music transcription and source separation to analyse the appearance of common melodic patterns in the ``walking'' lines played by several well-known jazz bassists. 

Similar techniques can be applied to learn melodic grammars representative of the style of individual jazz musicians. \citet{Norgaard2014-how} applied probabilistic modelling techniques based on interval $n$-grams to a corpus of improvisations by the influential jazz saxophonist Charlie Parker, finding that the vast majority of Parker's recordings could be represented using a relatively small formal grammar. In another project, some of the same authors simple Markov models to these probability distributions to generate plausible sounding, ``Parker-esque'' improvisations \citep{Norgaard2013-cognitive}. Similar work has also been conducted for jazz pianist Bill Evans \citep{Gross2011}.

The ``Dig that Lick'' (\GLS{DTL}) project represents an important contribution to pattern-based modelling of melodic jazz improvisations.\footnote{\url{https://dig-that-lick.eecs.qmul.ac.uk/}} Using pattern mining techniques to extract short melodic sequences (``licks'') from automatically generated transcriptions of over 1,000 jazz recordings, the \GLS{DTL} project developed a database of melodic patterns that can be explored using an interactive web application \citep{Frieler2018}. This application allows the user to view the patterns that particular jazz improvisers use most frequently. It is difficult to know if these patterns are truly idiomatic for each performer, however, versus simply being used by many musicians --- a subject we revisit in Section~\ref{sec:rsi_feature_importance_by_performer}. Subsequent work completed as part of the \GLS{DTL} project has involved creating a ``vocabulary'' of jazz melodic lines derived from Markov models \citep{Frieler2019-jazzlines} and tracking the transmission of particular patterns across performers and jazz history using objective measurements of similarity \citep{Frieler2019-Anatomy}. The \GLS{DTL} project represents an important step to apply advances in audio signal processing to generate a large dataset of annotated improvisations with minimal human intervention. In this work, we expand our scope both to consider numerous instruments in a single ensemble, as well as polyphonic instruments such as the piano.

% \subsubsection{Evolutionary Modelling}

% A third approach to modelling jazz melody borrows from evolutionary computing and involves the development of genetic algorithms that learn to refine jazz melodies sampled from an initial population. \citet{Biles1994} implemented an algorithm that learns from a population of existing solos and obtains assessments from a human rater in real-time, which in turn provides fitness values that are used to refine subsequent generations. In contrast, \citet{Papadopoulos1998} used a fitness function consisting of a series of musically informed heuristics (e.g., avoiding excessively large intervals and long durations), demonstrating that this alone could create feasible jazz improvisations from a randomly initialised population of melodies without human supervision. \citet{Nam2019} demonstrated that the diversity of melodies can be improved by optimising the mutations applied to melodic patterns that demonstrate high fitness.

\subsubsection{Deep-Learning Methods}

In contrast to rule- and pattern-based approaches, the current state-of-the-art in modelling jazz melody typically uses deep learning. \citet{Trieu2018} used adversarial methods to train a Recurrent Neural Network (\GLS{RNN}) to improvise monophonic jazz melodies over a given chord progression. While their method obtained surface-level similarities with jazz, it was also vulnerable to collapsing and producing highly repetitive outputs. \citet{Wu2020-frontline} used the ``Transformer-XL'' sequence-to-sequence architecture to produce both melodies and chordal accompaniments with long-range musical dependencies learned throughout the sequence. While their work obtained some similarities with jazz in terms of groove and tonality, it was also unable to match real performances in terms of subjective quality and diversity.

\subsection{Style}

Jazz is a remarkably diverse form of music, both in the styles of individual performers and composers and across distinct subgenres. There has been some recent interest in modelling the diversity of jazz styles using a variety of different learning algorithms.

\subsubsection{Composer Identification}

One possible task here involves predicting the composer of a jazz standard, typically using a lead sheet representation of one of their compositions. \citet{Hedges2014} demonstrated that the composer of a jazz composition can be identified solely using its underlying chord sequence, with their model also able to visualise particularly idiomatic harmonic progressions associated with different composers using a tree-based structure. \citet{Velenis2023} adopted a multi-task framework where the composer, harmonic style, form, and subgenre (amongst other features) of a jazz lead sheet are predicted simultaneously by a transformer model trained on lead-sheet representations of jazz standards. Using dimensionality reduction techniques and unsupervised learning, the features learned by this model could then be projected onto a lower-dimensional latent space to simultaneously show the similarities between different jazz composers, historical eras, and subgenres. While this work is interesting, the degree to which the ``composer'' of a jazz piece truly is responsible for its musical content is up for debate --- especially considering how performers frequently change both the harmony (e.g., through chord substitutions), melody, and occasionally even the entire structure of a composition \citep{Berliner1994}.

\subsubsection{Performer Identification}

A separate task instead involves identifying jazz \textit{performers}: here, the data source is typically a recording of an improvised performance, rather than a lead sheet. Early work in this area typically trained supervised learning models on ``handcrafted'' sets of quantitative features. \citet{Ramirez2010} demonstrated that features relating to the use of pitch, timing, dynamics, and timbre extracted automatically from an audio signal could be used to accurately identify different jazz saxophonists performing both in a laboratory environment and on commercial recordings, even from very short musical phrases. Using similar techniques, \citet{Abeser2015-scoreinformed} considered the degree to which the intonation of a jazz wind instrumentalist is artist-specific or varies as a function of recording year, tempo, and pitch.

More recently, impressive accuracy scores have been achieved by leveraging deep-learning to extract features automatically from a recording. \citet{Edwards2023} trained a convolutional recurrent neural network to identify thirty jazz pianists from symbolic transcriptions of their recordings represented as ``image-like'' piano rolls. \citet{Chou2024} instead took a language modelling approach by representing symbolic musical events as sequences of discrete tokens, and trained a bidirectional transformer model to identify recordings made by a jazz pianist versus performers of other musical styles. We provide an in-depth review of performer identification work beyond jazz within the introduction of Chapter~\ref{chap:rhythm_rsos}.

A limitation with much of the prior research on music composer and performer identification relates to the description of current \GLS{MIR} research as ``task-oriented'' given at the start of this chapter. As we argue in Chapter~\ref{chap:xai_rsi}, while these models could \textit{technically} be useful for identifying unknown jazz performers or composers, in practise this scenario is rare as online discographies of jazz recordings are now mature and comprehensive. Rather than simply trying to improve these models for their own sake, in Chapters~\ref{chap:xai_rsi} and~\ref{chap:rhythm_rsos} we follow \citet{Foscarin2022} in taking the interpretation of these models seriously, analysing their decision-making functions to generate quantitative insights into the specific qualities of different styles of jazz improvisation.

\subsection{Genre}

\subsubsection{Genre Classification}

Alongside Western classical and popular music forms, jazz often appears in the ``classic'' \GLS{MIR} task of genre identification. A full review of music genre classification models trained using symbolic features is given in \citet{Correa2016}. Here, we note simply that interpreting a genre identification model can provide insights into the specific musical qualities that best distinguish jazz from other genres. \citet{Zheng2017-genre} used features derived from melodic contour and duration to derive musicological interpretations from a genre classification model trained on both jazz and classical pieces. A comparable approach was taken by \citet{Simsekli2010} using only the bass line of the music. \citet{Dervakos2022} used a local feature-based technique to explore the regions of a MIDI ``piano roll'' representation that pushed a convolutional neural network to classify this as jazz or another genre. However, the interpretability of this technique was criticised by the authors, and is further questioned by our own work in Chapter~\ref{chap:xai_rsi}.

A small number of papers have attempted to evaluate computationally the differences in harmonic syntax between jazz and other musical genres. \citet{Harrison2018-harmony} used a feature-based approach informed by psychological modelling to compute the relative importance of abstract cognitive and music-theoretic terms (e.g., ``harmonicity'', ``voice-leading distance'') when classifying compositions as either Western classical, popular, or jazz. A comparable approach was earlier taken by \citet{Anglade2009}, who employed a tree-based classifier using features derived from chord progressions to develop transparent ``rules'' separating the harmony of jazz from classical and popular music. Although we do not consider the differences between jazz and other genres in this work particularly, this would be a useful extension of the models described in Chapters~\ref{chap:xai_rsi}--\ref{chap:mp_network} and offers an opportunity for future research (see Section~\ref{sec:discussion_limitations_and_future_directions}).

\subsubsection{Subgenre Classification}\label{sec:lit_review_subgenres}

Related to genre classification is the task of classifying distinct ``subgenres'' of jazz (e.g., ``swing'', ``bebop'', ``acid''). This task has been considered in a small number of papers, including several that also attempt to classify individual composers or performers \citep[e.g.,][]{Hedges2014, Abeser2015-scoreinformed, Velenis2023}. \citet{Eppler2014} used decision trees trained on a handcrafted feature set capturing rhythm, tempo, and tonality to classify the subgenre of a jazz recording from a small number of candidate classes. \citet{Quinto2017} trained numerous supervised learning architectures to identify three jazz subgenres using acoustic features, with the greatest success observed for recurrent neural networks. As mentioned above, \citet{Velenis2023} adopted a multi-task learning paradigm where the latent space of their model can be explored visually in terms of jazz subgenre, alongside performer and historical era.

However, the extent to which these models actually learn musical qualities distinct to particular subgenres --- as opposed to simply the differences in recording practices apparent between different historical time periods \citep[see][]{Flexer2010, Edwards2023} --- remains unclear. Moreover, it is not evident whether this division of jazz history into distinct chronological subgenres or ``eras'' is even particularly helpful, especially given that musicians may instead see the development of this music in a less-than linear fashion \citep[e.g.,][]{Litweiler1984} and that some jazz works may not fall neatly into the ``era'' they were created in. An alternative option is to take an unsupervised learning approach, identifying ``clusters'' of particular styles of jazz performance directly from raw data, without presupposing the existence of strict subgenres or eras. We consider this possibility further in Section~\ref{sec:rsos_rhythm_characterises_style}.

\subsection{History}

A related area of research involves modelling the musical development and evolution of jazz over the past century. Parallels exist here with equivalent work conducted with relation to popular music \citep[e.g.,][]{Hamilton2024, Warrell2024}. 

With relation to harmony and tonality, \citet{Weis2018} found that the complexity of pitch class representations obtained from both audio-based chromagrams and symbolic transcriptions of jazz performances followed a roughly linear path over the past century, with minimal differences between the type of input representation used. \citet{Abeser2015-scoreinformed} demonstrated a trend towards the now-standard 440 Hz tuning frequency in commercial jazz recordings over the twentieth century, as this gradually became accepted amongst musicians. \citet{Broze2013} considered trends in harmonic syntax in published ``lead sheet'' representations of jazz standards, finding evidence only for small, gradual shifts away from traditional ``tonal'' harmony in the latter part of the twentieth century. How these chords are actually realised by musicians was not considered, however. We discuss possible chronological trends in the usage of harmonic progressions by jazz pianists in Section~\ref{sec:rsi_factorised_cavs} of this work.

\citet{Frieler2016} developed a method whereby an improvisation is annotated with ``mid-level units'' (e.g., ``quotation'', ``ascending line'', ``theme''). Some evidence emerged from their analysis that the diversity of the units employed within an improvisation has increased over the past century. A subsequent project by the same authors extracted a wider range of features (spanning both ``mid-level units'' alongside pitch, rhythm, and interval features) from the same recordings. The user can explore simple regression models fit between these features and the year a given recording was made on an interactive web application, described in \citet{Frieler2018}\footnote{\url{https://jazzomat.hfm-weimar.de/feature_history_jazz/}}. While several features (e.g., pitch-class entropy) do seem to show clear relationships over time, for others this pattern is less evident. Moreover, it is not clear to what extent these features vary simply over the duration of a musician's career (e.g., performers use a greater range of pitch classes as they age, etc.), as opposed to varying more systematically over the past century of recorded jazz more generally. 

Similar observations were made by \citet{Corcoran2021}, who studied the use of swing in jazz from the earliest ``traditional'' recordings to more recent ``postbop'' styles. They found a monotonic increase in the average swing ratio over time, but were not able to rule out the possibility that the consistency of particular performers rhythmic style may have effected their results. We conduct such an analysis of the developments in jazz rhythm in Section~\ref{sec:rsos_rhythmic_styles_are_consistent} of this work.

\subsection{Ensembles}

Another area of concern to the present thesis involves modelling the strategies that are actually used to perform jazz music in an ensemble. 

A variety of methods exist for modelling coordination and interaction strategies in musical ensembles \citep[see][for a review]{Demos2023}. With reference to jazz, \citet{Bantula2016} developed a method to quantify the influence of accompanying rhythm section musicians on a soloist: features are extracted from the performance of the soloist and the soloist combined with the ensemble, separate supervised-learning models are trained on both datasets, and the accuracy of both models is compared. Another method is linear phase correction, introduced by \citet{Wing2014} and subsequently applied to string quartets \citep{Chang2017, Wing2014, Timmers2014}, piano duets \citep{Goebl2009}, and African drumming ensembles \citep{Jacoby2021}. Here, interaction is modelled as a process of distributed adaptation to timing discrepancies from exact isochrony, as in Equation~\eqref{eq:mp_phase_correction_model}.

Outside of the modelling literature, understanding the ways in which improvised conduct is coordinated and organised between musicians has seen interest from psychologists, linguists, and ethnographers. Previous work has studied the use of non-verbal feedback in duo improvisations \citep{Moran2015} and the pre-planning musicians engage in during rehearsal \citep{Dueck2013}. \citet{Doffman2014} quantified the timing synchronisation between members of a rhythm section with relation to the sensor-motor process of entrainment \citep{Clayton2020}. Finally, both \citet{Pras2017} and \citet{Schober2014} have evaluated the extent to which jazz musicians perceive each other's intentions during improvisation --- concluding that exactly shared understanding is not required for a performance to be successful. We provide further evidence in support of this argument as part of our listener evaluations described in Chapter~\ref{chap:mp_network}.

An interesting question that connects this work to traditional \GLS{MIR} tasks more specifically is whether features that are extracted from a computational model of ensemble coordination can be useful when training a jazz performer identification model. The ethnographic literature on jazz often suggests that the ways a performer coordinates and interacts with other musicians in their ensemble is a key part of their ``sound'' or style \citep[e.g.,][]{Monson1996}, and computational modelling can be an interesting way of testing this assumption. This is addressed in Section~\ref{sec:rsos_rhythmic_features_predict_identity} of the present work. Furthermore, in Chapter~\ref{chap:mp_network}, we apply this model to jazz improvisations and demonstrate how it can reveal both the aesthetic and stylistic priorities of different performers and ensembles.

\subsection{Datasets}

One limitation of many of the earliest computational studies of jazz improvisation is the restricted size of their datasets, often containing only a small number of recordings \citep[e.g., 6 recordings in][]{Friberg2002}. In response to this need, numerous large databases of annotated jazz performances and compositions have been developed and adopted by the community. Perhaps the best known is the Weimar Jazz Database or \GLS{WJD} \citep{Pfleiderer2017}, a dataset of 456 transcribed recordings that has since been used in a large number of research projects \citep[e.g.,][]{Wu2020-frontline, Corcoran2021, Frieler2018, Balke2022, Weis2018}. We provide a complete review of the \GLS{WJD} and other datasets of symbolic annotations of jazz performances \citep[e.g.,][]{Foster2021, Riley2023, Edwards2023, Goto2002} in Chapter~\ref{chap:jtd_tismir}, where we outline our own such dataset. 

Finally, we note that numerous datasets of specialized annotations exist for jazz, covering lead sheets and chord progressions \citep{Broze2013, Bunks2023, Eremenko2018, Harasim2019, Pachet2013-database}, formal structures \citep{Balke2022, Eremenko2018}, and harmonic and melodic progressions \citep{Adegbija2023}. While we do not specifically refer to these datasets in this work, they represent an important step by the community towards facilitating the training of computational models on large amounts of data made available under permissive licenses.

\subsection{Jazz Studies, Ethnography, and the Humanities}

While the methodology used in this work comes from statistical modelling and machine learning, interpreting our results requires us to engage with the broader jazz studies literature. We draw particularly from two landmark works in music ethnography by \citet{Berliner1994} and \citet{Monson1996}. Through extensive interviews with well-known performers and analyses of commercial recordings, these works evaluate the processes with which jazz musicians (both individually and collectively) learn to improvise. Our focus also extends to several oral histories of jazz edited by \citet{Sidran1992}, \citet{Lyons1983}, and \citet{Gottlieb1997}, which feature discussions by well-known jazz musicians (including several featured in our database) of their creative process. 

Several publications are referred to more explicitly as part of our data analysis and extraction pipelines. In particular, we use the discographies in \citet{Gioia2011} and \citet{Levine2011-1} to identify performers suitable for inclusion in our dataset of annotated recordings (see Section~\ref{sec:jtd_popular_performers}). We also take examples from the pedagogical textbook by \citet{Haerle1994} to create a ``concept dataset'' that we use to interpret one of our models (see Section~\ref{sec:rsi_factorised_cavs}).

\section{Motivations}\label{sec:intro_motivations}

Having reviewed some of the previous work in this area, we now provide an overview of the distinct motivations and themes that are central to the present research.

\textbf{Supervised Learning of Musical Corpora.} One motivation for this work is to understand the different musical features that underpin the diversity of jazz improvisation \textit{styles} from the past century. Accordingly, we apply our models to comprehensive collections of jazz music that reflect its many subgenres, structural formats, and historical eras, as well as its most prominent artists. While corpus analyses can be conducted in a variety of ways, our primary methodology consists of training a variety of classification and regression models and interpreting them with respect to existing musicological and critical writings on jazz. The majority of our models are supervised learning models, where the model learns to explicitly predict labelled target classes or numerical results. In contrast to unsupervised approaches, this enables us to understand how particular musical features and concepts extracted from recordings might relate to certain jazz performers or subgenres. We do, however, consider a number of unsupervised modelling approaches to complement our supervised-learning models (see Sections~\ref{sec:rsi_feature_importance_by_performer} and~\ref{sec:rsos_rhythm_characterises_style}).

\textbf{Resource Generation.} A second motivation for this work is to generate open-source resources that can facilitate subsequent computational research into jazz improvisation. We develop numerous datasets, computational models, software, and web applications, and release these under permissive, open licenses to enable future researchers to use and build upon them. In particular, we develop a database of annotated recordings (discussed in Chapter~\ref{chap:jtd_tismir}) by leveraging recent advances in audio signal processing and machine learning to automatically process thousands of recordings. These methods let us bypass the painstaking annotation process that is often involved in corpus analyses, which in turn can help us dramatically scale up our models to cover large swathes of jazz history. By releasing these resources publicly, we also allow researchers to explore questions relating to the computational modelling of jazz improvisation that are not covered in significant detail here, such as the difference between jazz and other musical genres. 

\section{Themes}\label{sec:intro_themes}

Alongside these motivations, our research also explores a number of additional themes, which we outline below.

\textbf{Modelling Improvisation Style.} Towards the end of the 20th century, it was claimed that, for jazz,
\begin{quote}
    \centering
    there doesn't exist ... any form of notation, graphic representation, and computer analysis capable of satisfactorily registering the subtlety of [the musical processes that] differ not just stylistically but also in terms of specific distinctions between groups and individuals \citep[p. 192]{Berendt1976}.
\end{quote}
Responding to this statement is a core theme of this research. One way in which we can do this is by training computational models to identify particular jazz musicians from their recordings. This is an interesting task in \GLS{MIR} research, but has mostly been limited to Western classical \citep{Mahmudrafee2023, Tang2023} and popular \citep{Chou2024} music. By training these models instead on jazz music and interpreting their predictions, we hope to demystify the factors that distinguish the styles of particularly well-known musicians. This has exciting potential applications for both digital humanities research and music education.

\textbf{Modelling Musical Ensembles.} A second theme underpinning this work is to model the differences between musical ensembles --- the ``specific distinctions between groups'', described above. The interaction between the members of a musical ensemble can substantially influence the success of their music-making and can also become a part of the style of an individual performer \citep{Monson1996}. Accordingly, psychological models of joint action and coordination \citep[e.g.,][]{Wing2014, Jacoby2021, Timmers2014} may potentially enhance our music performer identification models by helping to incorporate interesting, ensemble-level features. By comparing models trained on both ensemble and solo improvisations, we can also better understand the differences between both forms of music-making. These differences are frequently described by both musicians and ethnographers \citep[e.g.,][]{Monson1996}, but have not been substantially explored in empirical work before.

\textbf{Symbolic Music Modelling.} There are two primary traditions of music modelling research: (1) symbolic modelling, where a musical input is represented using formats such as musical notation, scores, and MIDI ``piano rolls'', and (2) acoustic modelling, where the underlying sound is represented directly using methods such as waveforms and spectrograms. While the latter tradition may sound appealing for jazz --- where the primary way a musical work is documented is through a recording, rather than in musical notation --- it has its drawbacks. In particular, computational models trained on acoustic features may have high predictive power but low interpretability, as the underlying representations may be unintuitive for non-technical readers \citep{Foscarin2022, Edwards2023}. Given our focus on model interpretability, we instead prefer to work with symbolic data extracted from an audio recording (as in Chapter~\ref{chap:jtd_tismir}), with the intention of facilitating explainable musical analyses that will be of interest to the widest possible audience.

\textbf{Model Interpretability.} There is a temptation in computational research to only use the current state-of-the-art techniques that yield the best results for any given task. Yet, as the complexity of any computational model increases, the extent to which its decision-making process can be understood by a human often decreases: they become ``black boxes'' \citep{Hassija2024}. While one approach to navigating this trade-off would be to employ only conventional ``white-box'' techniques (e.g., linear modelling), in Chapter~\ref{chap:xai_rsi} we instead tackle this problem of interpretability ``head-on'', exploring a variety of modelling approaches (both ``white-'' and ``black-box'') and techniques for explaining their predictions throughout this work. For example, we provide a systematic comparison of many different music performer identification architectures, evaluating them not only in terms of predictive accuracy and performance but also ease of interpretability. We also develop numerous interactive web applications as part of this work to showcase the models that we create and allow readers to draw their own conclusions from them.

\textbf{Musically Informed Feature Selection.} For many supervised-learning architectures, decisions must be made as to which features are extracted from a performance and used to train the model. While numerous methods exist for selecting or combining features from a large feature set (e.g., dimensionality reduction, penalised regression), in Chapters~\ref{chap:rhythm_rsos} and~\ref{chap:mp_network} we prefer to derive our features from the ground-up with reference to the musicological and critical literature on jazz. This eliminates the requirement for post-hoc interpretation of the embedding space learned by the model \citep[as in][]{Foscarin2022}. It also helps facilitate meaningful interpretations, as our features are already likely to be well-understood by musicians and researchers \citep[here, see][]{Hamilton2024}. The inverse also holds true, as well: interpretations that are derived from abstract computational models gain credibility when they can be supported by statements from critics, musicologists, or performers themselves.

\textbf{Modelling Straight-Ahead Jazz.} The scope of this research relates primarily to what is known as ``straight-ahead'' (variously also referred to as ``conventional'' or ``mainstream'') jazz. This involves improvisation based on what \citet[p. 48]{Bailey1992} calls ``tunes in time'': harmonic sequences of a set length are used (typically derived from popular song forms or other jazz compositions) and are played within a notionally strict sense of musical time \citep[``standards'': see][]{Gioia2012-standards}. This is different from ``free'' jazz improvisation, where these materials are typically absent. Most prior computational and empirical research has addressed ``conventional'' jazz improvisation, with a limited number of exceptions \citep[e.g.,][]{Pressing1987, Pras2017}.

\textbf{Modelling Jazz Rhythm Sections.} Alongside these stylistic considerations, we also restrict ourselves to the three instruments that constitute the jazz ``rhythm section'' --- piano, bass, and drum kit. We focus on these instruments specifically as they form the backbone of most straight-ahead jazz, providing the harmonic, rhythmic, and structural foundations of a performance over which ``solo'' improvisations (that may themselves be made by members of the rhythm section) take place \citep{Monson1996}. From a technical standpoint, methods capable of processing audio recordings by these instruments are considerably more advanced than many other instruments commonly associated with jazz, such as the saxophone \citep[although here, see][]{Riley2024-omnibook, Ramirez2010}.

\section{Thesis Structure and Contributions}

Our primary contributions in this work consist of advancements across three distinct tasks: modelling (1) improvisation style, (2) rhythm, and (3) ensemble interaction. Each subject is covered in an individual chapter of the thesis (Chapters~\ref{chap:xai_rsi}--\ref{chap:mp_network}). These are preceded by Chapter~\ref{chap:jtd_tismir}, which outlines an open source dataset of annotated recordings used to train and evaluate many of our models. Finally, the thesis concludes with Chapter~\ref{chap:discussion}, which discusses the outcomes of the present work. We provide a short overview of each chapter below.

\textbf{Chapter~\ref{chap:jtd_tismir}: Introducing the Jazz Trio Database.} This chapter addresses the problem of scaling-up computational music research by introducing an automated pipeline for generating symbolic annotations from jazz recordings. Pre-trained deep-learning models are applied to ``demix'' an audio recording into separate signals for multiple instruments, which are then automatically annotated using existing transcription models. We use this pipeline to generate the Jazz Trio Database (\GLS{JTD}), an open source dataset of annotated jazz rhythm section performances with a total of 44.5 hours of annotated audio across piano, double bass, and drum kit.

\textbf{Chapter~\ref{chap:xai_rsi}: Modelling Improvisation Style.} This chapter considers how computational modelling can disentangle the elements contributing to ``style'' in jazz improvisation. We construct a series of supervised learning models that learn to identify particular pianists from recordings in \GLS{JTD} and other datasets, and then we interrogate the learned decision functions of these models to understand how these judgements were made. This culminates in a novel deep neural network architecture that achieves predictive accuracy close to the current state-of-the-art, with a multi-input structure that allows its predictions to be explained in terms of four fundamental musical domains --- melody, harmony, rhythm, and dynamics. 

\textbf{Chapter~\ref{chap:rhythm_rsos}: Modelling Rhythm.} This chapter refines the scope of Chapter~\ref{chap:xai_rsi} to focus solely on the importance of rhythm to jazz improvisation style. We develop a jazz pianist identification model trained on handcrafted rhythmic features extracted from \GLS{JTD}. These features are derived from prior empirical and ethnographic accounts of jazz improvisation and relate to several high-level categories including ``feel'', ``swing'', and ``complexity''. Several features in an additional ``coordination'' category attempt to capture the interaction between members of the rhythm section and how this might relate to the style of the pianist.

\textbf{Chapter~\ref{chap:mp_network}: Modelling Ensemble Interaction.} This chapter focuses on modelling the mechanisms by which jazz improvisation actually takes place, using several of the features first defined in Chapter~\ref{chap:jtd_tismir} and~\ref{chap:rhythm_rsos}. We use temporal latency --- such as that introduced by networked communication platforms like Zoom --- as an experimental manipulation to disrupt the tight temporal coordination of action that is typically involved in ensemble jazz performances. We gather data from five professional duos of musicians via a novel software platform that emulates network latency in a controllable fashion. We then use linear causal modelling and computer simulations to explore the strategies they employ to coordinate with one another in the presence and absence of latency, and relate these strategies to descriptions given by the musicians of their own performances.

% \textbf{Chapter~\ref{chap:condition_gen}: Style-Conditioned Generative Modelling.} Unlike the previous chapters, this chapter focuses on training machine learning models to \textit{generate} new music in symbolic form, rather than understand existing music. Our contributions here are twofold. Firstly, we develop an automated method to link three existing datasets of transcribed jazz performances (including \GLS{JTD}) with high-quality subgenre annotations. Secondly, we use this data (alongside recordings gathered in Chapter~\ref{chap:mp_network}) to condition a large music language model to produce jazz performances in the style of particular subgenres and performers. In this way, the chapter wraps-up the work of the entire thesis --- using the datasets introduced in Chapters~\ref{chap:jtd_tismir} and~\ref{chap:mp_network}, while maintaining the focus on improvisation style from Chapters \ref{chap:xai_rsi} and \ref{chap:rhythm_rsos} --- while also looking to the future of symbolic music modelling research.

\textbf{Chapter~\ref{chap:discussion}: Discussion.} This chapter concludes the thesis by summarising the outcomes of the work, discussing its limitations, and offering suggestions for future research.