\chapter{Introduction}

Improvisation is part of many musical traditions. While definitions of improvisation vary, most agree that it involves the spontaneous creation of musical material, as opposed to the performance of pre-composed or pre-planned work. This practice has long fascinated musicians, composers, and scientists across a range of disciplines due to its intricate balance of creativity and technique, its challenges for analysis and modelling, and its apparent deep links with cognition, psychology, and linguistics.

Jazz is perhaps one of the most diverse musical forms reliant on improvisation to have emerged in the twentieth century. With roots in African, American, and European traditions, jazz has become part of the intangible heritage of many cultures where it is practised \citep{Feld2012}, and is studied at universities and colleges worldwide \citep{Berliner1994}. Through improvisation, jazz musicians manipulate many different aspects of the music they play, such as the harmony, melody, and rhythm of an underlying composition. In group settings, these choices must also be negotiated collectively between the members of an ensemble for a performance to be successful \citep{Monson1996}.

The widespread freedoms that are afforded to jazz improvisers render the formalization of this music a challenging task for researchers in the field of Music Information Retrieval (\GLS{MIR}). Computational modelling is one way of addressing this issue. Good models can explicitly address the ambiguities and assumptions that are inherent in discourse surrounding jazz, which often involves terms such as ``feel", ``interaction", and ``groove" that may be straightforward to define colloquially but difficult to locate in actual examples of the music. They can also provide a framework for studying improvisation systematically, bridging the gap between subjective interpretation and objective analysis --- with exciting potential applications both to digital humanities research and music education.

Despite the possibilities that computational modelling unlocks for the study of jazz improvisation, the extent to which these have been fully explored is debatable. For many years, \GLS{MIR} has been a primarily ``task-oriented" research field. New models are typically evaluated based on the extent that they improve upon the state-of-the-art in some objective metric. With relation to jazz specifically, these tasks can include the automatic alignment of notation to an original audio recording \citep{Shanin2023}, the detection of structural boundaries separating different improvised solos \citep{Balke2022}, and the automatic transcription of recordings into musical notation \citep{Riley2024-omnibook}.

This work is undoubtedly valuable in and of itself, and has led to numerous technologies that can help to inspire future music creation, such as by generating accompaniment to improvisations by human performers \citep{Ostermann2021, Keller2013} or rendering their playing in the styles of particularly well-known composers \citep{George2019}. But the extent to which these models have been developed or applied to better understand how this music works is altogether limited \citep{Borsan2023}. It still seems as if there is much left to discover about jazz improvisation using computational methods.

One challenge involved in modelling the complexity of jazz improvisation is the paucity of available data. Unlike Western classical music, the primary musical ``document" involved in jazz is typically not a notated score, but an audio recording of a performance. While interesting research can be accomplished by training models directly on representations of sound recordings (e.g., spectrograms, waveforms), many \GLS{MIR} tasks instead require symbolic data --- abstract, human-interpretable representations like chord symbols, pitch-class sets, or MIDI ``piano rolls". Creating this data often has required lengthy processes of annotating recordings by hand \citep{Balke2022, Pfleiderer2017, Goto2002}, limiting the scope of previous modelling research to a relatively small number of musical performances. However, recent advancements in neural audio processing offer the chance to render these processes obsolete, with the potential for dramatically scaling up this research.

Another challenge relates to how these models can be explained in ways that are interpretable and meaningful for those engaged with this music. Computational models can learn to rely on features that are extremely powerful for the task they are trained to perform, but otherwise not interpretable to humans. In task-oriented applications --- where the primary goal is achieving accurate results --- this may be of little importance. However, for those interested in using these models to better understand the structure of the underlying data, making these models transparent and accessible remains challenging. While numerous techniques for interpreting machine learning models have emerged \citep[see][for a recent review]{Hassija2024}, the extent to which these can be applied to generate explanations of complex forms of music such as jazz remains to be seen.

This thesis aims to address these problems within the existing literature. Not only do we intend to advance the current state-of-the-art in the computational modelling of jazz improvisation in the symbolic domain, but we aim also to interpret these models to learn more about jazz improvisation style and the ways in which this music is produced. In this way, our focus is on what Derek \citet{Bailey1992} has called the ``nature and practice" of improvisation. We train our models using large datasets comprising hundreds of hours of annotated performances, achieving a scale rarely seen in prior computational research. Our work is musically informed, insofar as our models are interpreted in light of not only their abstract statistical properties but also their connections with prior research on jazz improvisation from the humanities.

\section{Scope}

The scope of this research extends to what is typically known as ``conventional" (variously also referred to as ``straight-ahead", ``mainstream") jazz. This involves improvisation based on ``tunes in time" \citep{Bailey1992}, typically occurring over harmonic sequences of set length that may be derived from popular song forms and that are played within a (notionally) strict sense of musical time \citep[``standards": see][]{Gioia2012-standards}. This is different from ``free" jazz improvisation, where these materials are typically absent. Most prior computational and empirical research has addressed ``conventional" jazz improvisation, with a limited number of exceptions \citep[e.g.,][]{Pressing1987, Pras2017}.

Alongside these stylistic considerations, we also restrict ourselves to the three instruments that constitute the jazz ``rhythm section" --- piano, bass, and drum kit. We focus on these instruments specifically as they form the backbone of most conventional jazz, providing the harmonic, rhythmic, and structural foundations of a performance over which ``solo" improvisations (that may be made by members of the rhythm section) take place. From a technical standpoint, methods capable of processing audio recordings by these instruments are considerably more advanced than many other instruments associated with jazz, such as the saxophone \citep[although here see][]{Riley2024-omnibook}.

In the remainder of this introduction, we review previous computational work addressing improvised jazz, further define the motivating factors and themes underpinning the present research, and outline the structure and contributions of the thesis.

\section{Prior Research}

The earliest computational research into jazz improvisation dates to the 1970s and 80s, with the efforts of \citet{Urlich1977} and \citet{Fry1980} to develop systems capable of generating and synthesising jazz-like ``improvisations". Subsequent work has embraced developments in natural language processing, information theory, machine learning, cognitive psychology, neuroscience, and audio signal processing (amongst other fields). Computational research involving jazz and improvised music now appears widely in conference proceedings and journals dedicated both to \GLS{MIR} and a general scientific audience.

As we cannot discuss all computational research into jazz, we can instead summarise key trends with regards to modelling different musical concepts (e.g., rhythm, harmony, melody, form), as well as research into the modelling of musical style and ensemble performances. These topics are selected to provide a broad overview of the computational literature on jazz improvisation that is relevant to every chapter of the thesis. We further review the specific literature that is relevant to each modelling task considered in this work at the start of each chapter. 

\subsection{Rhythm}\label{sec:lit_review_rhythm}

Rhythm and timing have proved fruitful subjects for computational jazz research since at least the 1990s. This is perhaps due to the nature of the data that is required. Timing can be effectively quantified using only a vector of note onset or offset times, meaning that (unlike comparable analyses of melody and rhythm, for instance) a full notated transcription of a performance is not typically necessary. 

\subsubsection{``Swing"}

One prominent line of research involves the analysis of the ``swing" rhythm that is characteristic of this music, defined as the subdivision of the musical pulse into long-short groupings. \citet{Rose1989} quantified this as the ratio of long to short notes within each grouping: subsequent research has demonstrated that these ``swing ratios" vary as a function of both the tempo \citep{Ellis1991, Friberg2002, Honing2008, Dittmar2018, Foster2021} and genre \citep{Corcoran2021} of a performance. Performers also show a preference for particular swing ratios, with this apparently acting as a ``signature" of their own improvisation style \citep{Lindsay2007, Corcoran2021, Dittmar2018, Benadon2006}. \citet{Cheston2022} demonstrated that this signature varies between drummers depending on whether they are playing by themselves or accompanying an ensemble. 

\subsubsection{Synchronisation}

Analysing ensemble synchronisation is a related strand of research. \citet[p. 277]{Keil1987} referred to ``the little discrepancies ... between rhythm section and soloists" as ``participatory discrepancies". This has become particularly influential in subsequent research. Jazz soloists have frequently been demonstrated to delay their downbeat with respect to that implied by the rhythm section, perhaps to manifest a sensation of ``laying back" in their playing \citep{Doffman2014, Ellis1991}. Tight synchrony between musicians in the rhythm section is frequently observed, with delays between bass and drums of less than ten milliseconds being commonly reported in prior experimental work \citep{Kilchenmann2015, Doffman2014}.

Evidence for whether these minute discrepancies in swing and synchrony are directly perceivable by listeners remains inconclusive. \citet{Butterfield2010} found that most listeners are unable to discern a small discrepancy in timing between musicians across a variety of musical tempos. However, \citet{Nelias2022} demonstrated that slight downbeat delays between a soloist and ensemble enhanced the perceptual salience of swing, while \citet{Kilchenmann2015} found a small effect of timing discrepancies on the body movements of listeners. Both of these findings were restricted to jazz experts and professional musicians only.

\subsection{Harmony}

Owing to its combinatorial complexity and distinctiveness, jazz harmony has been extensively studied in the modelling literature. 

\subsubsection{Chord Progressions}

One approach involves modelling the harmony represented by jazz ``lead sheets", which provide a basic indication of the underlying chords, melody, and form of a composition that performers elaborate on during improvisation. \citet{Rohrmeier2020} proposed a theoretical framework of jazz lead sheet harmony based on formal grammars designed to capture the hierarchical function of common compositional devices in jazz (e.g., substitution, ``out-of-key" chords). Similar models have been implemented computationally \citep[e.g., by][]{Keller2013}. \citet{Granroth-wilding2014} proposed an abstract, context-free probabilistic model of jazz harmony that was subsequently refined with reference to the ``twelve-bar blues" form by \citet{Katz2017}. The performance of grammar-based models of jazz harmony can also be improved with the addition of grammars based on rhythmic information \citep{Harasim2019}.

\subsubsection{Chord Realisation}

A separate task involves modelling the actual realisation of a jazz chord progression from a lead sheet, which typically necessitates both harmonising individual chords and combining these efficiently into sequences through processes of voice-leading. \citet{Harrison2020-voiceleading} investigated the latter problem by developing a linear model to quantify the desirability of a given voice leading for a chord progression that, although trained initially on chorale harmonisations, proved capable of generating realistic interpretations of jazz standards. \citet{Kitahara2008} also explored the problem of efficient jazz voice leading by developing separate Bayesian networks for both bass and piano voicing generation. \citet{Chen2020-jazzification} considered the problem of generating both voice-leading and harmonisations for a plain chord progressions (i.e., a sequence of triads) end-to-end as part of a process they call ``chord jazzification". Finally, the task of modelling harmonic similarity between different harmonisations of the same underlying composition (``contrafacts") was addressed by \citet{Bunks2023}. 

\subsection{Melody}

Modelling jazz improvisation in the melodic domain is another area of considerable research interest, particularly in generative applications. 

\subsubsection{Rule-based Approaches}

One common approach involves the assumption that melodic jazz improvisation takes place based on a set of rules (such as associating particular chord progressions with certain musical scales), and that these rules can be approximated by an algorithm. \citet{Johnson-laird2002} developed a rule-based algorithm for generating jazz bass lines based on contour, chord progressions, chord-scale relationships, and passing tones. \citet{Norgaard2013-cognitive}, however, found that generating ``solo" improvisations using formal schemata produced improvisations with fewer recurrent patterns than those found in actual corpora, suggesting that such rules alone are insufficient to model the complexity of melodic improvisation in jazz. Generative models based on rules can also produce improvisations that may fulfil the basic harmonic qualities of jazz but which ultimately lack musical interest \citep{Pachet2012}. 

\subsubsection{Pattern-based Approaches}

In contrast to learning rules for improvisation, a pattern-based approach assumes that jazz improvisation draws from a repertoire of stock melodic sequences that can be approximated as a formal grammar using probabilistic modelling \citep{Pressing1987}. \citet{Gillick2010} learned grammatical representations of melodic jazz improvisation through Markov modelling and unsupervised clustering of short melodic contours and pitch-class interval patterns. \citet{Cross2023-intervals} have since explored the relationship between jazz melodic patterns and metrical positioning.

Similar techniques can be applied to learn melodic grammars representative of the style of individual jazz musicians. \citet{Norgaard2014-how} applied probabilistic modelling techniques based on interval $n$-grams to a corpus of improvisations by the influential jazz saxophonist Charlie Parker, finding that the vast majority of Parker's recordings could be represented using a relatively small formal grammar. Similar work has also been conducted for jazz pianist Bill Evans \citep{Gross2011}. Expanding beyond soloists, \citet{Riley2023} have also demonstrated the presence of common melodic patterns in the ``walking" lines played by several well-known jazz bassists.

The ``Dig that Lick" (\GLS{DTL}) project represents an important contribution to pattern-based modelling of melodic jazz improvisations.\footnote{\url{https://dig-that-lick.eecs.qmul.ac.uk/}} Using pattern mining techniques to extract short melodic sequences (``licks") from automatically generated transcriptions of over 1000 jazz recordings, the \GLS{DTL} project developed a database of melodic patterns that can be explored using an interactive web application \citep{Frieler2018}. Subsequent work using this dataset has involved creating a ``vocabulary" of jazz melodic lines derived from Markov models \citep{Frieler2019-jazzlines} and tracking the transmission of particular patterns across performers and jazz history using objective measurements of similarity \citep{Frieler2019-Anatomy}. The \GLS{DTL} project represents an important step to apply advances in audio signal and natural language processing to generate a large dataset of annotated improvisations with minimal human intervention, the scope of which we expand here to consider numerous instruments in a single ensemble. 

\subsubsection{Evolutionary Modelling}

A third approach to modelling jazz melody borrows from evolutionary computing and involves the development of genetic algorithms that learn to refine jazz melodies sampled from an initial population. \citet{Biles1994} implemented an algorithm that learns from a population of existing solos and obtains assessments from a human rater in real-time, which in turn provides fitness values that are used to refine subsequent generations. In contrast, \citet{Papadopoulos1998} used a fitness function consisting of a series of musically informed heuristics (e.g., avoiding excessively large intervals and long durations), demonstrating that this alone could create feasible jazz improvisations from a randomly initialised population of melodies without human supervision. \citet{Nam2019} demonstrated that the diversity of melodies can be improved by optimizing the mutations applied to melodic patterns that demonstrate high fitness.

\subsubsection{Modelling Multiple Musical Concepts}

Finally, we note that a number of recent papers addressing jazz have attempted to model multiple musical concepts (i.e., harmony, rhythm, form) simultaneously. For instance, \citet{Wu2020-frontline} developed a neural sequence model capable of generating melodic lines, chord progressions, and structural patterns for a jazz composition end-to-end. \citet{Velenis2023} adopted a multi-task framework using a transformer encoder backbone, where the composer, harmonic style, form, and subgenre (amongst other features) of a jazz lead sheet are predicted simultaneously. These and similar works \citep[e.g.,][]{Ramirez2010, Abeser2015-scoreinformed, Zheng2017-genre} have exciting potential not only for improving the performance of the underlying models but also generating a more holistic account of jazz improvisation.

\subsection{Style}

Jazz is a remarkably diverse form of music, both in the styles of individual performers and composers and across distinct subgenres. There has been some recent interest in modelling the diversity of jazz styles using supervised-learning algorithms. 

\subsubsection{Composer and Performer Identification}

One possible task here involves predicting the composer of a jazz standard, given a lead sheet representation of a composition. \citet{Hedges2014} demonstrated that the composer of a jazz composition can be identified solely using its underlying chord sequence, with their model also able to visualise particularly idiomatic harmonic progressions associated with different composers using a tree-based structure. Predicting the composer of a jazz standard was also one of the problems investigated as part of the multi-task framework adopted by \citet{Velenis2023}. 

A related task involves predicting the performer of a jazz improvisation from several candidates. \citet{Ramirez2010} demonstrated how pitch, timing, and timbral features extracted automatically from audio recordings can accurately identify different jazz saxophonists, even from short musical phrases. \citet{Edwards2023} expanded on this by learning representations capable of identifying different pianists directly from symbolic transcriptions of their performances using recurrent neural networks. Finally, the relationship between artist identity, intonation, and vibrato for jazz wind instrumentalists has been considered by \citet{Abeser2015-scoreinformed}. We provide an in-depth review of performer identification work beyond jazz within the introduction of Chapter \ref{chap:rhythm_rsos}.

\subsubsection{(Sub)-Genre Identification}

The task of classifying distinct subgenres of jazz has been considered in a small number of papers, including several that also attempt to classify individual composers or performers \citep[e.g.,][]{Hedges2014, Abeser2015-scoreinformed, Velenis2023}. \citet{Eppler2014} used tree-based models and handcrafted feature sets capturing rhythm, tempo, and tonality to classify the subgenre of a jazz recording. \citet{Quinto2017} trained numerous supervised learning architectures to identify three jazz subgenres (swing, bebop, and acid) using acoustic features, with the greatest success observed for recurrent neural networks. However, the extent to which their models learned actual musical qualities distinct to these subgenres --- as opposed to simply the differences in recording practices apparent between different historical time periods \citep[see][]{Edwards2023} --- remains unclear.

Related to this is the \GLS{MIR} task of genre identification, where jazz is often included as a target class for classification. A full review of music genre classification models trained using symbolic features is given in \citet{Correa2016}. Here, we note simply that interpreting these models can provide insights into the specific musical qualities that best distinguish jazz from other genres. \citet{Dervakos2022} used feature-based techniques to explore the regions of a MIDI ``piano roll" representation that pushed a convolutional neural network to classify this as jazz or another genre. \citet{Zheng2017-genre} used features derived from melodic contour and duration to derive musicological interpretations from a genre classification model trained on both jazz and classical pieces. A comparable approach was taken by \citet{Simsekli2010} using only the bass line of the music. 

A small number of papers have attempted to evaluate computationally the differences in harmonic syntax between jazz and other musical genres. \citet{Harrison2018-harmony} used a feature-based approach informed by psychological modelling to compute the relative importance of abstract sensory and music-theoretic terms (e.g., ``harmonicity", ``voice-leading distance") extracted from chord progressions to classifications of Western classical, popular, and jazz music. A comparable approach was taken by \citet{Anglade2009}, who employed a tree-based classifier using features derived from chord progressions to develop transparent ``rules" separating the harmony of jazz from classical and popular music.

\subsubsection{Modelling Jazz Styles over Time}

A related area of research is modelling the historical development of jazz improvisation styles across the past century. \citet{Corcoran2021} demonstrated a monotonic increase in the average swing ratio from the earliest jazz styles (e.g., ``traditional") to more recent (``postbop") styles. \citet{Weis2018} found that the complexity of pitch class representations obtained from both audio-based chromagrams and symbolic transcriptions of jazz performances followed a roughly linear path over the past century, with minimal differences between input types. \citet{Frieler2016} developed a method whereby an improvisation is annotated with ``mid-level units" (e.g., ``quotation", ``ascending line"). Some evidence emerged from their analysis that the diversity of the units employed within an improvisation has increased over the past century.

\subsection{Ensembles}

Another area of concern to the present thesis involves modelling the strategies that are actually used to perform music in an ensemble. \citet{Bantula2016} developed a method to quantify the influence of accompanying rhythm section musicians on a soloist: features are extracted from the performance of the soloist and the soloist combined with the ensemble, separate classification models are trained on both datasets, and the accuracy of both models is compared. The majority of this work has considered performances of notated Western classical music by ensembles including string quartets \citep{Chang2017, Wing2014, Timmers2014} and piano duets \citep{Goebl2009}, however, making this paper --- and the work of \citet{Jacoby2021} on African drumming ensembles --- somewhat unique. 

Outside of the computational modelling literature, understanding the ways in which improvised conduct is coordinated between musicians has seen greater interest from both psychologists and ethnographers. Previous work has studied the use of nonverbal feedback in duo improvisations \citep{Moran2015} and the pre-planning musicians engage in during rehearsal \citep{Dueck2013}. \citet{Doffman2014} quantified the timing synchronisation between members of a rhythm section with relation to the sensor-motor process of entrainment \citep{Clayton2020}. Finally, both \citet{Pras2017} and \citet{Schober2014} have evaluated the extent to which jazz musicians perceive each other's intentions during improvisation --- concluding that exactly shared understanding is not required for a performance to be successful.

\subsection{Datasets}

One limitation of many of the earliest computational studies of jazz improvisation is the restricted size of their datasets, often containing only a small number of recordings \citep[e.g., 6 recordings in][]{Friberg2002}. In response to this need, numerous large databases of annotated jazz performances and compositions have been developed and adopted by the community, perhaps the most well-known of which is the Weimar Jazz Database or \GLS{WJD} \citep{Pfleiderer2017}. We provide a complete review of this and other datasets of symbolic annotations of jazz performances \citep[e.g.,][]{Foster2021, Riley2023, Edwards2023, Goto2002} as part of our own such contribution in chapter \ref{chap:jtd_tismir}. 

We also note here that numerous datasets of specialized annotations exist for jazz, covering lead sheets and chord progressions \citep{Broze2013, Bunks2023, Eremenko2018, Harasim2019, Pachet2013-database}, formal structures \citep{Balke2022, Eremenko2018}, and harmonic and melodic progressions \citep{Adegbija2023}. While we do not specifically refer to these datasets in this work, they represent an important step by the community towards facilitating the training of computational models on large amounts of data.

\subsection{Jazz Studies, Ethnography, and the Humanities}

While the methodology of our work derives primarily from statistical modelling and machine learning, interpreting our results requires us to engage with the broader jazz studies literature. In particular, we note how 

We draw particularly from two landmark works in music ethnography by \citet{Berliner1994} and \citet{Monson1996}, which both evaluate the processes with which jazz musicians (individually and collectively) learn to improvise through extensive analysis of interviews given by well-known performers. This focus extends to several oral histories of jazz edited by \citet{Sidran1992}, \citet{Lyons1983}, and \citet{Gottlieb1997}, which feature discussions by well-known jazz musicians (including several featured in our database, described in chapter \ref{chap:jtd_tismir}) of their creative process. Finally, we also draw from several historical overviews of jazz by \citet{Gioia2011} and \citet{Shipton2005} alongside pedagogical texts by \citet{Levine2011-1} and \citet{Haerle1994}, especially in Chapter \ref{chap:xai_rsi}. 

\section{Motivations}
In this section, we provide an overview of three distinct motivations central to this research.

\textbf{Supervised learning of diverse musical corpora.} One motivation for this work is to understand the different musical features that have underpinned the diversity of jazz improvisation styles that have manifested across the past century. We therefore apply our computational models to the analysis of large corpora representing various subgenres, formats, and historical eras of jazz music. While corpus analyses can be conducted in a variety of ways, our primary methodology consists of training and interpreting supervised classification models. In contrast to unsupervised or semi-supervised approaches, this allows us to understand how particular musical features and concepts we extract might explicitly relate to the classes (e.g., performers, musical styles, etc.) that the model is trained to identify.

\textbf{Modelling of improvisation style.} A second factor motivating this work is to understand the diversity of improvisation styles associated with jazz. While ``style" can refer to different subgenres of jazz, we primarily focus here on modelling the style of individual performers \citep[cf.][]{Quinto2017, Eppler2014}. Training computational models to identify the style of particular musicians is an interesting task for \GLS{MIR} research, but one that has mostly been limited to practitioners of Western classical music \citep[e.g.,][]{Mahmudrafee2023, Tang2023}. Indeed, \citet[p. 192]{Berendt1976} has claimed that ``there doesn't exist ... any form of notation, graphic representation, and computer analysis capable of satisfactorily registering the subtlety of ... [the] specific distinctions between groups and individuals" in jazz. By developing such tools for computational analysis, we hope to demystify the different factors that contribute to the style of several particularly well-known musicians, with exciting potential applications for both digital humanities and music education research.

\textbf{Modelling of musical ensembles.} A third factor motivating this work is to model the processes by which musical improvisation actually occurs. The interaction between the members in an ensemble can substantially influence the success of their music-making, as well become associated with the style of individual performers. Previous research involving the modelling of joint action and coordination \citep[e.g.,][]{Wing2014, Jacoby2021, Timmers2014} offers an interesting possibility to enhance the modelling of musical style by incorporating these ensemble-level features. Additionally, by comparing models trained on both ensemble and unaccompanied improvisations, we seek to better understand the differences between both forms of music-making.

\section{Themes}

Alongside these motivations, our research also explores a number of secondary themes, which we outline below.

\textbf{Musically informed modelling.} For many supervised machine-learning architectures, decisions must be made as to which features are extracted from a performance for use during training and evaluation. While numerous methods exist for feature selection (e.g., dimensionality reduction, penalty terms, stepwise feature removal), we prefer to derive our features wherever possible from the musicological and ethnomusicological literature on jazz improvisation. This helps facilitate meaningful interpretations as our features are already likely to be well-understood by musicians and researchers \citep[here, see][]{Hamilton2024}, and also eliminates the requirement for post-hoc interpretation of the feature space \citep[as in][]{Foscarin2022}. The inverse can also be said to be true:  interpretations that are derived from abstract computational models gain credibility when they can be supported by statements from critics, musicologists, or performers themselves.

\textbf{Model comparison.} A substantial amount of research in \GLS{MIR} has been devoted to improving the state-of-the-art in music modelling, including the modelling of improvisation. However, detailed comparisons of different model architectures are surprisingly rare for several of the tasks we consider here, such as automatic performer identification. Here we subscribe to the claim made by \citet{Rudin2024} that ``amazing things come from having many good models": we provide a systematic comparison of many different architectures in Chapter \ref{chap:xai_rsi}, evaluating them not only in terms of predictive accuracy and performance but also ease of interpretability. Moreover, we note that interpretations of one model gain weight when they can be supported by others that may have learned different decision functions from the same data \citep{Breiman2001-cultures}.

\textbf{Model explainability.} There is a temptation in computational research to only use the current state-of-the-art techniques that yield the best results for any given task. Yet, as the complexity of any computational model increases, the extent to which its decision-making process can be understood by a human often (but not always) decreases \citep{Hassija2024}. While one approach to navigating this trade-off would be to employ only conventional techniques (e.g., linear modelling), we instead tackle this problem ``head-on", exploring a variety of modelling approaches and techniques for explaining their predictions across this work. Throughout this work we also develop numerous interactive web applications to demonstrate the models that we create and allow readers to draw their own conclusions from them.

\textbf{Symbolic versus acoustic modelling.} There exist two primary traditions of music modelling: (1) symbolic modelling, where a musical input is represented using formats such as notation, scores, and MIDI ``piano rolls", and (2) acoustic modelling, where the underlying sound is represented directly using methods such as waveforms and spectrograms. While the latter may sound appealing for jazz --- where the primary way a musical work is documented is through a recording, rather than in notation --- it has drawbacks. In particular, computational models trained on acoustic features may have high predictive power but low explainability, as the underlying representations may be unintuitive for non-technical readers \citep{Foscarin2022}. Instead, we prefer to work with symbolic data extracted from an audio recording, with the intention of facilitating intuitive and explainable musical analyses.

\textbf{Big data analysis.} A particular contribution of the present work is to revisit several ``classic" questions in the computational study of jazz --- including, for instance, swing and synchronization, which have both been studied extensively over the past thirty years (see section \ref{sec:lit_review_rhythm} --- with significantly larger datasets than have been employed in previous work. To do so, we leverage recent advances in audio signal processing to create a database of several hundred hours of jazz performances, annotated automatically. We release this database under a permissive, open source license to facilitate future research.

\section{Thesis Structure and Contributions}

Our primary contributions in this work consist of advancements across three distinct tasks: modelling (1) improvisation style, (2) rhythm, and (3) ensemble interaction. Each subject is covered in an individual chapter of the thesis (Chapters \ref{chap:rhythm_rsos}--\ref{chap:mp_network}). These are preceded by Chapter \ref{chap:jtd_tismir}, which outlines an open source dataset of annotated recordings used to train and evaluate many of our models. Finally, the thesis concludes with Chapter \ref{chap:discussion}, which discusses the outcomes of the present work. We provide a short overview of each chapter below.

\textbf{Chapter \ref{chap:jtd_tismir}:} introducing the Jazz Trio Database. This chapter addresses the problem of scaling-up computational music research by introducing an automated pipeline for generating symbolic annotations from jazz recordings. Pre-trained deep-learning models are applied to ``unmix" an audio recording into separate signals for multiple instruments, which are then automatically annotated using existing transcription models. We use this pipeline to generate the Jazz Trio Database (\GLS{JTD}), an open source dataset of annotated jazz rhythm section performances with a total of 133.5 hours of annotated audio.

\textbf{Chapter \ref{chap:xai_rsi}:} modelling improvisation style. This chapter considers how computational modelling can disentangle the elements contributing to ``style" in jazz improvisation. We construct a series of supervised learning models that learn to identify particular performers from recordings in \GLS{JTD} and other datasets, and then we interrogate the learned decision functions of these models to understand how these judgements were made. This culminates in a novel deep neural network architecture inspired by mixture-of-experts modelling that achieves state-of-the-art predictive accuracy, with a factorised structure that allows its predictions to be explained in terms of four fundamental musical domains --- melody, harmony, rhythm, and dynamics. 

\textbf{Chapter \ref{chap:rhythm_rsos}:} modelling rhythmic style. This chapter refines the scope of the previous chapter to focus solely on the importance of rhythm to jazz improvisation style. We develop a jazz pianist identification model trained on handcrafted rhythmic features extracted from \GLS{JTD}. These features are derived from prior empirical and ethnographic accounts of jazz improvisation and relate to several high-level categories including ``feel", ``swing", and ``complexity". Several features in an additional ``coordination" category attempt to capture the interaction between every member of the ensemble, including the pianist. 

\textbf{Chapter \ref{chap:mp_network}:} modelling ensemble interaction. This chapter focuses on modelling the mechanisms by which jazz improvisation actually takes place, using several of the features first defined in Chapter \ref{chap:rhythm_rsos}. We use temporal latency --- such as that introduced by networked communication platforms like Zoom --- as an experimental manipulation to disrupt the tight temporal coordination of action that is typically involved in ensemble jazz performances. We gather data from five professional duos of musicians via a novel software platform that emulates network latency in a controllable fashion. We then use linear causal modelling and computer simulations to explore the strategies they employ to coordinate with one another in the presence and absence of latency. 

\textbf{Chapter \ref{chap:discussion}:} discussion. This chapter concludes the thesis by summarising the outcomes of the work, discussing its limitations, and offering suggestions for future research.