\chapter{Introduction}\label{chap:introduction}

Improvisation is a central aspect of many musical traditions. While definitions of improvisation vary, most agree that it involves the spontaneous creation of musical material, as opposed to the performance of pre-composed or pre-planned work. This practice has long fascinated musicians, composers, and scientists across a range of disciplines due to its intricate balance of creativity and technique, its challenges for analysis and modelling, and its apparent deep links with cognition, psychology, and linguistics.

Jazz is amongst the richest musical forms reliant on improvisation to have emerged in the twentieth century. With roots in African, American, and European traditions, jazz has become part of the intangible heritage of many cultures where it is practised \citep{Feld2012}, and is studied at universities and colleges worldwide \citep{Berliner1994}. Through improvisation, jazz musicians manipulate many different aspects of the music they play, such as the harmony, melody, and rhythm of an underlying composition. In group settings, these choices must also be negotiated collectively between the members of an ensemble for a performance to be successful \citep{Monson1996}.

The widespread freedoms that are afforded to jazz improvisers render the formalization of this music a challenging task for researchers in the field of Music Information Retrieval (\GLS{MIR}). Computational modelling may prove to be one way of addressing this issue effectively. Good models can explicitly address the ambiguities and assumptions that are inherent in discourse surrounding jazz, which often involves terms such as ``feel'', ``interaction'', and ``groove'' that may be straightforward to use colloquially but difficult to locate in actual examples of the music. Computational models can also provide a framework for studying improvisation systematically, bridging the gap between subjective interpretation and objective analysis --- with exciting potential applications both to digital humanities research and music education.

Despite the possibilities that computational modelling unlocks for the study of jazz improvisation, the extent to which these have been fully explored remains debatable. For many years, \GLS{MIR} has been a primarily ``task-oriented'' research field. New models are typically evaluated based on the extent that they improve upon the state-of-the-art in some objective metric. With relation to jazz specifically, these tasks can include the automatic alignment of notation to an original audio recording \citep{Shanin2023}, the detection of structural boundaries separating different improvised solos \citep{Balke2022}, and the automatic transcription of recordings into musical notation \citep{Riley2024-omnibook}.

This work is undoubtedly valuable in and of itself, and has led to numerous technologies that can help to inspire future music creation, such as by generating accompaniment to improvisations by human performers \citep{Ostermann2021, Keller2013} or rendering their playing in the styles of particularly well-known composers \citep{George2019}. But the extent to which these models have been developed or applied to better understand how this music works is altogether limited \citep{Borsan2023}. Despite the diverse possibilities that computational modelling has unlocked for the analysis of styles of Western classical music \citep[e.g.,][]{Foscarin2022}, it still seems as if there remains much left to discover about jazz improvisation using computational methods.

One challenge involved in modelling the complexity of jazz improvisation is the paucity of available data. Unlike Western classical music, the primary musical ``document'' involved in jazz is typically not a notated score, but an audio recording of a performance. While interesting research can be accomplished by training models directly on representations of sound recordings (e.g., spectrograms, waveforms), many \GLS{MIR} tasks instead require symbolic data --- abstract, human-interpretable representations like chord symbols, pitch-class sets, or MIDI ``piano rolls''. Creating this data often has required lengthy processes of annotating recordings by hand \citep{Balke2022, Pfleiderer2017, Goto2002}, limiting the scope of previous modelling research to a relatively small number of musical performances. However, recent advancements in neural audio processing offer the chance to render these processes obsolete, with the potential for dramatically scaling up this research \citep[e.g.,][]{Edwards2023, Riley2024-omnibook, Shanin2023}.

Another challenge relates to how these models can be explained in ways that are interpretable and meaningful for those engaged with this music. Computational models can learn to rely on features that are extremely powerful for the task they are trained to perform but that are uninterpretable to humans. In task-oriented applications --- where the primary goal is achieving accurate results --- this may be of little importance. However, for those interested in using these models to better understand the structure of the underlying data, making these models transparent and accessible remains challenging. While numerous techniques for interpreting machine learning models have emerged \citep[see][for a recent review]{Hassija2024}, the extent to which these can be applied to generate explanations of complex forms of music such as jazz remains to be seen.

This thesis aims to address these problems within the existing literature. Not only do we intend to advance the current state-of-the-art in the computational modelling of jazz improvisation in the symbolic domain across tasks such as automatic performer identification, but we aim also to interpret these models to learn more about jazz improvisation style and the ways in which this music is produced. In this way, our focus is on what Derek \citet{Bailey1992} has called the ``nature and practice'' of improvisation. We train our models using large datasets comprising hundreds of hours of annotated performances (including a new dataset created as part of this work), achieving a scale rarely seen in prior computational research. Our work is musically informed, insofar as our models are interpreted in light of not only their abstract statistical properties but also their connections with prior research on jazz improvisation from the humanities.

In the remainder of this introduction, we (1) review previous computational work addressing improvised jazz, (2) define the motivations and themes of the present research in light of prior work, (3) describe the scope of this work, and (4) outline the structure and contributions of the thesis.

\section{Prior Research}

The earliest computational research into jazz improvisation dates to the 1970s and 80s, with the efforts of \citet{Urlich1977} and \citet{Fry1980} to develop systems capable of generating and synthesising jazz-like ``improvisations''. Subsequent work has embraced developments in natural language processing, information theory, machine learning, cognitive psychology, neuroscience, and audio signal processing (amongst other fields). Computational research involving jazz and improvised music now appears widely in conference proceedings and journals dedicated both to \GLS{MIR} and a general scientific audience.

As we cannot discuss all computational research into jazz, we can instead summarise key trends with regards to modelling different musical concepts or domains (e.g., rhythm, harmony, melody), as well as research into the modelling of musical style and ensemble performances. These topics are selected to provide a broad overview of the types of computational literature on jazz improvisation that are relevant to each chapter of the thesis. We further review the specific literature that is relevant to the specific modelling tasks considered in this work at the start of every chapter. 

\subsection{Rhythm}\label{sec:lit_review_rhythm}

Rhythm and timing have proved fruitful subjects for computational jazz research since at least the 1990s. This is perhaps due to the nature of the data that is required. Timing can be effectively quantified using only a vector of note onset or offset times. This means that (unlike comparable analyses of melody and harmony, for instance) a full notated transcription of a performance is not typically necessary.

\subsubsection{``Swing''}

One prominent line of research involves the analysis of the ``swing'' rhythm that is characteristic of jazz music, defined as the subdivision of the quarter note musical pulse into long-short groupings of eighth notes. \citet{Rose1989} was the first to quantify swing as the ratio of long to short notes within each grouping: subsequent research has demonstrated that these ``swing ratios'' vary as a function of both the tempo \citep{Ellis1991, Friberg2002, Honing2008, Dittmar2018, Foster2021} and subgenre \citep{Corcoran2021} of a performance. Performers also show a preference for particular swing ratios, with this apparently acting as a ``signature'' of their own improvisation style \citep{Lindsay2007, Corcoran2021, Dittmar2018, Benadon2006}. \citet{Cheston2022} demonstrated that this stylistic signature varies between drummers depending on whether they are playing by themselves or accompanying an ensemble. 

\subsubsection{Synchronisation}

Analysing ensemble synchronisation is a related strand of research. \citet[p. 277]{Keil1987} referred to ``the little discrepancies ... between rhythm section and soloists'' as ``participatory discrepancies''. This notion has become particularly influential in subsequent research. Jazz soloists have frequently been demonstrated to delay their downbeat with respect to that implied by the accompanying musicians in an ensemble, perhaps to manifest a sensation of ``laying back'' in their playing \citep{Doffman2014, Ellis1991}. Tight synchrony between musicians in the accompanying ``rhythm section'' has been frequently observed, with delays between bass and drums of less than ten milliseconds reported in prior experimental work \citep{Kilchenmann2015, Doffman2014}.

Evidence for whether these minute discrepancies in swing and synchrony are directly perceivable by listeners remains inconclusive. \citet{Butterfield2010} found that most listeners are unable to discern a small discrepancy in timing between musicians across a variety of musical tempos. However, \citet{Nelias2022} demonstrated that slight downbeat delays between a soloist and ensemble enhanced the perceptual salience of swing, while \citet{Kilchenmann2015} found a small effect of timing discrepancies on the body movements of listeners. Both of these findings were restricted to jazz experts and professional musicians only, however.

\subsection{Harmony}

Owing to its combinatorial complexity and sonic distinctiveness, jazz harmony has been extensively studied in the modelling literature. 

\subsubsection{Chord Progressions}

One approach involves modelling the harmony represented by jazz ``lead sheets'', which provide a basic indication of the underlying chords, melody, and form of a composition that performers elaborate on during improvisation. \citet{Rohrmeier2020} proposed a theoretical framework of jazz lead sheet harmony based on formal grammars designed to capture the hierarchical function of common compositional devices in jazz (e.g., substitution, ``out-of-key'' chords). Similar models have been implemented computationally \citep[e.g., by][]{Keller2013}. \citet{Granroth-wilding2014} proposed an abstract, context-free probabilistic model of jazz harmony that was subsequently refined with reference to the ``twelve-bar blues'' form by \citet{Katz2017}. The performance of grammar-based models of jazz harmony can also be improved with the addition of grammars based on rhythmic information \citep{Harasim2019}.

\subsubsection{Chord Realisation}

A separate task involves modelling the actual realisation of a jazz chord progression from a lead sheet, which typically necessitates both harmonising individual chords and combining these efficiently into sequences through processes of voice-leading. \citet{Harrison2020-voiceleading} investigated the latter problem by developing a linear model to quantify the desirability of a given voice leading for a chord progression that, although trained initially on chorale harmonisations, proved capable of generating realistic interpretations of jazz standards. \citet{Kitahara2008} also explored the problem of efficient jazz voice leading by developing separate Bayesian networks for both bass and piano voicing generation. \citet{Chen2020-jazzification} considered the problem of generating both voice-leading and harmonisations end-to-end for a plain chord progressions (i.e., a sequence of triads) as part of a process they call ``chord jazzification''. Finally, the task of modelling harmonic similarity between different harmonisations of the same underlying composition (``contrafacts'') was addressed by \citet{Bunks2023}. 

\subsection{Melody}

Modelling jazz improvisation in the melodic domain is another area of considerable research interest, particularly in generative applications. 

\subsubsection{Rule-based Approaches}

One common approach involves the assumption that melodic jazz improvisation takes place based on a set of rules (such as associating particular chord progressions with certain musical scales), and that these rules can be approximated by an algorithm. \citet{Johnson-laird2002} developed a rule-based algorithm for generating jazz bass lines based on contour, chord progressions, chord-scale relationships, and passing tones. \citet{Norgaard2013-cognitive}, however, found that generating ``solo'' improvisations using formal schemata produced improvisations with fewer recurrent patterns than those found in actual corpora, suggesting that such rules alone are insufficient to model the complexity of melodic improvisation in jazz. Generative models based solely on rules can also produce improvisations that may fulfil the basic harmonic and syntactical qualities of jazz but which ultimately lack musical interest \citep{Pachet2012}. 

\subsubsection{Pattern-based Approaches}

In contrast to learning rules for improvisation, a pattern-based approach assumes that jazz improvisation draws from a repertoire of stock melodic sequences that can be approximated as a formal grammar using probabilistic modelling \citep{Pressing1987}. \citet{Gillick2010} used Markov modelling and unsupervised clustering of short melodic contours and pitch-class interval patterns to learn grammatical representations of melodic, monophonic jazz improvisation. \citet{Cross2023-intervals} have since explored the relationship between melodic patterns and metrical positioning in jazz. Expanding beyond soloists, \citet{Riley2023} used automatic music transcription and source separation to analyse the appearance of common melodic patterns in the ``walking'' lines played by several well-known jazz bassists. Similar techniques can be applied to learn melodic grammars representative of the style of individual jazz musicians, rather than jazz as a whole. \citet{Norgaard2014-how} applied probabilistic modelling techniques based on interval $n$-grams to a corpus of improvisations by the influential jazz saxophonist Charlie Parker, finding that the vast majority of Parker's recordings could be represented using a relatively small formal grammar. Similar work has also been conducted for jazz pianist Bill Evans \citep{Gross2011}. 

The ``Dig that Lick'' (\GLS{DTL}) project represents an important contribution to pattern-based modelling of melodic jazz improvisations.\footnote{\url{https://dig-that-lick.eecs.qmul.ac.uk/}} Using pattern mining techniques to extract short melodic sequences (``licks'') from automatically generated transcriptions of over 1,000 jazz recordings, the \GLS{DTL} project developed a database of melodic patterns that can be explored using an interactive web application \citep{Frieler2018}. This application allows the user to view the patterns that particular jazz improvisers use most frequently. It is difficult to know if these patterns are truly idiomatic for each performer, however, versus simply being used often by many musicians: we revisit this issue in section \ref{sec:rsi_feature_importance_by_performer}. Subsequent work completed as part of the \GLS{DTL} project has involved creating a ``vocabulary'' of jazz melodic lines derived from Markov models \citep{Frieler2019-jazzlines} and tracking the transmission of particular patterns across performers and jazz history using objective measurements of similarity \citep{Frieler2019-Anatomy}. The \GLS{DTL} project represents an important step to apply advances in audio signal processing to generate a large dataset of annotated improvisations with minimal human intervention, the scope of which we expand here to consider numerous instruments in a single ensemble. 

\subsubsection{Evolutionary Modelling}

A third approach to modelling jazz melody borrows from evolutionary computing and involves the development of genetic algorithms that learn to refine jazz melodies sampled from an initial population. \citet{Biles1994} implemented an algorithm that learns from a population of existing solos and obtains assessments from a human rater in real-time, which in turn provides fitness values that are used to refine subsequent generations. In contrast, \citet{Papadopoulos1998} used a fitness function consisting of a series of musically informed heuristics (e.g., avoiding excessively large intervals and long durations), demonstrating that this alone could create feasible jazz improvisations from a randomly initialised population of melodies without human supervision. \citet{Nam2019} demonstrated that the diversity of melodies can be improved by optimizing the mutations applied to melodic patterns that demonstrate high fitness.

\subsection{Modelling Multiple Musical Domains}

The work we discussed in the preceding sections mostly considered individual musical domains in isolation, with little discussion (for instance) of how harmony and melody may interact. A number of recent papers have attempted to model several musical domains simultaneously, however. 

\citet{Wu2020-frontline} developed a neural sequence model capable of generating melodic lines, chord progressions, and structural patterns for a jazz composition end-to-end. While their model was able to generate short musical phrases and ``jazz-like'' grooves to some extent, it proved unable to match the longer overall structure of improvisations produced by humans. \citet{Velenis2023} adopted a multi-task framework where the composer, harmonic style, form, and subgenre (amongst other features) of a jazz lead sheet are predicted simultaneously by a transformer model. Using dimensionality reduction techniques and unsupervised learning, the features learned by this model could then be projected onto a lower-dimensional latent space to simultaneously show the similarities between jazz composers, historical eras, and subgenres. These and similar papers \citep[e.g.,][]{Ramirez2010, Abeser2015-scoreinformed, Zheng2017-genre} have exciting potential not only for improving the performance of the particular modelling tasks in question, but also generating a more holistic account of jazz improvisation and musical style. In Chapter \ref{chap:xai_rsi} we further contribute to this area with the introduction of a novel deep-learning architecture that learns separately from the melodic, harmonic, rhythmic, and dynamic content of a jazz performance in order to predict the improviser playing on a recording.

\subsection{Style}

Jazz is a remarkably diverse form of music, both in the styles of individual performers and composers and across distinct subgenres. There has been some recent interest in modelling the diversity of jazz styles using a variety of different learning algorithms.

\subsubsection{Composer Identification}

One possible task here involves predicting the composer of a jazz standard, typically using a lead sheet representation of one of their compositions. \citet{Hedges2014} demonstrated that the composer of a jazz composition can be identified solely using its underlying chord sequence, with their model also able to visualise particularly idiomatic harmonic progressions associated with different composers using a tree-based structure. As mentioned above, predicting the composer of a jazz standard was also one of the problems investigated as part of the multi-task framework adopted by \citet{Velenis2023}. While this work is interesting, the degree to which the ``composer'' of a jazz piece truly is responsible for its musical content is up for debate, especially considering how performers frequently change both the harmony (e.g., through chord substitutions), melody, and occasionally even the entire structure of a lead sheet \citep{Berliner1994}.

\subsubsection{Performer Identification}

A separate task instead involves identifying jazz \textit{performers}: here, the data source is typically a recording of an improvised performance, rather than a lead sheet. Early work in this area typically trained supervised learning models on ``handcrafted'' sets of quantitative features. For example, \citet{Ramirez2010} demonstrated how pitch, timing, and timbral features extracted automatically from audio recordings could accurately identify different jazz saxophonists performing both in a laboratory environment and on commercial recordings, even from very short musical phrases. The relationship between artist identity, intonation, and vibrato for jazz wind instrumentalists was also considered by \citet{Abeser2015-scoreinformed}, using similar techniques.

More recently, impressive accuracy scores have been achieved by leveraging deep-learning to extract features automatically from a recording. \citet{Edwards2023} trained a convolutional recurrent neural network to identify thirty jazz pianists from symbolic transcriptions of their recordings represented as ``image-like'' piano rolls. \citet{Chou2024} instead took a language modelling approach by representing symbolic musical events as sequences of discrete tokens, and trained a bidirectional transformer model to identify recordings by a jazz pianist (Herbie Hancock) alongside other musical styles. We provide an in-depth review of performer identification work beyond jazz within the introduction of Chapter \ref{chap:rhythm_rsos}.

A limitation with much of the prior research on music composer and performer identification relates to the description of current \GLS{MIR} research as ``task-oriented'' given at the start of this chapter. As we argue in Chapter \ref{chap:xai_rsi}, while these models could \textit{technically} be useful for identifying unknown jazz performers or composers, in practise this scenario is rare as online discographies of recordings (on platforms such as MusicBrainz\footnote{\url{https://musicbrainz.org/}} and Discogs\footnote{\url{https://www.discogs.com/}}) are now mature and comprehensive. Rather than simply trying to improve these models for their own sake, in Chapters \ref{chap:xai_rsi} and \ref{chap:rhythm_rsos} we follow \citet{Foscarin2022} in taking the interpretation of these models seriously, analysing their decision-making functions to generate quantitative insights into the specific qualities of different styles of jazz improvisation.

\subsection{Genre}

\subsubsection{Genre Classification}

Alongside Western classical and popular music forms, jazz often appears in the ``classic'' \GLS{MIR} task of genre identification. A full review of music genre classification models trained using symbolic features is given in \citet{Correa2016}. Here, we note simply that interpreting a genre identification model can provide insights into the specific musical qualities that best distinguish jazz from other genres. \citet{Zheng2017-genre} used features derived from melodic contour and duration to derive musicological interpretations from a genre classification model trained on both jazz and classical pieces. A comparable approach was taken by \citet{Simsekli2010} using only the bass line of the music. \citet{Dervakos2022} used a local feature-based technique to explore the regions of a MIDI ``piano roll'' representation that pushed a convolutional neural network to classify this as jazz or another genre. However, the interpretability of this technique was criticised by the authors, and is further questioned by our own work in Chapter \ref{chap:xai_rsi}.

A small number of papers have attempted to evaluate computationally the differences in harmonic syntax between jazz and other musical genres. \citet{Harrison2018-harmony} used a feature-based approach informed by psychological modelling to compute the relative importance of abstract cognitive and music-theoretic terms (e.g., ``harmonicity'', ``voice-leading distance'') extracted from chord progressions to classifications of Western classical, popular, and jazz music. A comparable approach was earlier taken by \citet{Anglade2009}, who employed a tree-based classifier using features derived from chord progressions to develop transparent ``rules'' separating the harmony of jazz from classical and popular music. Although we do not consider the differences between jazz and other genres in this work particularly, this would be a useful extension of the models described in Chapters \ref{chap:xai_rsi}--\ref{chap:mp_network} and offers an opportunity for future research (see section \ref{sec:discussion_limitations_and_future_directions}).

\subsubsection{Subgenre Classification}\label{sec:lit_review_subgenres}

Related to genre classification is the task of classifying distinct ``subgenres'' of jazz (e.g., ``swing'', ``bebop'', ``acid''). This task has been considered in a small number of papers, including several that also attempt to classify individual composers or performers \citep[e.g.,][]{Hedges2014, Abeser2015-scoreinformed, Velenis2023}. \citet{Eppler2014} used decision trees trained on a handcrafted feature set capturing rhythm, tempo, and tonality to classify the subgenre of a jazz recording from a small number of candidate classes. \citet{Quinto2017} trained numerous supervised learning architectures to identify three jazz subgenres using acoustic features, with the greatest success observed for recurrent neural networks. 

However, the extent to which these models actually learn musical qualities distinct to particular subgenres --- as opposed to simply the differences in recording practices apparent between different historical time periods \citep[see][]{Flexer2010, Edwards2023} --- remains unclear. Moreover, it is not evident whether this division of jazz history into distinct chronological subgenres or ``eras'' is even particularly helpful, especially given that musicians may instead see the development of this music in a less-than linear fashion \citep[e.g.,][]{Litweiler1984} and that some jazz works may not fall neatly into the ``era'' they were created in. An alternative option is to take an unsupervised learning approach, identifying ``clusters'' of particular styles of jazz performance directly from raw data, without presupposing the existence of strict subgenres or eras. We consider this possibility further in section \ref{sec:rsos_rhythm_characterises_style}.

\subsection{History}

A related area of research involves modelling the musical development and evolution of jazz over the past century. Parallels exist here with equivalent work conducted with relation to popular music \citep[e.g.,][]{Hamilton2024, Warrell2024}. 

With relation to harmony and tonality, \citet{Weis2018} found that the complexity of pitch class representations obtained from both audio-based chromagrams and symbolic transcriptions of jazz performances followed a roughly linear path over the past century, with minimal differences between the type of input representation used. \citet{Broze2013} considered trends in harmonic syntax in published ``lead sheet'' representations of jazz standards, finding evidence only for small, gradual shifts away from traditional ``tonal'' harmony in the latter part of the twentieth century. How these chords are actually realised by musicians was not considered, however. We discuss possible chronological trends in the usage of harmonic progressions by jazz pianists in section \ref{sec:rsi_factorised_cavs} of this work.

\citet{Frieler2016} developed a method whereby an improvisation is annotated with ``mid-level units'' (e.g., ``quotation'', ``ascending line'', ``theme''). Some evidence emerged from their analysis that the diversity of the units employed within an improvisation has increased over the past century. A subsequent project by the same authors extracted a wider range of features (spanning both ``mid-level units'' alongside pitch, rhythm, and interval features) from the same recordings. The user can explore simple regression models fit between these features and the year a given recording was made on an interactive web application, described in \citet{Frieler2018}.\footnote{\url{https://jazzomat.hfm-weimar.de/feature_history_jazz/}}. While several features (e.g., pitch-class entropy) do seem to show clear relationships over time, for others this pattern is less evident. Moreover, it is not clear to what extent these features vary simply over the duration of a musician's career (e.g., performers use a greater range of pitch classes as they age, etc.), as opposed to varying more systematically over the past century of recorded jazz more generally. 

Similar observations were made by \citet{Corcoran2021}, who studied the use of swing in jazz from the earliest ``traditional'' recordings to more recent ``postbop'' styles. They found a monotonic increase in the average swing ratio over time, but were not able to rule out the possibility that the consistency of particular performers rhythmic style may have effected their results. We conduct such an analysis of the developments in jazz rhythm in section \ref{sec:rsos_rhythmic_styles_are_consistent} of this work.

\subsection{Ensembles}

Another area of concern to the present thesis involves modelling the strategies that are actually used to perform jazz music in an ensemble. 

A variety of methods exist for modelling coordination and interaction strategies in musical ensembles \citep[see][for a review]{Demos2023}. With reference to jazz, \citet{Bantula2016} developed a method to quantify the influence of accompanying rhythm section musicians on a soloist: features are extracted from the performance of the soloist and the soloist combined with the ensemble, separate supervised-learning models are trained on both datasets, and the accuracy of both models is compared. Another method is linear phase correction, introduced by \citet{Wing2014} and subsequently applied to string quartets \citep{Chang2017, Wing2014, Timmers2014}, piano duets \citep{Goebl2009}, and African drumming ensembles \citep{Jacoby2021}. Here, interaction is modelled as a process of distributed adaptation to timing discrepancies from exact isochrony (see equation \ref{eq:mp_phase_correction_model}).

Outside of the modelling literature, understanding the ways in which improvised conduct is coordinated and organised between musicians has seen interest from psychologists, linguists, and ethnographers. Previous work has studied the use of non-verbal feedback in duo improvisations \citep{Moran2015} and the pre-planning musicians engage in during rehearsal \citep{Dueck2013}. \citet{Doffman2014} quantified the timing synchronisation between members of a rhythm section with relation to the sensor-motor process of entrainment \citep{Clayton2020}. Finally, both \citet{Pras2017} and \citet{Schober2014} have evaluated the extent to which jazz musicians perceive each other's intentions during improvisation --- concluding that exactly shared understanding is not required for a performance to be successful. We provide further evidence in support of this argument as part of our listener evaluations described in Chapter \ref{chap:mp_network}.

An interesting question that connects this work to traditional \GLS{MIR} tasks more specifically is whether features that are extracted from a computational model of ensemble coordination can be useful when training a jazz performer identification model. The ethnographic literature on jazz often suggests that the ways a performer coordinates and interacts with other musicians in their ensemble is a key part of their ``sound'' or style \citep[e.g.,][]{Monson1996}, and computational modelling can be an interesting way of testing this assumption. This is addressed in section \ref{sec:rsos_rhythmic_features_predict_identity} of the present work. Furthermore, in Chapter \ref{chap:mp_network}, we apply this model to jazz improvisations and demonstrate how it can reveal both the aesthetic and stylistic priorities of different performers and ensembles.

\subsection{Datasets}

One limitation of many of the earliest computational studies of jazz improvisation is the restricted size of their datasets, often containing only a small number of recordings \citep[e.g., 6 recordings in][]{Friberg2002}. In response to this need, numerous large databases of annotated jazz performances and compositions have been developed and adopted by the community. Perhaps the best known is the Weimar Jazz Database or \GLS{WJD} \citep{Pfleiderer2017}, a dataset of 456 transcribed recordings that has since been used in a large number of research projects \citep[e.g.,][]{Wu2020-frontline, Corcoran2021, Frieler2018, Balke2022, Weis2018}. We provide a complete review of the \GLS{WJD} and other datasets of symbolic annotations of jazz performances \citep[e.g.,][]{Foster2021, Riley2023, Edwards2023, Goto2002} in Chapter \ref{chap:jtd_tismir}, where we also outline our own such dataset. 

Finally, we note that numerous datasets of specialized annotations exist for jazz, covering lead sheets and chord progressions \citep{Broze2013, Bunks2023, Eremenko2018, Harasim2019, Pachet2013-database}, formal structures \citep{Balke2022, Eremenko2018}, and harmonic and melodic progressions \citep{Adegbija2023}. While we do not specifically refer to these datasets in this work, they represent an important step by the community towards facilitating the training of computational models on large amounts of data made available under permissive licenses.

\subsection{Jazz Studies, Ethnography, and the Humanities}

While the methodology used in this work comes from statistical modelling and machine learning, interpreting our results requires us to engage with the broader jazz studies literature. We draw particularly from two landmark works in music ethnography by \citet{Berliner1994} and \citet{Monson1996}, which evaluate the processes with which jazz musicians (both individually and collectively) learn to improvise through extensive analyses of interviews with by well-known performers. This focus extends to several oral histories of jazz edited by \citet{Sidran1992}, \citet{Lyons1983}, and \citet{Gottlieb1997}, which feature discussions by well-known jazz musicians (including several featured in our database, described in chapter \ref{chap:jtd_tismir}) of their creative process. Finally, we also draw from several historical overviews of jazz by \citet{Gioia2011} and \citet{Shipton2005} alongside pedagogical texts by \citet{Levine2011-1} and \citet{Haerle1994} --- with the latter text especially relevant to the work described in section \ref{sec:rsi_factorised_cavs}. 

\section{Motivations}\label{sec:intro_motivations}

Having now reviewed some of the previous work in this area, we now provide an overview of the distinct motivations and themes that are central to the present research.

\textbf{Supervised learning of diverse musical corpora.} One motivation for this work is to understand the different musical features that underpin the diversity of jazz improvisation \textit{styles} from the past century. We therefore apply our computational models to the analysis of large corpora representing various subgenres, formats, and historical eras of jazz music. While corpus analyses can be conducted in a variety of ways, our primary methodology consists of training a variety of classification and regression models and interpreting them with respect to existing musicological and critical writings on jazz. The majority of our models are supervised learning models, where the model learns to explicitly predict labelled target classes. In contrast to unsupervised or semi-supervised approaches, this enables us to understand how particular musical features and concepts we extract from jazz recordings might explicitly relate to particular performers or musical styles. We do, however, consider a number of unsupervised modelling approaches to complement our supervised learning models (see sections \ref{sec:rsi_feature_importance_by_performer} and \ref{sec:rsos_rhythm_characterises_style}).

\textbf{Resource generation.} A second motivation for this work is to generate open-source resources that can facilitate subsequent computational research into jazz improvisation. We develop numerous datasets, computational models, software, and web applications, all of which are released under permissive, open licenses to enable future researchers to use and build upon them. One of these outputs is a database of annotated recordings (discussed in Chapter \ref{chap:jtd_tismir}), which we develop by leveraging recent advances in audio signal processing and machine learning to automatically process of thousands of recordings. We also use the resources that we develop to revisit several ``classic'' questions in the computational study of jazz --- including, for instance, swing and synchronization, which have both been studied extensively over the past thirty years (see section \ref{sec:lit_review_rhythm}) --- with significantly larger datasets than have been employed before.

\section{Themes}\label{sec:intro_themes}

Alongside these motivations, our research also explores a number of additional themes, which we outline below.

\textbf{Modelling of improvisation style.} A primary theme underpinning this work involves understanding the diversity of distinct jazz improvisation styles. While ``style'' can refer to different subgenres of jazz \citep[see][]{Quinto2017, Eppler2014}, we primarily focus here on modelling the style of individual performers. Training computational models to identify the style of particular musicians is an interesting task for \GLS{MIR} research, but one that has mostly been limited to practitioners of Western classical \citep{Mahmudrafee2023, Tang2023} and popular \citep{Chou2024} music. Indeed, \citet[p. 192]{Berendt1976} has claimed that ``there doesn't [yet] exist ... any form of notation, graphic representation, and computer analysis capable of satisfactorily registering the subtlety of ... [the] specific distinctions between groups and individuals'' in jazz. By developing such tools for computational analysis, we hope to demystify the different factors that contribute to the style of several particularly well-known musicians, with exciting potential applications for both digital humanities and music education research.

\textbf{Modelling of musical ensembles.} A second theme underpinning this work is to model the processes by which musical improvisation actually occurs --- i.e., modelling the ``specific distinctions between groups'' described by \citet{Berendt1976} above. The interaction between the members in an ensemble can substantially influence the success of their music-making, as well as become associated with the style of individual performers \citep{Monson1996}. Accordingly, psychological models of joint action and coordination \citep[e.g.,][]{Wing2014, Jacoby2021, Timmers2014} may potentially enhance our music performer and style identification models by allowing ensemble-level features to be incorporated. Additionally, by comparing models trained on both ensemble and unaccompanied improvisations, we seek to better understand the differences between both forms of music-making.

\textbf{Musically informed feature selection.} For many supervised-learning architectures, decisions must be made as to which features are extracted from a performance for use during training and evaluation. While numerous methods exist for feature selection or combination (e.g., dimensionality reduction, penalty terms, stepwise feature removal), we prefer to derive our features wherever possible from the musicological and ethnomusicological literature on jazz improvisation. This helps facilitate meaningful interpretations as our features are already likely to be well-understood by musicians and researchers \citep[here, see][]{Hamilton2024}, and also eliminates the requirement for post-hoc interpretation of the feature space \citep[as in][]{Foscarin2022}. The inverse statement can also be said to be true: interpretations that are derived from abstract computational models gain credibility when they can be supported by statements from critics, musicologists, or performers themselves.

\textbf{Model comparison and diversity.} A substantial amount of research in \GLS{MIR} has been devoted to improving the state-of-the-art in music modelling, including the modelling of improvisation. However, detailed comparisons of different model architectures are surprisingly rare for several of the tasks we consider here, such as automatic performer identification. Here, we subscribe to the claim made by \citet{Rudin2024} that ``amazing things come from having many good models'': we provide a systematic comparison of many different music performer identification architectures in Chapter \ref{chap:xai_rsi}, evaluating them not only in terms of predictive accuracy and performance but also ease of interpretability. Moreover, we note that interpretations of one model gain weight when they can be supported by others that may have learned different decision functions from the same data \citep{Breiman2001-cultures}.

\textbf{Model interpretability.} There is a temptation in computational research to only use the current state-of-the-art techniques that yield the best results for any given task. Yet, as the complexity of any computational model increases, the extent to which its decision-making process can be understood by a human often decreases: they become ``black boxes'' \citep{Hassija2024}. While one approach to navigating this trade-off would be to employ only conventional ``white-box'' techniques (e.g., linear modelling), we instead tackle this problem of interpretability ``head-on'', exploring a variety of modelling approaches (both ``white-'' and ``black-box'') and techniques for explaining their predictions throughout this work. We also develop numerous interactive web applications to showcase the models that we create and allow readers to draw their own conclusions from them.

\section{Scope}

The scope of this research extends to what is typically known as ``conventional'' (variously also referred to as ``straight-ahead'' or ``mainstream'') jazz. This involves improvisation based on ``tunes in time'' \citep[p. 48]{Bailey1992}, typically occurring over harmonic sequences of set length that may be derived from popular song forms and that are played within a (notionally) strict sense of musical time \citep[``standards'': see][]{Gioia2012-standards}. This is different from ``free'' jazz improvisation, where these materials are typically absent. Most prior computational and empirical research has addressed ``conventional'' jazz improvisation, with a limited number of exceptions \citep[e.g.,][]{Pressing1987, Pras2017}.

Alongside these stylistic considerations, we also restrict ourselves to the three instruments that constitute the jazz ``rhythm section'' --- piano, bass, and drum kit. We focus on these instruments specifically as they form the backbone of most conventional jazz, providing the harmonic, rhythmic, and structural foundations of a performance over which ``solo'' improvisations (that may themselves be made by members of the rhythm section) take place. From a technical standpoint, methods capable of processing audio recordings by these instruments are considerably more advanced than many other instruments associated with jazz, such as the saxophone \citep[although here, see][]{Riley2024-omnibook}.

Finally, we note that there are two primary traditions of music modelling research: (1) symbolic modelling, where a musical input is represented using formats such as musical notation, scores, and MIDI ``piano rolls'', and (2) acoustic modelling, where the underlying sound is represented directly using methods such as waveforms and spectrograms. While the latter tradition may sound appealing for jazz --- where the primary way a musical work is documented is through a recording, rather than in musical notation --- it has its drawbacks. In particular, computational models trained on acoustic features may have high predictive power but low interpretability, as the underlying representations may be unintuitive for non-technical readers \citep{Foscarin2022, Edwards2023}. Given our focus on model interpretability throughout this work, we instead prefer to work with symbolic data extracted from an audio recording, with the intention of facilitating intuitive and explainable musical analyses that will be of interest to the widest possible audience.

\section{Thesis Structure and Contributions}

Our primary contributions in this work consist of advancements across three distinct tasks: modelling (1) improvisation style, (2) rhythm, and (3) ensemble interaction. Each subject is covered in an individual chapter of the thesis (Chapters \ref{chap:rhythm_rsos}--\ref{chap:mp_network}). These are preceded by Chapter \ref{chap:jtd_tismir}, which outlines an open source dataset of annotated recordings used to train and evaluate many of our models. Finally, the thesis concludes with Chapter \ref{chap:discussion}, which discusses the outcomes of the present work. We provide a short overview of each chapter below.

\textbf{Chapter \ref{chap:jtd_tismir}:} introducing the Jazz Trio Database. This chapter addresses the problem of scaling-up computational music research by introducing an automated pipeline for generating symbolic annotations from jazz recordings. Pre-trained deep-learning models are applied to ``unmix'' an audio recording into separate signals for multiple instruments, which are then automatically annotated using existing transcription models. We use this pipeline to generate the Jazz Trio Database (\GLS{JTD}), an open source dataset of annotated jazz rhythm section performances with a total of 133.5 hours of annotated audio across piano, double bass, and drum kit.

\textbf{Chapter \ref{chap:xai_rsi}:} modelling improvisation style. This chapter considers how computational modelling can disentangle the elements contributing to ``style'' in jazz improvisation. We construct a series of supervised learning models that learn to identify particular pianists from recordings in \GLS{JTD} and other datasets, and then we interrogate the learned decision functions of these models to understand how these judgements were made. This culminates in a novel deep neural network architecture inspired by mixture-of-experts modelling that achieves state-of-the-art predictive accuracy, with a multi-input structure that allows its predictions to be explained in terms of four fundamental musical domains --- melody, harmony, rhythm, and dynamics. 

\textbf{Chapter \ref{chap:rhythm_rsos}:} modelling rhythm. This chapter refines the scope of Chapter \ref{chap:xai_rsi} to focus solely on the importance of rhythm to jazz improvisation style. We develop a jazz pianist identification model trained on handcrafted rhythmic features extracted from \GLS{JTD}. These features are derived from prior empirical and ethnographic accounts of jazz improvisation and relate to several high-level categories including ``feel'', ``swing'', and ``complexity''. Several features in an additional ``coordination'' category attempt to capture the interaction between members of the rhythm section and how this might relate to the style of the pianist.

\textbf{Chapter \ref{chap:mp_network}:} modelling ensemble interaction. This chapter focuses on modelling the mechanisms by which jazz improvisation actually takes place, using several of the features first defined in Chapter \ref{chap:jtd_tismir} and \ref{chap:rhythm_rsos}. We use temporal latency --- such as that introduced by networked communication platforms like Zoom --- as an experimental manipulation to disrupt the tight temporal coordination of action that is typically involved in ensemble jazz performances. We gather data from five professional duos of musicians via a novel software platform that emulates network latency in a controllable fashion. We then use linear causal modelling and computer simulations to explore the strategies they employ to coordinate with one another in the presence and absence of latency, and relate these strategies to descriptions given by the musicians of their own performances.

\textbf{Chapter \ref{chap:discussion}:} discussion. This chapter concludes the thesis by summarising the outcomes of the work, discussing its limitations, and offering suggestions for future research.