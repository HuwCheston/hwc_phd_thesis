\chapter{Introduction}\label{chap:introduction}

% What is improvisation?
Improvisation is a fundamental part of many musical traditions. While definitions of improvisation vary, most agree that it involves the spontaneous creation of musical material, as opposed to the performance of a pre-composed work. This practice has long fascinated musicians, composers, and scientists across a range of disciplines due to its balance of spontaneity and prior planning, its apparent deep links with cognition, psychology, and linguistics, and its challenges for analysis and modelling.
 
% What is jazz?
Jazz is a rich musical genre that relies heavily on improvisation. With historical roots in African, American, and European musical traditions from the 19th century, jazz has evolved into a valued part of intangible cultural heritage and is taught internationally in academic settings \citep{Feld2012, Berliner1994}. Through improvisation, jazz musicians manipulate many aspects of the music they play, such as the harmony, melody, and rhythm of a composition. In group settings, these choices must also be negotiated collectively between the members of an ensemble for a performance to be successful \citep{Monson1996}. 

% What is style?
All of these parameters (and many more) relate to the idea of musical \textit{style}. In jazz, style can be defined as the individual differences between performers, ensembles, geographic locations, subgenres, and distinct historical eras of this music, among other factors.

\textbf{Performers:} Jazz performers often strive to develop their own distinctive and recognisable style of improvisation, which they might refer to as their ``conception'', ``language'', or ``sound'' \citep{Berliner1994}. With sufficient training and experience, humans can become highly adept at recognising the styles of different jazz musicians. In the context of a ``blindfold test'' \citep[such as those published in the ``Downbeat'' magazine e.g.,][]{Alkyer2018}, famous jazz musicians are invited to listen to recordings --- typically in front of a live audience --- and identify the soloists playing on them by name, despite often having never heard these recordings before.

\textbf{Ensembles:} Likewise, an ensemble or band can also have a unique style, over and above the styles of its individual members \citep{Hagberg2017}. One well-known example is the ``Jazz Messengers'', a group led by drummer Art Blakey. The Jazz Messengers featured a revolving cast of musicians who appeared alongside Blakey throughout the thirty-year history of the group. Nonetheless, the band remained known for their singular approach to ``hard bop'' jazz that combined elements of funk, blues, and gospel music \citep{Gioia2011}.

\textbf{Locations:} Geographical locations can become associated with particular styles of jazz, that may be known as ``scenes'' and ``schools''. For example, \citet{Feld2012} described how a particular style of jazz emerged in Ghana during the early 20th century that mixed together European, American, Christian, and Buddhist imagery, aesthetics, and sounds. This, he claimed, represents a ``cosmopolitan'' approach towards jazz that is nevertheless distinctly associated with a particular location. Other ethnographic research has explored the cultural history of the jazz ``scenes'' developed in postwar Japan \citep{Atkins2001} and France \citep{Perchard2015}.

\textbf{Subgenres:} Given time, the style of a particular musical scene may come to transcend a specific location (or locations) and become a fully-fledged subgenre of its own. For example, the ``bebop'' style of jazz was initially cultivated during the first half of the 20th century in several clubs along 52nd Street, New York City, before eventually spreading across the United States and worldwide \citep{Gioia2011}. Individual subgenres of jazz typically have distinctive musical qualities: for instance, jazz ``fusion'' is known for the use of electronic instruments and a ``straight'' rhythmic feel, all features that are not typically associated with bebop.

\textbf{Chronology:} Finally, jazz music has also displayed stylistic variation over time. The factors motivating these changes may be both external and internal. External factors derive from outside the musical language of jazz. These can include the adoption of distinct technical standards \citep{Abeser2015-scoreinformed} and changing economic and political landscapes \citep{Schuller1986}. Internal motivations instead relate to structural features of the language of jazz. These include the small, gradual changes away from ``tonal'' harmonic movement in jazz over the course of the 20th century, such as in ``free'' or ``avant-garde'' styles \citep{Broze2013}.

% Artistic style has been studied for decades in jazz and in other music. But it's hard because it's very subjective. 
Understanding the nature of style as it relates to these and other areas is an important task in academic research, both for jazz and in the study of the arts more generally. Theoretically, artistic style can be assessed entirely using human judgements. In jazz, this could involve using the methods of musicological analysis proposed by \citet{Cugny2019} or \citet{Larson2009}, for example. But these judgements alone may be insufficient to paint a complete picture of artistic style. First, they are necessarily slow and hence are hard to apply at scale to many artworks or musical performances. Second, subjectivity is also a problem, since every human analyst comes with their own history of \replaced[id=HC]{artistic}{musical} exposure that will inevitably affect their interpretations. 

% Computational modelling could be a good way of understanding style
Computational modelling may prove to be one way of addressing this issue effectively. Good models can explicitly address the ambiguities and assumptions that are inherent in critical discourse surrounding jazz style. This often involves terms such as ``feel'', ``interaction'', and ``groove'' that may frequently be used colloquially but which are, ultimately, difficult to locate in concrete examples of the music. Computational models can also provide a framework for studying style systematically and at scale as, once an algorithm has been designed and validated, it can theoretically be applied to any performance or recording. This has exciting potential applications to many areas of digital humanities research, including music information retrieval (\GLS{MIR}), computational musicology, musical corpus analysis, and music education.

% However, have we fully explored these possibilities?
Despite the possibilities that computational modelling unlocks for the study of style in jazz improvisation, however, the extent to which these have been fully explored is unclear. For many years, music computing and \GLS{MIR} have been primarily ``task-oriented'' research fields. New models are typically evaluated based on the extent that they improve upon the previous state-of-the-art in some objective metric or pre-defined task, and most contributions from these fields rarely make their way to musicology or the humanities \citep[see, particularly,][]{Borsan2023}. For jazz, especially, towards the turn of the 20th century it was even claimed that
\begin{quote}
    \centering
    there doesn't exist ... any form of notation, graphic representation, and computer analysis capable of satisfactorily registering the subtlety of [the musical processes that] differ not just stylistically but also in terms of specific distinctions between groups and individuals \citep[][p. 192]{Berendt1976}.
\end{quote}

% This thesis
With the benefit of thirty years of computing research and development, we may now be in a position to reassess the validity of this statement. But, if such a form of computer analysis were to exist, what might it look like? What types of data would it seek to quantify? How would it be interpreted in ways that are meaningful both to musicologists, scientists and --- above all --- jazz musicians themselves? This thesis describes a programme of research that attempts to answer both these and other, related, questions. In particular, we aim to consider whether machine learning can offer one way of modelling the diversity of jazz improvisation styles that have manifested over the 20th and 21st centuries.

% Lack of recordings
One challenge that we can use machine learning to address relates to a lack of available data. Unlike Western classical music, the primary musical ``document'' involved in jazz is typically not a notated score, but an audio recording of a performance. While interesting research can be accomplished by training models directly on representations of sound recordings (e.g., spectrograms, waveforms), many \GLS{MIR} tasks instead require symbolic data --- abstract, human-interpretable representations like lead sheets, musical scores, or MIDI ``piano rolls''. Creating this data often has required lengthy processes of annotating \added[id=HC]{commercial} recordings by hand \citep[as in][]{Balke2022, Pfleiderer2017, Goto2002}, limiting the scope of previous modelling research to a relatively small number of musical performances. However, recent advancements in neural audio processing offer the chance to render these processes obsolete, with the potential for dramatically scaling up this research \citep[e.g.,][]{Edwards2023, Riley2024-omnibook, Shanin2023}. In this thesis, we use these techniques to automatically generate a new dataset of annotated jazz performances, which we can then use to train our models --- achieving a scale rarely achieved in prior computational research into jazz style.

% Interpreting these models
Another challenge we seek to address in this work involves interpreting machine learning models in ways that are meaningful for those engaged with this music. Computational models can learn to rely on features that are extremely powerful for the task they are trained to perform, but that are otherwise uninterpretable to humans. In task-oriented \GLS{MIR} applications --- where the primary goal is achieving the best performance on unseen data --- this may be of little importance. However, for those interested in using these models to better understand the structure of the underlying data, making these models transparent and interpretable remains challenging. While numerous techniques for interpreting machine learning models have emerged \citep[see][for a recent review]{Hassija2024}, the extent to which these can be applied to generate explanations of complex forms of music such as jazz remains to be seen. In this thesis, we take model interpretability seriously, applying a variety of existing techniques --- as well as developing several of our own --- to interpret our models, with the end goal of learning more about individual differences in jazz improvisation style.

% Link to next section
The scope of this work thus involves using computational and statistical methods to study the improvisation style of individual jazz musicians, ensembles, subgenres, and historical periods across large and diverse datasets of annotated musical performances. In the next section of this introduction, we review the existing literature related to these four areas. We then proceed to define the approach we take in the present research and outline the structure of the thesis.

\section{Prior Research}

The earliest computational research into jazz improvisation dates to the 1970s and 1980s, with the efforts of \citet{Urlich1977} and \citet{Fry1980} to develop rule-based systems capable of generating and synthesising jazz-like ``improvisations''. Subsequent work has embraced developments in natural language processing, information theory, machine learning, cognitive psychology, neuroscience, and audio signal processing (amongst other fields). Computational research involving jazz and improvised music now appears widely in conference proceedings and journals dedicated both to \GLS{MIR} and a general scientific audience.

This literature review considers prior work conducted with relation to musical style across (1) individual jazz performers, (2) different musical ensembles, (3) specific subgenres of jazz, and (4) particular historical eras. Across all four areas, we review work from the machine learning literature and also relevant statistical analyses of large music datasets. In the case of (2), it is also necessary to consider work from the psychological and experimental literature relating to the computational modelling of joint action and synchrony.

\subsection{Modelling Individuals}

One way that style can be understood is by considering the individual differences between specific jazz musicians \citep{Berliner1994}. Nearly any musical parameter can feasibly be manipulated by a musician in a way that may be considered idiomatic or ``stylistic''. Here, we consider individual jazz style to relate to the use of rhythm and melody by an improvising jazz soloist. We make this distinction because, unlike instrumental timbre or chord voicings (for instance), the techniques that are used to analyse rhythm and melody are broadly applicable to any instrument. At the end of this section, we also review prior work that attempts to develop computational models capable of automatically identifying jazz performers from their own recordings.

\subsubsection{Rhythm}\label{sec:lit_review_rhythm}

Rhythm and timing have proved fruitful subjects for computational jazz research since at least the 1990s \citep[e.g.,][]{Rose1989}, including a number of works considering style. This is perhaps due to the nature of the data that is required. Timing can be effectively quantified using only a vector of note onset or offset times. This means that --- unlike comparable analyses of melody and harmony, for instance --- a full notated transcription of an improvised performance is not typically necessary.

One prominent line of research involves analysing the ``swing'' rhythm that is characteristic of jazz music, defined as the subdivision of the quarter note musical pulse into long-short groupings of eighth notes. Methods for quantifying swing include the swing or ``beat-upbeat'' ratio \citep[\GLS{BUR}, see][]{Benadon2006}. The \GLS{BUR} has previously been used to investigate the relationship between swing, tempo \citep{Ellis1991, Friberg2002, Honing2008, Dittmar2018, Foster2021}, instrumentation \citep{Butterfield2011, Cheston2022}, and subgenre \citep{Corcoran2021}. 

Other work has considered how swing varies between different performers. Both \citet{Corcoran2021} and \citet{Benadon2006}, for example, have demonstrated clear variation in the distribution of \GLS{BUR}s played by different soloists, independent of their instrument. They find that a small minority of soloists use high \GLS{BUR}s significantly more than often than would typically be expected, perhaps to enhance the perception of groove in their playing \citep[see][]{Butterfield2011, Iyer2002}. Finally, \citet{Collier2002} described a case study of the swing ``vocabulary'' of the legendary trumpeter Louis Armstrong --- showing that Armstrong demonstrated considerably less swing in his playing than would be expected given a notated representation, and that this did not vary systematically based on musical factors. We further discuss swing as it relates to the style of different jazz performers within Sections~\ref{sec:jtd_swing} and~\ref{sec:rsos_swing_features} of this work. 

Alongside beat-upbeat ratio, downbeat delays are often considered to be another component of swing \citep{Collier2002, Nelias2022}. As these relate to the ways in which a performer times their playing with respect to the whole ensemble, however, we consider these instead to relate to differences between \textit{groups}, and review the relevant literature in Section \ref{sec:intro_ensemble_litreview}, below.

\subsubsection{Melody}

Modelling differences in the melodic vocabulary of jazz musicians has been another area of considerable research interest. 

One approach assumes that the individualistic qualities of melodic jazz improvisation result from differences in the use of stock sequences and melodic ``licks''. Indeed, memorising melodic sequences does often form an important part of jazz education \citep{Berliner1994, Monson1996}, and many textbooks of licks exist \citep[e.g.,][]{Naylor2024-BE, Naylor2024-OP, Levine2011-1}. These patterns can be represented as pitch or interval $n$-grams and their distribution approximated via probabilistic modelling. The ``Virtuoso'' \citep{Pachet2012} system, for example, uses Markovian processes to generate monophonic improvisations that include idiomatic jazz features such as chromatic ``side-slips''. Similarly, early versions of the ``Impro-visor'' system operate by breaking an improvisation up into fragments, clustering related fragments together using unsupervised learning, computing $n$-gram and transition statistics on the clusters, and then using this data as the input to a Markov chain \citep{Gillick2010}. 

A key advantage of many of these approaches is that the learned distribution of $n$-grams can easily be updated based on a corpus of recordings from a single performer. This allows new improvisations to be generated, for instance, that embody aspects of the style of this musician, which can theoretically be used in music education contexts. ``Impro-visor'', for instance, has been used to generate twelve-bar blues solos in the style of influential jazz saxophonists Charlie Parker and John Coltrane \citep{Gillick2010}. Similar work was conducted by \citet{Norgaard2014-how} for Charlie Parker --- who found that the vast majority of Parker's recordings could be represented using a small subset of interval $n$-grams --- and for jazz pianist Bill Evans by \citet{Gross2011}. 

One of the most important recent projects to consider the musicological insights that can be gained from modelling the melodic patterns used by different jazz performers is the ``Dig that Lick'' (\GLS{DTL}) project.\footnote{\url{https://dig-that-lick.eecs.qmul.ac.uk/}} Using audio signal processing and machine learning, the \GLS{DTL} team were able to automatically transcribe over 1,000 commercial jazz recordings into a machine-readable format with minimal human intervention. Pattern mining techniques were then applied to this dataset to extract short melodic patterns (``licks'') that frequently reoccur across recordings. These patterns can also be explored using an interactive web application \citep{Frieler2018}.

An important aspect of this work is that it allows researchers to consider the patterns that particular jazz improvisers use most frequently. Subsequent corpus analyses of the \GLS{DTL} data have, for instance, taken a single lick from the dataset and traced its transmission over time --- from its initial popularisation by earlier bebop pioneers like Charlie Parker and Dizzy Gillespie to subsequent reappearances in the ``post-bop'' language of contemporary players like Chris Potter \citep{Frieler2019-Anatomy}. Additional projects have also attempted to categorise individual patterns into distinct melodic classes, such as ``repetition'', ``arpeggio'', and ``trill'', enabling the distribution of these \textit{classes} to be explored across performers \citep{Frieler2019-jazzlines}

The \GLS{DTL} project represents an important step in the computational analysis of jazz, with applications to the modelling of individual performance styles. Our work aims to extend many of the techniques introduced in this project. We use similar audio signal processing methods to automatically produce a dataset containing transcriptions of numerous instruments from a single jazz recording, as well as transcriptions of polyphonic instruments such as the piano (Chapter \ref{chap:jtd_tismir}). We also consider the extent to which melodic patterns are truly idiomatic for individual performers (versus simply being used by many performers) by training supervised-learning models to identify musicians from their use of such patterns (Section~\ref{sec:rsi_feature_importance_by_performer}). 

\subsubsection{Performer Identification}

So far, we have mostly considered statistical corpus analyses that investigate the style of individual jazz improvisers. A related line of research involves training a supervised machine learning model to directly \textit{predict} the performer of a jazz recording. This is an interesting task in \GLS{MIR} research, but has mostly been limited to performers of Western classical \citep{Mahmudrafee2023, Tang2023} and popular \citep{Chou2024} music. A full review of the literature on music performer identification (covering genres beyond jazz) is provided in Chapter \ref{chap:rhythm_rsos}.

Early work in this area typically involved using ``handcrafted'' sets of quantitive features\replaced[id=HC]{. Some potential features have been}{, several of which we have} reviewed above. \citet{Ramirez2010} demonstrated how features extracted automatically from an audio signal could be used to accurately identify different jazz saxophonists performing both in a laboratory environment and on commercial recordings, even from very short musical phrases. Several of their features encode musical parameters discussed above, such as the duration (``swing'') and contour of pairs of successive notes. Using similar techniques, \citet{Abeser2015-scoreinformed} considered the degree to which the intonation of a jazz wind instrumentalist is artist-specific or varies as a function of recording year, tempo, and pitch.

More recently, impressive accuracy scores have been achieved by leveraging deep learning to extract features automatically from a performance, rather than explicitly defining these beforehand. \citet{Edwards2023} trained a convolutional recurrent neural network to identify thirty jazz pianists from symbolic transcriptions of their recordings represented as ``image-like'' piano rolls. \citet{Chou2024} adopted a language modelling approach by representing symbolic musical events as sequences of discrete tokens, and trained a bidirectional transformer model to identify recordings made by a jazz pianist versus performers of other musical styles. Most recently, \citet{Guo2025} proposed a novel transformer architecture for encoding symbolic music information \added[id=HC]{using both absolute and relative positional embeddings}, demonstrating that this improves the accuracy of jazz pianist identification on the datasets considered by both \citet{Edwards2023} and \citet{Chou2024}.

A limitation with much of this prior work on jazz performer identification relates to the earlier description of \GLS{MIR} as primarily a ``task-oriented'' research field. As we argue in Chapter~\ref{chap:xai_rsi}, while all the models discussed above could \textit{technically} be useful for identifying unknown jazz performers, in practise this scenario is rare as online discographies of jazz recordings are now mature and comprehensive. Rather than simply trying to improve these models for their own sake, in Chapters~\ref{chap:xai_rsi} and~\ref{chap:rhythm_rsos} we follow \citet{Foscarin2022} in taking the interpretation of these models seriously. We train a variety of supervised-learning models to identify jazz performers from their recordings, and interpret their decision-making functions to learn more about the individual differences in their improvisation styles. 

\subsection{Modelling Ensembles}\label{sec:intro_ensemble_litreview}

The success of any jazz performance depends on whether an entire band can generate ``a kind of co-operative creativity that rises above the contributions of any [one] individual'' \citep[][p. 300]{Hagberg2017}. Consequently, we can also understand improvisation style to relate to the ways in which individual musicians adjust their own playing to match with the ensemble they are playing with \citep{Monson1996}. Features extracted from an entire ensemble may also prove useful when training a computational model to identify the soloist on a recording \citep[e.g.,][]{Bantula2016}.

\subsubsection{Synchrony}

One way in which jazz ensembles may meaningfully differ from each other is in the level of synchrony displayed by the musicians. Tight synchronisation has frequently been observed between musicians in jazz ensembles, with delays of less than ten milliseconds between the double bass and drums reported in prior experimental work \citep{Kilchenmann2015}. However, the degree of synchrony in a jazz performance can (and does) vary between different ensembles \citep[][, Table 2]{Butterfield2010}. One possibility is that these variations may reflect the social dynamics within a group: \citet{Doffman2014} reported how the members of a piano trio who frequently performed with each other were able to alternate between playing in- and out-of-sync as an expressive musical device.

Another way in which synchrony can vary between ensembles is in ``the little discrepancies ... between rhythm section and soloists'', famously referred to by \citet[][p. 277]{Keil1987} as ``participatory discrepancies''. Jazz soloists have frequently been demonstrated to delay their downbeat with respect to that implied by the accompanying musicians in an ensemble, while also synchronising their offbeats \citep{Ellis1991, Friberg2002, Collier2002, Nelias2022}. One possible explanation for this phenomenon is that it helps manifest a desirable sensation of ``laying back'' in their playing \citep{Doffman2014}; another is that, by synchronising in this manner, jazz soloists enhance the perceptual qualities of ``swing'', both in their playing and that of the entire ensemble \citep{Iyer2002}. 

Evidence for whether these minute discrepancies in ensemble synchrony are directly perceivable by listeners remains inconclusive. \citet{Butterfield2010} found that most listeners are unable to discern a small discrepancy in timing between musicians across a variety of musical tempos. However, \citet{Nelias2022} demonstrated that slight downbeat delays between a soloist and ensemble enhanced the perceptual salience of swing, while \citet{Kilchenmann2015} found a small effect of timing discrepancies on the body movements of listeners. Both of these findings were restricted to jazz experts and professional musicians only, however.

\subsubsection{Interaction}

Related to the idea of synchrony is the notion of ``interaction'' --- the ways in which performers not only stay in time with each other, but also communicate and coordinate ideas during improvisation. Interaction can be measured in a variety of ways, including periodic adaptation to timing discrepancies \citep{Timmers2014, Wing2014, Jacoby2021}, shared body movements \citep{Chang2017, Moran2015}, explicit verbal feedback \citep{Dueck2013}, and in the musical content of an improvisation \citep{Setzler2020}.

Several computational models capable of quantifying interaction in a jazz ensemble have been proposed. \citet{Bantula2016} developed a method where features are extracted from the performance of a jazz soloist, both when they performed individually and with an ensemble. These features are then used to train supervised-learning classifiers to predict various aspects of the underlying musical compositions, such as the density and range of chord voicings. They claimed that the influence of the ensemble on the soloist (and vice versa) could then be computed by comparing the accuracy of models trained only on solo improvisations versus those trained on both solo and ensemble improvisations. 

\citet{Eerola2018} employed a different approach. They gathered video recordings of both non-pulsed, ``free'' jazz improvisations and pulsed improvisations over jazz ``standards'' and invited \replaced[id=HC]{expert}{professional} musicians to annotate instances of interaction in every performance. They then extracted a variety of acoustic and visual features from each improvisation and used these to train a supervised-learning model to directly predict the presence or absence of interaction within a section of a performance. They found that their model could successfully quantify interaction to within a reasonable degree of accuracy, albeit with greater success for non-pulsed versus pulsed improvisations. 

Other ways to model ensemble interaction come from the literature on pairwise techniques for time-series modelling \citep[see][for a review]{Demos2023}. One such method is linear phase correction. We reserve a formal description of this model for Equations \eqref{eq:mp_phase_correction_model} and \eqref{eq:mp_phase_correction_model_alt}; here, it is sufficient to note that it involves modelling interaction as a process of distributed adaptation to timing discrepancies, away from exact isochrony. Linear phase correction has previously been applied to model interaction in string quartets \citep{Chang2017, Wing2014, Timmers2014}, piano duets \citep{Goebl2009}, and African drumming ensembles \citep{Jacoby2021}. We provide the first application of this model to improvising jazz groups in Sections \ref{sec:rsos_interaction_features} and \ref{sec:mp_phase_correction_modelling}. 

A central question in this thesis is whether computational models trained to predict the improvisation style of an individual performer can be improved by including features extracted from an entire ensemble. The ethnographic literature on jazz often suggests that the ways a performer coordinates and interacts with other musicians in their ensemble forms a key part of their ``sound'' or style \citep[e.g.,][]{Monson1996}. In Section \ref{sec:rsos_rhythmic_features_predict_identity} of this work, we explicitly test this assumption. \replaced[id=HC]{We extract features relating to group synchrony and linear phase correction from recordings of jazz ensembles, and then use these}{We use synchrony and linear phase correction features extracted from recordings of an entire jazz ensemble, and then use features extracted from this model} to train a supervised-learning classifier to predict the identity of the soloist in the ensemble.

\subsection{Modelling Genre}

There are many distinct subgenres of jazz --- see Table \ref{tab:gen_genre_matching} for an overview --- and each of these have their own unique musical qualities. As a result, we can also use computational techniques to consider how the style of these subgenres may differ from each other: this topic is discussed in further detail through the formal corpus analysis conducted in Section \ref{sec:gen_comparison_between_genres}. We can also consider the ways in which jazz as a whole may differ from other distinct musical genres, such as Western classical and popular music.

\subsubsection{Subgenre Classification}\label{sec:lit_review_subgenres}

A number of research papers have considered the task of classifying distinct subgenres of jazz using supervised-learning algorithms. \citet{Quinto2017} trained numerous models to identify three jazz subgenres, finding the greatest success when using recurrent neural networks (\GLS{RNN}s). Both \citet{Barbedo2006} and \citet{Tzanetakis2002} employed hierarchical taxonomies where jazz performances are first separated from non-jazz performances and then classified as one of six distinct subgenres. All of these papers used acoustic features extracted from audio recordings, meaning that the extent to which they actually learned stylistic qualities distinct to particular subgenres --- as opposed to simply the differences in recording practices apparent between different historical time periods \citep[see][]{Flexer2010, Edwards2023} --- remains unclear.

Symbolic music representations have also been used for identifying distinct jazz subgenres and may facilitate more musically meaningful interpretations. \citet{McKay2004} used a large set of handcrafted features extracted from MIDI ``piano rolls'' to classify three distinct jazz subgenres, alongside six subgenres of Western classical and popular music. They found that features relating to instrumentation were especially important to the classifier, both when separating performances from the same ``parent'' genre and across subgenres. \citet{Velenis2023} trained a transformer model using a multitask learning paradigm, where individual classification heads each predict a variety of qualities from a jazz composition --- including its composer and tonality, as well as its subgenre. The latent space of their model can then be projected onto a lower dimensional representation and explored to visually ascertain connections between different subgenres. 

Ultimately, however, it is not evident whether this implicit division of jazz history into distinct \added[id=HC]{(and mutually exclusive)}\deleted[id=HC]{chronological} subgenres is particularly helpful. This is due to the fact that musicians may not see the development of this music in a such a linear fashion \citep[e.g.,][]{Litweiler1984}, and that some jazz works may not fall neatly into a single ``subgenre''. An alternative option is to take an unsupervised learning approach, identifying ``clusters'' of particular jazz performers directly from raw data, without presupposing the existence of strict subgenres or eras. We consider this possibility further in Section~\ref{sec:rsos_rhythm_characterises_style}. A multi-label classification task could also be explored (i.e., where a recording is tagged with multiple subgenres), potentially using some of the annotated recordings we introduce in Chapter \ref{chap:conditioned_gen}.

\subsubsection{Genre Classification}

Alongside Western classical and popular music forms, jazz often appears as a target genre in the ``classic'' \GLS{MIR} task of genre identification. A full review of music genre classification models trained using symbolic features is given in \citet{Correa2016}. Although we do not consider the stylistic differences between jazz and other genres in this work particularly, this would be a useful extension of the models described in Chapters~\ref{chap:xai_rsi}--\ref{chap:mp_network} and offers an opportunity for future research (see Section~\ref{sec:discussion_limitations_and_future_directions}).

Interpreting a genre identification model can provide insights into the stylistic qualities that best distinguish jazz from other genres. \citet{Zheng2017-genre} used melody and duration $n$-grams to derive musicological interpretations from a genre classification model trained on both jazz, classical, and ragtime music. They found, for instance, that typically only $n$-grams from the bass line of a piece were required to make an accurate classification, an observation also made by \citet{Simsekli2010}. \citet{Dervakos2022} used a local feature-based technique \citep[``\GLS{LIME}'': see][]{Ribeiro2016} to explore the regions of a MIDI ``piano roll'' representation that pushed a convolutional neural network to classify this either as jazz or another genre. However, the interpretability of this technique was criticised by the authors, and is further questioned by our own work in Chapter~\ref{chap:xai_rsi}.

A number of papers have attempted to evaluate computationally the differences in harmonic syntax between jazz and other musical genres. \citet{Harrison2018-harmony} used a feature-based approach informed by psychological modelling to compute the relative importance of abstract cognitive and music-theoretic terms (e.g., ``harmonicity'', ``voice-leading distance'') during autoregressive prediction of Western classical, popular, and jazz compositions. They found that voice-leading distance was significantly more important for predictions of jazz music compared with other genres, whereas harmonicity was important for other genres but not for jazz. A comparable approach was also taken by \citet{Anglade2009}, who employed a tree-based classifier using features derived from chord progressions to develop transparent ``rules'' separating the harmony of jazz from classical and popular music. 

\subsection{Modelling Jazz History}

A final area of research relevant to this thesis involves modelling the stylistic evolution of jazz music over time. The goal, here, is not to classify or predict distinct jazz subgenres, but instead to explore chronological trends in this music over the 20th and 21st centuries. Parallels exist here with equivalent work conducted with relation to popular music \citep[e.g.,][]{Hamilton2024, Warrell2024}. 

The analysis of the historical evolution of jazz has been made possible due to the public release of datasets such as the Weimar Jazz Database \citep[\GLS{WJD},][]{Pfleiderer2017}. The \GLS{WJD} includes 456 note-for-note transcriptions of improvised jazz solos recorded between 1925 and 2009. It also includes detailed metadata, such as the name of the performer and the year the recording was made. We provide a complete review of the \GLS{WJD} and other similar datasets in Chapter~\ref{chap:jtd_tismir}. 

A number of statistical corpus analyses have been conducted to consider how features extracted from recordings in the \GLS{WJD} may have changed over the course of the 20th century. For example, \citet{Corcoran2021} analysed the use of swing in the entire \GLS{WJD}. They observed a monotonic increase in the average \GLS{BUR} over time, but were not able to rule out the possibility that this may be the result of individual performers' behavioural patterns, rather than historical trends. We conduct our own analysis of the developments in jazz rhythm over the past century in Section~\ref{sec:rsos_rhythmic_styles_are_consistent}, using a larger dataset of recordings that we introduce in Chapter \ref{chap:jtd_tismir}.

\citet{Weis2018} explored the evolution of features relating to tonal complexity in jazz, also using recordings from the \GLS{WJD}. They, too, found a slight increase in complexity, with two inflection points occurring in 1950 and 2000. The authors speculate that the first may be attributed to the influence of Charlie Parker and the emergence of the ``bebop'' jazz subgenre, with the latter perhaps occurring due to the revival of bebop in the ``post-bop'' language of saxophonists David Liebman and Michael Brecker. Likewise, a sudden drop in complexity during the 1960s could be explained by the emergence of the ``hard-bop'' subgenre, which prioritised influences from funk and rhythm-and-blues \replaced[id=HC]{--- both genres which are typically understood to have a lower level of harmonic complexity than, for instance, bebop}{over bebop} \citep{Carr1988}.

\citet{Frieler2016} developed a method whereby an improvisation from the \GLS{WJD} is first annotated with ``mid-level units'' (e.g., ``quotation'', ``ascending line'', ``theme''). The diversity of these units can then be explored using measures of information content (e.g., Shannon entropy), which in turn can be modelled as a function of both recording year, subgenre, and performer. With relation to the historical evolution of jazz style, they found that, the later a recording was made, the greater the variety of employed mid-level units. In other words, jazz solos have become increasingly diverse in the musical material they employ. 

\citet{Abeser2015-scoreinformed} explored the changes in the use of reference tuning by jazz wind instruments, again using a subset of recordings from \GLS{WJD}. They found a clear trend towards using $A_4 = 440 \text{Hz}$ as a reference tuning over the course of the 20th century. A particular inflection point towards the use of $440 \text{Hz}$ occurred after 1955, around the time that this tuning was adopted by the International Standards Organization.

\section{Our Approach}\label{sec:intro_motivations}

Having reviewed the previous work in this area, we now provide an overview of the approach that we adopt in this research.

\textbf{Supervised Learning of Musical Corpora.} Perhaps the main motivation for this work is to understand the different musical features that underpin the diversity of jazz improvisation \textit{styles} from the past century. Accordingly, we apply our models to comprehensive collections of jazz music that reflect its many subgenres and historical eras, as well as its most prominent artists and bands. While musical corpus analyses can be conducted in a variety of ways, our primary methodology consists of training a variety of classification and regression models and interpreting them with respect to existing musicological and critical writings on jazz. The majority of our models are supervised learning models, where the model learns to explicitly predict labelled target classes, numeric results, or --- in the case of the autoregressive models in Chapters \ref{chap:mp_network} and \ref{chap:conditioned_gen} --- future values or events. In contrast to unsupervised approaches, this enables us to understand how particular musical features and concepts extracted from recordings might relate to certain jazz performers or subgenres. We do, however, consider a number of unsupervised modelling approaches to complement our supervised models (see Sections~\ref{sec:rsi_feature_importance_by_performer} and~\ref{sec:rsos_rhythm_characterises_style}).

\textbf{Resource Generation.} A second motivation for this work is to generate open-source resources that can facilitate subsequent computational research into jazz improvisation. We develop numerous datasets, computational models, software, and web applications, and release these under permissive, open licences to enable future researchers to use and build upon them. In particular, we develop a database of annotated recordings (discussed in Chapter~\ref{chap:jtd_tismir}) by leveraging recent advances in audio signal processing and machine learning to automatically process thousands of recordings. These methods let us bypass the painstaking annotation process that is often involved in corpus analyses, which in turn can help us dramatically scale up our models to cover large swathes of jazz history. By releasing these resources publicly, we also hope that subsequent researchers will use them to explore questions that are not covered in significant detail here, such as the difference between jazz and other musical genres. Finally, in Chapter \ref{chap:conditioned_gen} we also develop and validate a model capable of \textit{generating} musical performances in the style of particular musicians and jazz subgenres, which may prove useful in music education research.

\textbf{Model Interpretability.} There is a temptation in computational research to only use the current state-of-the-art techniques that yield the best results for any given task. Yet, as the complexity of any computational model increases, the extent to which its decision-making process can be understood by a human often decreases: it becomes a ``black box'' \citep{Hassija2024}. While one approach to navigating this trade-off would be to employ only conventional ``white-box'' techniques (e.g., linear modelling), a third factor motivating this research is to tackle the problem of interpretability ``head-on''. Throughout this work, we explore a variety of modelling approaches (both ``white-'' and ``black-box'') and techniques for explaining their predictions. For example, in Chapter \ref{chap:xai_rsi} we provide a systematic comparison of several architectures for music performer identification, evaluating them not only in terms of predictive accuracy and performance but also ease of interpretability. We also develop numerous interactive web applications as part of this work to showcase the models that we create and allow readers to draw their own conclusions from them.

\textbf{Musically Informed Feature Selection.} For many supervised-learning architectures, decisions must be made as to which features are extracted from a performance and used to train the model. While numerous methods exist for selecting or combining features from a large feature set (e.g., dimensionality reduction, penalised regression), \added[id=HC]{in Chapters \ref{chap:rhythm_rsos} and \ref{chap:mp_network}} we prefer to derive our features from the ground up with reference to the musicological and critical literature on jazz. This eliminates the requirement for post-hoc interpretation of the embedding space learned by the model \citep[as in][]{Foscarin2022}. It also helps facilitate meaningful interpretations, as our features are already likely to be well-understood by musicians and researchers \citep[here, see][]{Hamilton2024}. The inverse also holds true, as well: interpretations that are derived from abstract computational models gain credibility when they can be supported by statements from critics, musicologists, or performers themselves.

\textbf{Symbolic Music Modelling.} There are two primary traditions of music modelling research: (1) symbolic modelling, where a musical input is represented using formats such as musical notation, scores, and MIDI ``piano rolls'', and (2) acoustic modelling, where the underlying sound is represented directly using methods such as waveforms and spectrograms. While the latter tradition may sound appealing for jazz --- where the primary way a musical work is documented is through a recording, rather than in musical notation --- it has its drawbacks. In particular, computational models trained on acoustic features may have high predictive power but low interpretability, as the underlying representations may be unintuitive for non-technical readers \citep{Foscarin2022, Edwards2023}. Given our focus on model interpretability, we instead prefer to work with symbolic data extracted from an audio recording, with the intention of facilitating explainable musical analyses that will be of interest to the widest possible audience.

\textbf{Modelling Conventional Jazz.} The scope of this research relates primarily to what is known as ``conventional'' (also referred to as ``mainstream'') jazz. This involves improvisation based on what \citet[p. 48]{Bailey1992} calls ``tunes in time'' --- in other words, improvisation takes place on harmonic sequences of a set length (which are typically derived from popular song forms or other jazz compositions), within a notionally strict sense of musical time. This is different from ``free'' improvisation, where these materials are typically absent. Most prior computational and empirical research has addressed ``conventional'' jazz improvisation, with a limited number of exceptions \citep[e.g.,][]{Pressing1987, Pras2017, Eerola2018}.

\textbf{Modelling Jazz Rhythm Sections.} Alongside these stylistic considerations, we also restrict ourselves to the three instruments that constitute the jazz ``rhythm section'' --- piano, bass, and drum kit. We focus on these instruments specifically as they form the backbone of most conventional jazz, providing the harmonic, rhythmic, and structural foundations of a performance over which ``solo'' improvisations (that may themselves be made by members of the rhythm section) take place \citep{Monson1996}. From a technical standpoint, methods capable of processing audio recordings by these instruments are considerably more advanced than many other instruments commonly associated with jazz, such as the saxophone \citep[although here, see][]{Riley2024-omnibook, Ramirez2010}.

% \section{Themes}\label{sec:intro_themes}
\section{Thesis Structure and Contributions}

Our primary contributions in this work consist of advancements across four distinct modelling tasks. We consider: (1) modelling the styles of different jazz performers; (2) modelling the use of rhythm by different performers, and across subgenres and historical periods; (3) modelling the strategies used by different ensembles to coordinate improvisation; and (4) \textit{generating} performances in the style of distinct jazz performers and subgenres. Each subject is covered in an individual chapter of the thesis (Chapters~\ref{chap:xai_rsi}--\ref{chap:conditioned_gen}). These are preceded by Chapter~\ref{chap:jtd_tismir}, which outlines an open-source dataset of annotated recordings used to train and evaluate many of our models. Finally, the thesis concludes with Chapter~\ref{chap:discussion}, which discusses the outcomes of the present work. We provide a short overview of each chapter below.

\textbf{Chapter~\ref{chap:jtd_tismir}: Introducing the Jazz Trio Database.} This chapter addresses the problem of scaling-up computational music research by introducing an automated pipeline for generating symbolic annotations from jazz recordings. Pre-trained deep learning models are applied to ``demix'' an audio recording into separate signals for multiple instruments, which are then automatically annotated using existing transcription models. We use this pipeline to generate the Jazz Trio Database (\GLS{JTD}), an open source dataset of annotated jazz rhythm section performances with a total of 44.5 hours of annotated audio across piano, double bass, and drum kit.

\textbf{Chapter~\ref{chap:xai_rsi}: Modelling Individual Style.} This chapter considers how computational modelling can disentangle the elements contributing to personal improvisation style in jazz improvisation. We construct a series of supervised learning models that learn to identify particular pianists from recordings in \GLS{JTD} and other datasets, and then we interrogate the learned decision functions of these models to understand how these judgements were made. This culminates in a novel deep neural network architecture that achieves predictive accuracy close to the current state-of-the-art, with a multi-input structure that allows its predictions to be explained in terms of four fundamental musical domains --- melody, harmony, rhythm, and dynamics. 

\textbf{Chapter~\ref{chap:rhythm_rsos}: Modelling Rhythmic Style.} This chapter refines the scope of Chapter~\ref{chap:xai_rsi} to focus solely on the importance of rhythm to jazz improvisation style. We develop a jazz pianist identification model trained on handcrafted rhythmic features extracted from \GLS{JTD}. These features are derived from prior empirical and ethnographic accounts of jazz improvisation, and relate to several high-level categories including ``feel'', ``swing'', and ``complexity''. Several features in an additional ``coordination'' category attempt to capture the interaction between members of the rhythm section and how this might relate to the style of the pianist.

\textbf{Chapter~\ref{chap:mp_network}: Modelling Ensemble Interaction.} This chapter focuses on modelling differences between the style of multiple jazz ensembles, using several of the features first defined in Chapters~\ref{chap:jtd_tismir} and~\ref{chap:rhythm_rsos}. We use temporal latency --- such as that introduced by networked communication platforms like Zoom --- as an experimental manipulation to disrupt the tight temporal coordination of action that is typically involved in ensemble jazz performances. We gather data from five professional duos of musicians via a novel software platform that emulates network latency in a controllable fashion. We then use linear causal modelling and computer simulations to explore the strategies they employ to coordinate with one another in the presence and absence of latency, and relate these strategies to descriptions given by the musicians of their own performances.

\textbf{Chapter~\ref{chap:conditioned_gen}: Style-Conditioned Jazz Generation.} Unlike the previous chapters, this chapter focuses on training machine learning models to \textit{generate} new music, rather than understand existing music. Our contributions here are twofold. First, we develop an automated method to link three existing datasets of transcribed jazz performances (including \GLS{JTD}) with high-quality metadata. Second, we use this metadata to train a generative model to produce jazz performances in the style of particular subgenres and performers. A subsidiary goal of this chapter is also to wrap up the work of the entire thesis. We do so by training our model using the datasets first introduced in Chapters~\ref{chap:jtd_tismir} and~\ref{chap:mp_network} and evaluating it using some of the same metrics from Chapters~\ref{chap:xai_rsi} and~\ref{chap:rhythm_rsos}. %We evaluate our model with a subjective listening test and confirm that it is able to produce musical examples that sufficiently sound ``like'' the target style. 

\textbf{Chapter~\ref{chap:discussion}: Conclusion.} This chapter concludes the thesis by summarising the outcomes of the work, discussing its limitations, and offering suggestions for future research.