%%%%%
%% HCheston PhD Thesis, University of Cambridge, Centre for Music & Science
%%%%%

\documentclass[glossary]{cam-thesis}

\usepackage[
    style=authoryear,
    % bibstyle=apa, % why biblatex, why?
    maxcitenames=2,
    mincitenames=1, 
    maxbibnames=99,
    minbibnames=1,
    sortcites=true,
    backend=biber,
    natbib=true,
    labeldate=year,
    uniquename=false,
    uniquelist=false,
    giveninits=true,
    isbn=false,
    url=false,
    eprint=false,
    dashed=false,
    doi=true
]{biblatex}

% Adding packages
\usepackage{graphicx, booktabs, rotating, svg, subfig, amsmath, placeins, url, minted, amsfonts, float, tabularx, multirow, setspace, algpseudocode, algorithm}
\usepackage[authormarkup=superscript,]{changes}
\definechangesauthor[name={HWC},color=red]{HC}

%% Fucking LateX, this shit is cursed
% remove quotations from article titles
\DeclareFieldFormat[article]{title}{#1}

% sentence case for article titles
\DeclareFieldFormat[article, inbook, incollection, inproceedings, patent, thesis, report, unpublished]{title}{\MakeSentenceCase*{#1}}

% names as last-first
\DeclareNameAlias{author}{family-given}

% Redefine macro to only print DOI, not eprint or URL
\DeclareFieldFormat{doi}{%
  \ifhyperref
    {\href{http://doi.org/#1}{\url{http://doi.org/#1}}}
    {\url{\http://doi.org/#1}}}
\renewbibmacro*{doi+eprint+url}{%
  \printfield{doi}}

% Print volume/issue as Volume(Issue)
\renewbibmacro*{volume+number+eid}{%
  \printfield[italic]{volume}%
  \iffieldundef{number}
    {}
    {\printtext{(\printfield{number})}}%
  \setunit{\addcomma\space}%
  \printfield{eid}}

% Remove "In:" from bibliography for journal articles, replace with In for everything else
\renewbibmacro*{in:}{%
  \ifentrytype{article}
    {}
    {\printtext{In\space}}%
}

% Ensure only the year is displayed in citations & references
\AtEveryBibitem{\clearfield{month}\clearfield{day}\clearfield{date}}
\AtEveryCitekey{\clearfield{month}\clearfield{day}\clearfield{date}}

\addbibresource{thesis.bib}

% Fixes https://github.com/mrpiggi/svg/issues/11#issuecomment-525175569
% TODO: eventually replace SVG files with PDF as they slow compile
\svgsetup{inkscapepath=svgsubdir}

% Cambridge requirements specif 1.5 line spacing
\onehalfspacing

\title{Computational Modelling of \\
Jazz Improvisation}
\collegeshield{figures/college_shield}
\author{\textbf{Huw William Cheston}}
\college{Robinson College} % \\ University of Cambridgec
\submissiondate{June, 2025}
% \submissionnotice{}
\date{June, 2025}

\subjectline{Music Information Retrieval}
\keywords{music information retrieval, machine learning, jazz improvisation, explainable artificial intelligence, corpus analysis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{    
    Jazz is a highly improvised form of Western music that so far has received limited scientific attention. This is due in part both to the difficulty of analysing music for which written scores are generally not available and of crafting statistical models that are likely to be meaningful for those who engage with this music. This thesis reports a research programme of five studies that address these problems by first developing a large dataset of annotated jazz recordings and then analysing this and other similar datasets using a variety of computational methods. First, we describe the construction of the Jazz Trio Database (\GLS{JTD}). This is an open source dataset of 45 hours of jazz rhythm section performances with symbolic annotations, comprising both quarter-note downbeats and beats, alongside MIDI for the pianist. Second, we construct a series of supervised-learning models that learn to identify particular \GLS{JTD} pianists from features relating to their use of harmony, melody, rhythm, and dynamics. We then use the decision functions learned by these models to disentangle the different elements that contribute towards defining musical style in jazz. Third, we refine the scope of the previous study to focus on modelling the relationship between rhythm and musical style. We extract a range of rhythmic features (including those relating to ``feel'', ``swing'', and ``interaction'') from JTD and use these to objectively test accounts of jazz rhythmic style given in prior musicological and ethnographic writing. Fourth, we model the mechanisms by which ensemble jazz improvisations actually take place. We use several features from the previous studies to explore the strategies that five duos of professional musicians employ to coordinate with one another under experimental conditions that are designed to disrupt the tight temporal coordination of action typically involved in group jazz performances. Finally, we introduce a generative model that produces music in the styles of particular performers and jazz subgenres, which we train using data and techniques introduced across the entire thesis. Our studies are accompanied by open-source implementations of our models, data, and research software, alongside numerous interactive web applications. We hope these will facilitate future computational research into musical improvisation --- in jazz, and beyond.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{
{\setlength{\parindent}{0cm}
    Although my name is the only one on the cover of this thesis, in reality many people have played a role in shaping this work into its current format. I could not have hoped for a more dedicated supervisor than Peter Harrison, who was continuously generous with his time and advice. I'm also very grateful to my external examiners, Simon Dixon and Martin Clayton, who gave much valuable advice about improving this work. I am also grateful to Ian Cross for his guidance throughout the earlier stages of this research, and to Marcus Pearce, Tuomas Eerola, and John Rink for providing helpful comments on earlier drafts presented at my progression meetings. I am indebted to many others who contributed useful feedback on this research, including Katelyn Emerson, Joshua Frank, David Whyatt, Katya Ness, Nicky Swett, Manuel Anglada-Tort, David Baker, Alex Williams, Nicolas Guo, Iran Roman, Xavier Riley, Drew Edwards, Ivan Shanin, and several anonymous reviewers. I am also grateful to numerous collaborators and co-authors who helped with aspects of this research, including Joshua Schlichting, Reuben Bance, and Tessa Pastor, alongside all of the individuals who participated in the experiments described in Chapters \ref{chap:mp_network} and \ref{chap:conditioned_gen}. During the course of this PhD, I spent several months working as a research intern at Spotify, and I would like to thank Jan Van Balen, Simon Durand, Sebastian Ewert, Peter Sobot, and Ben Hayes for their support and advice during this time. More generally, I also enjoyed the support of various research groups and centres, including the Centre for Music and Science, Centre for Data-Driven Discovery, and Centre for Digital Humanities at Cambridge, and the Centre for Digital Music at Queen Mary. It is unlikely that I would have pursued this research area if not for the encouragement of my earliest teachers, John Law, Stuart Ryan, and Richard O'Mahony, and my tutors at Oxford, Jonathan Cross, Mark Doffman, Eric Clarke, and Leah Broad. I would also like to thank my family, Andrea, Al, Katharine, and Rick, for their help (and their proofreading!) throughout this process. Lastly, I would like to thank my fiancée Hayley for encouraging and supporting me, and for always being willing to listen to my ideas.
    
    \vspace{1.5em}
    
    This work was supported by a Vice-Chancellor's Award from the Cambridge Trust. Additional funding for the research described in Chapter \ref{chap:mp_network} was received from a Project Incubation Award by Cambridge Digital Humanities.
}}

% I'm also grateful to Marcus Pearce and Tuomas Eerola for taking the time to examine my interim submissions and prociding useful advice during my 
%   - Peter (and Ian)
%   - Marcus Pearce + Tuomas Eerola (interim reports)
%   - External examiners: Simon Dixon & Martin Clayton
%   - Support of: Centre for Music & Science, Centre for Digital Humanities at the University of Cambridge, and Centre for Digital Music at Queen Mary University of London.
%   - Feedback on work: at the CMS, Joshua Frank, Katelyn Emerson, David Whyatt, Katya Ness, Nicky Swett; at C4DM, Xavier Riley, Nicolas Guo, Ben Hayes, Alex Williams, Pedro Sarmento; also anonymous reviewers
%   - Intern @ Spotify: thank Jan Van Balen, Simon Durand, Sebastian Ewert, Peter Sobot
%   - Current jobs: thank Iran Roman
%   - Past students and collaborators: Joshua Schlichting, Reuben Bance, Tessa Pastor, prior undergraduate students at the Centre for Music & Science
%   - Family & Hayley
%   - Work supported by Vice-Chancellor's award from the Cambridge Trust.
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Glossary
\newglossaryentry{ATEPP}{
    name=ATEPP,
    description={Automatically Transcribed Expressive Piano Performances \citep{Zhang2022-atepp}}
}
\newglossaryentry{AIC}{
    name=AIC,
    description={Akaike Information Criterion}
}
\newglossaryentry{BIC}{
    name=BIC,
    description={Bayesian Information Criterion}
}
\newglossaryentry{DPO-P}{
    name=DPO-P,
    description={Direct Preference Optimisation Positive \citep{Pal2024}}
}
\newglossaryentry{JTD}{
    name=JTD,
    description={Jazz Trio Database (Chapter \ref{chap:jtd_tismir})}
}
\newglossaryentry{JTD-300}{
    name=JTD-300,
    description={Jazz Trio Database 300 (Section \ref{sec:jtd_class_imbalance})}
}
\newglossaryentry{WJD}{
    name=WJD,
    description={Weimar Jazz Database \citep{Pfleiderer2017}}
}
\newglossaryentry{PiJAMA}{
    name=PiJAMA,
    description={Piano Jazz with Automatic MIDI Annotations \citep{Edwards2023}}
}
\newglossaryentry{TSD}{
    name=TSD,
    description={TimeShift-Duration \citep{Fradet2023-impact}}
}
\newglossaryentry{CNN}{
    name=CNN,
    description={Convolutional Neural Network}
}
\newglossaryentry{RNN}{
    name=RNN,
    description={Recurrent Neural Network}
}
\newglossaryentry{CRNN}{
    name=CRNN,
    description={Convolutional Recurrent Neural Network}
}
\newglossaryentry{BUR}{
    name=BUR,
    description={Beat-Upbeat Ratio \citep{Benadon2006}}
}
\newglossaryentry{LR}{
    name=LR,
    description={Logistic Regression}
}
\newglossaryentry{LSTM}{
    name=LSTM,
    description={Long Short-Term Memory}
}
\newglossaryentry{GRU}{
    name=GRU,
    description={Gated Recurrent Unit}
}
\newglossaryentry{SVM}{
    name=SVM,
    description={Support Vector Machine}
}
\newglossaryentry{RF}{
    name=RF,
    description={Random Forest \citep{Breiman2001}}
}
\newglossaryentry{MIR}{
    name=MIR,
    description={Music Information Retrieval}
}
\newglossaryentry{DBN}{
    name=DBN,
    description={Dynamic Bayesian Network}
}
\newglossaryentry{LZ77}{
    name=LZ77,
    description={Lempel-Ziv 77 Compression Algorithm \citep{Ziv1977}}
}
\newglossaryentry{LIME}{
    name=LIME,
    description={Locally-Interpretable Model Explanations \citep{Ribeiro2016}}
}
\newglossaryentry{TF-IDF}{
    name=TF-IDF,
    description={Term Frequency–Inverse Document Frequency}
}
\newglossaryentry{DTL}{
    name=DTL,
    description={Dig That Lick \citep{Frieler2018}}
}
\newglossaryentry{OR}{
    name=OR,
    description={Odds Ratio}
}
\newglossaryentry{PCA}{
    name=PCA,
    description={Principal Component Analysis}
}
\newglossaryentry{t-SNE}{
    name=t-SNE,
    description={t-Distributed Stochastic Neighbor Embedding}
}
\newglossaryentry{NLL}{
    name=NLL,
    description={Negative Log-Likelihood}
}
\newglossaryentry{CS}{
    name=CS,
    description={CLaMP-3 Score \citep[see][]{Wu2025-clamp3, Wang2025}}
}
\newglossaryentry{ACS}{
    name=ACS,
    description={Average CLaMP-3 Score}
}
\newglossaryentry{PCE}{
    name=PCE,
    description={Pitch-Class Entropy}
}
\newglossaryentry{NPS}{
    name=NPS,
    description={Notes Per Second}
}
\newglossaryentry{CLaMP-3}{
    name=CLaMP-3,
    description={Contrastive Language-Music Pre-training 3: \citep[see][]{Wu2025-clamp3}}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page, abstract, declaration etc.:
\frontmatter{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%
\input{chapters/01_introduction}
\input{chapters/02_jtd_tismir}
\input{chapters/03_xai_rsi}
\input{chapters/04_rhythm_rsos}
\input{chapters/05_network_mperc}
\input{chapters/06_conditioned_gen}
\input{chapters/07_discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Bibliography:
%%
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Appendix:
%%

\appendix
\input{appendix/rsi_feature_weights}
\input{appendix/rsi_haerle_concepts}
\input{appendix/mp_performer_selfreports}

% It is finished.
\cleardoublepage
\thispagestyle{empty}
\null
\end{document}
